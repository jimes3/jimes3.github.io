<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/source/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="Jimes"><meta name="keywords" content=""><meta name="description" content="图神经网络（GNN）数学公式解析图神经网络（Graph Neural Networks, GNN）是一类专门用于处理图结构数据的深度学习模型。GNN 的核心思想是信息传递（Message Passing）：通过迭代地在节点之间传递和聚合邻居的信息，逐步更新节点的表示，最终用于节点分类、链接预测或图分类等任务。  1. 图与初始表示设图为：$$\mathcal{G} &#x3D; (\mathcal"><meta property="og:type" content="article"><meta property="og:title" content="图神经网络-GNN"><meta property="og:url" content="https://jimes.cn/2025/02/14/GNN/index.html"><meta property="og:site_name" content="马锦的博客"><meta property="og:description" content="图神经网络（GNN）数学公式解析图神经网络（Graph Neural Networks, GNN）是一类专门用于处理图结构数据的深度学习模型。GNN 的核心思想是信息传递（Message Passing）：通过迭代地在节点之间传递和聚合邻居的信息，逐步更新节点的表示，最终用于节点分类、链接预测或图分类等任务。  1. 图与初始表示设图为：$$\mathcal{G} &#x3D; (\mathcal"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2025-02-14T07:23:29.857Z"><meta property="article:modified_time" content="2025-02-14T08:09:03.070Z"><meta property="article:author" content="Jimes"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>图神经网络-GNN - 马锦的博客</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var dntVal,Fluid=window.Fluid||{},CONFIG=(Fluid.ctx=Object.assign({},Fluid.ctx),{hostname:"jimes.cn",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!1,baidu:null,google:{measurement_id:null},tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!0}},search_path:"https://cdn.jsdelivr.net/gh/jimes3/jimes3.github.io/local-search.xml",include_content_in_search:!0});CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>Fluid.ctx.dnt||Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=",function(){function a(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],a("js",new Date),a("config","")})</script><meta name="generator" content="Hexo 7.0.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong class="navbar-title">Jimes&#39; Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="图神经网络-GNN"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2025-02-14 15:23" pubdate>2025年2月14日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 1.4k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 23 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">图神经网络-GNN</h1><p id="updated-time" class="note note-info">本文最后更新于 2025年2月14日 下午</p><div class="markdown-body"><h1 id="图神经网络（GNN）数学公式解析"><a href="#图神经网络（GNN）数学公式解析" class="headerlink" title="图神经网络（GNN）数学公式解析"></a>图神经网络（GNN）数学公式解析</h1><p>图神经网络（Graph Neural Networks, GNN）是一类专门用于处理图结构数据的深度学习模型。GNN 的核心思想是<strong>信息传递</strong>（Message Passing）：通过迭代地在节点之间传递和聚合邻居的信息，逐步更新节点的表示，最终用于节点分类、链接预测或图分类等任务。</p><hr><h2 id="1-图与初始表示"><a href="#1-图与初始表示" class="headerlink" title="1. 图与初始表示"></a>1. 图与初始表示</h2><p>设图为：<br>$$<br>\mathcal{G} &#x3D; (\mathcal{V}, \mathcal{E})<br>$$<br>其中 $\mathcal{V}$ 是节点集合，$\mathcal{E}$ 是边集合。对于每个节点 $v \in \mathcal{V}$，我们有一个初始特征向量：<br>$$<br>\mathbf{x}_v \in \mathbb{R}^d<br>$$<br>节点的初始隐藏状态：<br>$$<br>\mathbf{h}_v^{(0)} &#x3D; \mathbf{x}_v<br>$$</p><hr><h2 id="2-信息传递机制"><a href="#2-信息传递机制" class="headerlink" title="2. 信息传递机制"></a>2. 信息传递机制</h2><p>GNN 的核心步骤是<strong>信息传递</strong>（Message Passing），一般在每一层（或迭代步）进行。第 $k$ 层时，每个节点 $v$ 的隐藏状态 $\mathbf{h}_v^{(k)}$ 根据自身以及邻居节点的信息更新。一般来说，该过程可以拆分为三个步骤：</p><ol><li><p><strong>消息计算（Message）</strong><br>对于每条边 $(u, v) \in \mathcal{E}$，计算从节点 $u$ 到节点 $v$ 的消息：</p>$$ \mathbf{m}_{uv}^{(k)} = \text{MESSAGE}^{(k)}\big( \mathbf{h}_u^{(k-1)}, \mathbf{h}_v^{(k-1)}, \mathbf{e}_{uv} \big) $$<p>其中 $\mathbf{e}_{uv}$ 表示边的特征（如果有）。</p></li><li><p><strong>消息聚合（Aggregate）</strong><br>将节点 $v$ 所有来自邻居的消息聚合成一个综合信息：</p>$$ \mathbf{m}_v^{(k)} = \text{AGGREGATE}^{(k)}\left( \left\{ \mathbf{m}_{uv}^{(k)} : u \in \mathcal{N}(v) \right\} \right) $$<p>这里 $\mathcal{N}(v)$ 表示节点 $v$ 的邻居集合。常用的聚合函数有求和（sum）、平均（mean）和最大值（max）。</p></li><li><p><strong>状态更新（Update）</strong><br>根据当前节点的表示和聚合的信息更新节点状态：<br>$$<br>\mathbf{h}_v^{(k)} &#x3D; \text{UPDATE}^{(k)}\left( \mathbf{h}_v^{(k-1)}, \mathbf{m}_v^{(k)} \right)<br>$$</p></li></ol><p>综合上述步骤，节点 $v$ 的更新可以简写为：</p>$$ \mathbf{h}_v^{(k)} = \text{UPDATE}^{(k)}\left( \mathbf{h}_v^{(k-1)},\, \text{AGGREGATE}^{(k)}\Big( \big\{ \text{MESSAGE}^{(k)}\big( \mathbf{h}_u^{(k-1)},\, \mathbf{h}_v^{(k-1)},\, \mathbf{e}_{uv} \big) : u \in \mathcal{N}(v) \big\} \Big) \right) $$<p>经过 $K$ 层的迭代后，每个节点获得了包含更丰富结构信息的表示 $\mathbf{h}_v^{(K)}$。</p><h2 id="3-Readout-层"><a href="#3-Readout-层" class="headerlink" title="3. Readout 层"></a>3. Readout 层</h2><p>在 GNN 任务中，我们通常面临两种主要的预测任务：</p><ol><li><strong>节点级任务（Node-Level Tasks）</strong>：例如节点分类、节点回归，直接使用最终的节点表示 $\mathbf{h}_v^{(K)}$ 作为特征输入到后续的分类器或回归模型。</li><li><strong>图级任务（Graph-Level Tasks）</strong>：例如分子分类、社交网络分析等，需要将整个图的信息汇总成一个固定长度的向量 $\mathbf{y}$，然后进行分类或回归。这一过程被称为 <strong>Readout</strong>。</li></ol><hr><h3 id="1-Readout-的数学定义"><a href="#1-Readout-的数学定义" class="headerlink" title="1. Readout 的数学定义"></a>1. Readout 的数学定义</h3><p>Readout 层的目标是将所有节点的最终表示聚合成一个全局图级表示 $ \mathbf{y}$：</p>$$ \mathbf{y} = \text{READOUT}\Big( \big\{ \mathbf{h}_v^{(K)} : v \in \mathcal{V} \big\} \Big) $$<p>其中，READOUT 函数需要满足 <strong>排列不变性</strong>（Permutation Invariance），即不受节点顺序的影响。这与 GNN 本身的特性一致，因为图的结构不依赖于节点的排列顺序。</p><hr><h3 id="2-常见的-Readout-方法"><a href="#2-常见的-Readout-方法" class="headerlink" title="2. 常见的 Readout 方法"></a>2. 常见的 Readout 方法</h3><h4 id="1-全局池化（Global-Pooling）"><a href="#1-全局池化（Global-Pooling）" class="headerlink" title="(1) 全局池化（Global Pooling）"></a>(1) 全局池化（Global Pooling）</h4><p>最常见的 Readout 操作是使用池化（Pooling）方法对所有节点表示进行聚合，主要包括：</p><ul><li><strong>求和池化（Sum Pooling）</strong></li><li><strong>平均池化（Mean Pooling）</strong></li><li><strong>最大池化（Max Pooling）</strong></li></ul><ol><li><p>求和池化<br>$$<br>\mathbf{y} &#x3D; \sum_{v \in \mathcal{V}} \mathbf{h}_v^{(K)}<br>$$<br>这种方法适用于节点个数不同的图，并且保留了所有节点的信息。但是，如果节点数目变化较大，可能导致数值尺度不稳定。</p></li><li><p>平均池化<br>$$<br>\mathbf{y} &#x3D; \frac{1}{|\mathcal{V}|} \sum_{v \in \mathcal{V}} \mathbf{h}_v^{(K)}<br>$$<br>这种方法可以缓解求和池化的尺度问题，使得不同大小的图得到的向量具有相似的尺度。</p></li><li><p>最大池化<br>$$<br>\mathbf{y} &#x3D; \max_{v \in \mathcal{V}} \mathbf{h}_v^{(K)}<br>$$<br>这种方法选取每个维度上最大的值，适用于强调局部重要性信息的场景，但可能会丢失部分全局信息。</p></li></ol><hr><h4 id="2-注意力加权池化（Attention-Pooling）"><a href="#2-注意力加权池化（Attention-Pooling）" class="headerlink" title="(2) 注意力加权池化（Attention Pooling）"></a>(2) 注意力加权池化（Attention Pooling）</h4><p>全局池化方法对所有节点一视同仁，但在实际应用中，某些节点比其他节点更重要。因此，我们可以引入<strong>注意力机制</strong>，为不同节点分配不同的权重：</p>$$ \alpha_v = \frac{\exp\left( \mathbf{w}^T \mathbf{h}_v^{(K)} \right)}{\sum_{u \in \mathcal{V}} \exp\left( \mathbf{w}^T \mathbf{h}_u^{(K)} \right)} $$<p>$$<br>\mathbf{y} &#x3D; \sum_{v \in \mathcal{V}} \alpha_v \mathbf{h}_v^{(K)}<br>$$</p><p>其中：</p><ul><li>$\mathbf{w}$ 是一个可学习的向量参数。</li><li>$\alpha_v$ 是归一化的注意力权重（类似于 softmax）。</li><li>通过训练，模型可以自动学习哪些节点的重要性较高。</li></ul><hr><h4 id="3-递归池化（Set2Set）"><a href="#3-递归池化（Set2Set）" class="headerlink" title="(3) 递归池化（Set2Set）"></a>(3) 递归池化（Set2Set）</h4><p>Set2Set（Vinyals et al., 2015）是一种用于集合数据的聚合方法，基于递归神经网络（RNN）和注意力机制：</p>$$ \mathbf{q}_t = \text{LSTM}(\mathbf{q}_{t-1}) $$ $$ \mathbf{y}_t = \sum_{v \in \mathcal{V}} \alpha_v^{(t)} \mathbf{h}_v^{(K)} $$ $$ \mathbf{y} = \text{Concat}(\mathbf{y}_T, \mathbf{y}_{T-1}, \dots) $$<p>其中：</p><ul><li>$\mathbf{q}_t$ 是一个动态查询向量。</li><li>LSTM 用于动态更新 $\mathbf{q}_t$。</li><li>通过多步计算，Set2Set 可以捕获更复杂的全局信息。</li></ul><hr><h3 id="3-Readout-在不同任务中的应用"><a href="#3-Readout-在不同任务中的应用" class="headerlink" title="3. Readout 在不同任务中的应用"></a>3. Readout 在不同任务中的应用</h3><table><thead><tr><th><strong>任务类型</strong></th><th><strong>Readout 方法</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td><strong>节点分类</strong></td><td>无需 Readout</td><td>直接用 $\mathbf{h}_v^{(K)}$</td></tr><tr><td><strong>图分类</strong></td><td>Sum, Mean, Max Pooling</td><td>一般场景</td></tr><tr><td><strong>大规模图分类</strong></td><td>Attention Pooling</td><td>关键节点影响较大</td></tr><tr><td><strong>复杂结构图</strong></td><td>Set2Set, Transformer Readout</td><td>需要更复杂的全局信息</td></tr></tbody></table></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a></span></span></div></div><div class="license-box my-3"><div class="license-title"><div>图神经网络-GNN</div><div>https://jimes.cn/2025/02/14/GNN/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Jimes</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2025年2月14日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i> </span></a><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="NC - 非商业性使用"><i class="iconfont icon-nc"></i> </span></a><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="SA - 相同方式共享"><i class="iconfont icon-sa"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2025/07/19/c++%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/" title="c++学习文档"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">c++学习文档</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2025/02/08/RNN/" title="从RNN到LSTM（包含代码实现）"><span class="hidden-mobile">从RNN到LSTM（包含代码实现）</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",function(){var t="github-light",e="github-dark",s="dark"===(s=document.documentElement.getAttribute("data-user-color-scheme"))?e:t,t=(window.UtterancesThemeLight=t,window.UtterancesThemeDark=e,document.createElement("script"));t.setAttribute("src","https://utteranc.es/client.js"),t.setAttribute("repo","jiems3/utterances_comments"),t.setAttribute("issue-term","pathname"),t.setAttribute("label","utterances"),t.setAttribute("theme",s),t.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(t)})</script><script src="https://utteranc.es/client.js" repo="jimes3/utterances_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div><span id="timeDate">正在载入天数...</span> <span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("01/01/2024 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="🚀已持续航行&nbsp"+dnum+"&nbsp天",document.getElementById("times").innerHTML=hnum+"&nbsp时&nbsp"+mnum+"&nbsp分&nbsp"+snum+"&nbsp秒"}setInterval("createtime()",250)</script></div><div class="total-wordcount">总字数: <span>62.3k</span> 字</div><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Jimes</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Blog</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,t=t.getElementById("subtitle");t&&e&&e(t.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){var t;"tocbot"in window&&(tocbot.refresh(),0!==(t=jQuery("#toc")).length)&&tocbot&&0<t.find(".toc-list-item").length&&t.css("visibility","visible")}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback(function(){if("anchors"in window){anchors.removeAll();var n,o=[];for(n of(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","))o.push(".markdown-body > "+n.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}})})</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{t=t.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback(function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())})</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body></html>