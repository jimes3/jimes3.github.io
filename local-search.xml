<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>考研复试</title>
    <link href="/2025/03/22/%E8%80%83%E7%A0%94%E5%A4%8D%E8%AF%95/"/>
    <url>/2025/03/22/%E8%80%83%E7%A0%94%E5%A4%8D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h1 id="一，机试"><a href="#一，机试" class="headerlink" title="一，机试"></a>一，机试</h1><ul><li>常用库与输入输出</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span>  <span class="hljs-comment">//动态内存</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdbool.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;math.h&gt;</span></span><br><span class="hljs-comment">//scanf</span><br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot; %c %c %c&quot;</span>,&amp;a,&amp;b,&amp;c);<span class="hljs-comment">// 输入时，里面的空格代表输入时任意长度的空格</span><br><br><span class="hljs-comment">//fgets 读取一行数据</span><br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%c&quot;</span>,&amp;c);<span class="hljs-comment">//去除换行府，和fgets搭配使用</span><br><span class="hljs-built_in">fgets</span>(p,n,stdin);<span class="hljs-comment">//读取一行数据，直到换行符或者指定字符长度n-1，&lt;stdio.h&gt;</span><br><br><span class="hljs-comment">//读取数组</span><br><span class="hljs-type">char</span> p[<span class="hljs-number">100</span>];<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%s&quot;</span>,&amp;p);<br><br><span class="hljs-comment">//数组结束，\0</span><br><span class="hljs-comment">//换行符，\n</span><br><span class="hljs-comment">//单字符可以当数字计算，使用对应的ASCLL编码,大小写字母相差32，大写更小，字符集256个</span><br><span class="hljs-comment">//占位符：%d  %c  %s  %f  %lf</span><br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment">学校要求仅用这两个标准库</span><br><span class="hljs-comment">&lt;stdio.h&gt;：scanf(),fgets(),printf()</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">&lt;stdlib.h&gt;：rand(),malloc(),realloc(),free(),abs(int),qsort()</span><br><span class="hljs-comment">0-10的随机数：rand()%10</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">        int cmp(const void *a,const void *b) &#123;</span><br><span class="hljs-comment">            return *(int*)a-*(int*)b;//可以换成char实现字符排序</span><br><span class="hljs-comment">        &#125;</span><br><span class="hljs-comment">        qsort(num, n, sizeof(int), cmp);</span><br><span class="hljs-comment">        qsort(数组名, 元素个数, 元素字节, 排序原则);</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">printf(&quot;%.2f&quot;,x); //打印保留两位小数，四舍五入</span><br><span class="hljs-comment">//变量四舍五入成整数</span><br><span class="hljs-comment">float a;</span><br><span class="hljs-comment">int aa = (int)(a+0.5);</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="1-1-动态扩容"><a href="#1-1-动态扩容" class="headerlink" title="1.1 动态扩容"></a>1.1 动态扩容</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">int</span> capacity = <span class="hljs-number">2</span>; <span class="hljs-comment">// 初始容量</span><br><span class="hljs-type">int</span> size = <span class="hljs-number">0</span>; <span class="hljs-comment">// 当前元素个数</span><br><span class="hljs-type">int</span> num;      <span class="hljs-comment">//输入数据</span><br><br><span class="hljs-comment">// 动态扩充内存</span><br><span class="hljs-type">int</span> *arr = (<span class="hljs-type">int</span> *)<span class="hljs-built_in">malloc</span>(capacity * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<span class="hljs-comment">// 分配初始内存</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;请输入整数（输入任意非数字字符结束）：\n&quot;</span>);<br><span class="hljs-keyword">while</span> (<span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>,&amp;num) == <span class="hljs-number">1</span>) &#123; <span class="hljs-comment">//成功读取并赋值了n个输入项，scanf返回n，因此输入为整数时返回1</span><br>                                 <span class="hljs-comment">//也可以不设，使用ctral+z手动结束</span><br>    <span class="hljs-comment">// 如果当前元素个数达到容量上限，扩展内存</span><br>    <span class="hljs-keyword">if</span> (size &gt;= capacity) &#123;<br>        capacity *= <span class="hljs-number">2</span>; <span class="hljs-comment">// 容量翻倍</span><br>        <span class="hljs-type">int</span> *new_arr = (<span class="hljs-type">int</span> *)<span class="hljs-built_in">realloc</span>(arr, capacity * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<span class="hljs-comment">// 重点，动态扩充内存</span><br>        arr = new_arr; <span class="hljs-comment">// 更新指针</span><br>    &#125;<br>    arr[size++] = num; <span class="hljs-comment">// 将输入的数存入数组，动态记录数组存储的数据量</span><br>&#125;<br><span class="hljs-comment">// 释放动态数组内存</span><br><span class="hljs-built_in">free</span>(arr);<br></code></pre></td></tr></table></figure><h2 id="1-2-链表"><a href="#1-2-链表" class="headerlink" title="1.2 链表"></a>1.2 链表</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 1.结构体定义----------------------------------</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Lnode</span>&#123;<br><span class="hljs-type">int</span> data;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Lnode</span> *next;<br>&#125;Lnode,*sqlist;<br><br><span class="hljs-comment">// 2.头插入创建链表------------------------------</span><br>sqlist L = (Lnode*)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(Lnode));<br>L-&gt;next = <span class="hljs-literal">NULL</span>;<br>sqlist s = (Lnode*)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(Lnode)); <span class="hljs-comment">//新建结点</span><br><br><span class="hljs-comment">// 3.链表插入----------------------------------</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">insert</span><span class="hljs-params">(sqlist L,<span class="hljs-type">int</span> x)</span></span>&#123;<br>sqlist T = (Lnode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(Lnode));<br>T-&gt;data = x;<br>T-&gt;next = L-&gt;next;<br>L-&gt;next = T;<br>&#125;<br><br><span class="hljs-comment">// 4.链表删除----------------------------------</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">del</span><span class="hljs-params">(sqlist L)</span></span>&#123;<br><span class="hljs-keyword">if</span>(L-&gt;next == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    <span class="hljs-type">int</span> x;<br>sqlist H = L-&gt;next;<br>L-&gt;next = H-&gt;next;<br>    x = H-&gt;data;<br><span class="hljs-built_in">free</span>(H);<br>    <span class="hljs-keyword">return</span> x;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="1-3-栈与队列"><a href="#1-3-栈与队列" class="headerlink" title="1.3 栈与队列"></a>1.3 栈与队列</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//可使用头插法链表代替</span><br></code></pre></td></tr></table></figure><h2 id="1-4-括号匹配"><a href="#1-4-括号匹配" class="headerlink" title="1.4 括号匹配"></a>1.4 括号匹配</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">char</span> b;<br>sqlist L = (Lnode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(Lnode));<span class="hljs-comment">//栈初始化 </span><br>L-&gt;next = <span class="hljs-literal">NULL</span>;<br><span class="hljs-keyword">while</span>(<span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%c&quot;</span>,&amp;b))&#123;<br><span class="hljs-keyword">if</span>(b==<span class="hljs-string">&#x27;\n&#x27;</span>)&#123;<br><span class="hljs-keyword">break</span>;<br>&#125;<br><span class="hljs-keyword">if</span>(b==<span class="hljs-string">&#x27;(&#x27;</span>)&#123;<br><span class="hljs-built_in">insert</span>(L,b);<br>&#125;<br><span class="hljs-keyword">if</span>(b==<span class="hljs-string">&#x27;)&#x27;</span>)&#123;<span class="hljs-comment">//防止右括号过多与顺序不对 </span><br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">del</span>(L)==<span class="hljs-string">&#x27;(&#x27;</span>)&#123;<br><span class="hljs-keyword">continue</span>;<br>&#125;<br><span class="hljs-keyword">else</span>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;error&quot;</span>);<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span>(L-&gt;next==<span class="hljs-literal">NULL</span>)<span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;match&quot;</span>);<span class="hljs-comment">//防止左括号过多 </span><br><span class="hljs-keyword">else</span> <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;error&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="1-5-十进制转二进制"><a href="#1-5-十进制转二进制" class="headerlink" title="1.5 十进制转二进制"></a>1.5 十进制转二进制</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">int</span> a;<span class="hljs-comment">//除二所剩的商</span><br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>,&amp;a);<br><span class="hljs-type">int</span> b;<span class="hljs-comment">//余数即二进制</span><br><span class="hljs-type">int</span> i=<span class="hljs-number">1</span>;计算结果由低到高<br><span class="hljs-type">int</span> result = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">while</span>(a&gt;=<span class="hljs-number">1</span>)&#123;<br>b = a%<span class="hljs-number">2</span>;<br>a = a/<span class="hljs-number">2</span>;<br>result += i*b;<br>i=i*<span class="hljs-number">10</span>;<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>,result);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="1-6-最长不重复字符串"><a href="#1-6-最长不重复字符串" class="headerlink" title="1.6 最长不重复字符串"></a>1.6 最长不重复字符串</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">check</span><span class="hljs-params">(<span class="hljs-type">char</span> s[],<span class="hljs-type">int</span> i,<span class="hljs-type">int</span> j)</span></span>&#123;<span class="hljs-comment">//检查是否有重复字符</span><br><span class="hljs-type">int</span> k;<br>    <span class="hljs-keyword">for</span>(i;i&lt;=j;i++)&#123;<br>    <span class="hljs-keyword">for</span>(k=i+<span class="hljs-number">1</span>;k&lt;=j;k++)&#123;<br>        <span class="hljs-keyword">if</span>(s[i]==s[k])<span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;len;i++)&#123;<br>    <span class="hljs-keyword">for</span>(j=i+<span class="hljs-number">1</span>;j&lt;len;j++)&#123;<br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">check</span>(s,i,j))&#123;<br>            <span class="hljs-keyword">if</span>(j-i+<span class="hljs-number">1</span>&gt;result)result=j-i+<span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d&quot;</span>,result);<br></code></pre></td></tr></table></figure><h2 id="1-7-字符大小写转换"><a href="#1-7-字符大小写转换" class="headerlink" title="1.7 字符大小写转换"></a>1.7 字符大小写转换</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//字符小写</span><br><span class="hljs-function"><span class="hljs-type">char</span> <span class="hljs-title">low</span><span class="hljs-params">(<span class="hljs-type">char</span> c)</span></span>&#123;<br>    <span class="hljs-keyword">if</span> (c &gt;= <span class="hljs-string">&#x27;A&#x27;</span> &amp;&amp; c &lt;= <span class="hljs-string">&#x27;Z&#x27;</span>) &#123;<br>        <span class="hljs-keyword">return</span> c + <span class="hljs-number">32</span>;<br>    &#125;<br>    <span class="hljs-comment">// 如果不是大写字母，直接返回原字符</span><br>    <span class="hljs-keyword">return</span> c;<br>&#125;<br><br><span class="hljs-comment">//字符大写</span><br><span class="hljs-function"><span class="hljs-type">char</span> <span class="hljs-title">up</span><span class="hljs-params">(<span class="hljs-type">char</span> c)</span></span>&#123;<br>    <span class="hljs-keyword">if</span> (c &gt;= <span class="hljs-string">&#x27;a&#x27;</span> &amp;&amp; c &lt;= <span class="hljs-string">&#x27;z&#x27;</span>) &#123;<br>        <span class="hljs-keyword">return</span> c - <span class="hljs-number">32</span>;<br>    &#125;<br>    <span class="hljs-comment">// 如果不是小写字母，直接返回原字符</span><br>    <span class="hljs-keyword">return</span> c;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">char</span> a[<span class="hljs-number">100</span>]=<span class="hljs-string">&quot;lskdjflskdjf@QQ.com&quot;</span>;<br><span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;<br><span class="hljs-type">int</span> j;<br><span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)&#123;<br><span class="hljs-keyword">if</span>(a[i]==<span class="hljs-string">&#x27;\0&#x27;</span>)&#123;<span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;不是邮箱\n&quot;</span>);<br>&#125;<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(a[i]==<span class="hljs-string">&#x27;@&#x27;</span>)&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;是邮箱\n&quot;</span>);<br><span class="hljs-keyword">for</span>(j=<span class="hljs-number">1</span>;j&lt;i;j++)&#123;  <span class="hljs-comment">//加密，第一个除外转换为星号</span><br>a[j]=<span class="hljs-string">&#x27;*&#x27;</span>;<br>&#125;<br><span class="hljs-keyword">while</span>(a[i]!=<span class="hljs-string">&#x27;\0&#x27;</span>)&#123;  <span class="hljs-comment">//小写邮箱字符</span><br>a[i] = <span class="hljs-built_in">low</span>(a[i]);<br>i++;<br>&#125;<br><span class="hljs-keyword">break</span>;<br>&#125;<br>i++;<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s&quot;</span>,a);<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="二，综合面试（个人项目概括）"><a href="#二，综合面试（个人项目概括）" class="headerlink" title="二，综合面试（个人项目概括）"></a>二，综合面试（个人项目概括）</h1><ul><li>提前学习神经网络基础。</li></ul><h2 id="2-1-CNN"><a href="#2-1-CNN" class="headerlink" title="2.1 CNN"></a>2.1 CNN</h2><ul><li>数据集：MINIST数据集，28*28灰度图，要标准化</li><li>结构：2*（卷积层+激活函数+池化层）+全连接+激活函数+全连接<ul><li>数据的通道：1 -&gt; 32 -&gt; 64，灰度图初始为1。</li><li>卷积核（滤波器）的大小,3*3（有优化）</li><li>padding为1，步长默认为1</li><li>池化：在每个 2x2 的区域内，步长为2，取最大值作为输出</li><li>激活函数：relu</li></ul></li></ul><h2 id="2-2-RNN与LSTM"><a href="#2-2-RNN与LSTM" class="headerlink" title="2.2 RNN与LSTM"></a>2.2 RNN与LSTM</h2><ul><li><p>数据集：18万训练集，1万验证集与训练集，电影评论10分类。</p></li><li><p>词汇表（分字）与词嵌入（腾讯）均下载在本地。</p></li><li><p>输入固定长度25，多的填充。</p></li><li><p>RNN结构：</p><ul><li>词汇表大小：4762</li><li>词嵌入维度：200</li><li>隐藏层维度：128（隐藏层向量长128，每一个隐藏层的向量树）</li><li>RNN层数：2（多少层隐藏层）</li><li>学习率：0.001</li><li>额外要有 pad，unk 的索引</li></ul></li><li><p>LSTM结构：</p><ul><li>词汇表大小：4762</li><li>词嵌入维度：200</li><li>隐藏层维度：128（隐藏层向量长128，每一个隐藏层的向量树）</li><li>LSTM层数：2（多少层隐藏层）</li><li>学习率：0.001</li><li>额外要有 pad，unk 的索引</li></ul></li></ul><h2 id="2-3-transformer"><a href="#2-3-transformer" class="headerlink" title="2.3 transformer"></a>2.3 transformer</h2><ul><li>数据集：18万训练集，1万验证集与训练集，电影评论10分类。</li><li>词汇表（分字）与词嵌入（腾讯）均下载在本地。</li><li>输入固定长度25，多的填充。</li><li>结构：<ul><li>词汇表大小：4762</li><li>词嵌入维度：200</li><li>编码器头数：4（确保词嵌入维度能被其整除）</li><li>编码器层数：2（包含多头注意力层和前馈网络层）</li><li>前馈网络的维度：400（词嵌入2-4倍）</li><li>Dropout概率：0.1</li><li>学习率：0.0001</li><li>额外要有 pad，unk 的索引</li></ul></li></ul><h2 id="2-4-数学建模"><a href="#2-4-数学建模" class="headerlink" title="2.4 数学建模"></a>2.4 数学建模</h2><ul><li>多波束测深问题</li><li>问题一与问题二：建立几何模型，运用余弦定理</li><li>问题三：通过贪心算法在斜度固定的坡面上覆盖最广的测线位置</li><li>问题四：在给定海底坡面数据下，结合第三问通过蒙特卡洛模拟得出测线大概方向；再用最小二乘法进行坡面拟合，用改进的鲸鱼算法计算位置。</li><li>问题：<ul><li>没有进行对比分析，只有自己计算的结果。</li><li>数据验证存在问题。应该进行随机点检测。</li><li>测线全为直线，不太现实。</li></ul></li></ul><h2 id="2-5-自我介绍"><a href="#2-5-自我介绍" class="headerlink" title="2.5 自我介绍"></a>2.5 自我介绍</h2><p>　　尊敬的各位老师，大家好！我是马锦，江西鄱阳人，来自西安工业大学物流管理专业。很荣幸能够在此参加复试。<br>　　在本科学习方面，我的绩点为3.43，曾获得二等学业奖学金。<br>　　在技能证书方面，我通过了英语四级，计算机python二级，获得了优秀共青团员。<br>　　在竞赛方面，我获得了全国大学生数学建模陕西赛区二等奖，并且在比赛中担任主力，完成绝大部分任务。除此之外还有互联网+和物流管理专业方面的竞赛，都是校级奖项。<br>　　在计算机学习方面，我在23年底就买了域名建立了自己的博客，并且把自己学习中的笔记发到博客上分享，我认为这是一件很让人满足的事。同时在寒假期间我也学习了很多关于深度学习方向的内容，像BP、CNN、RNN、LSTM、Transformer等主流网络结构，也学习了pytorch并通过它来实现这些网络，同时在数据集上进行应用。其中，BP神经网络我是通过数学公式实现的，然后因为做的是分类任务所以Transformer我只使用了编码器，这些在我的博客上都有记录。我的博客目前访问人数约1500人，访问次数约2800次。我很渴望学习到新的知识，我的规划是把暑假的时间用来补充基础知识和复现相关论文的能力。<br>　　我非常希望能够加入贵校，在各位老师的指导下进一步提升自己。谢谢！</p><h1 id="三，英语面试"><a href="#三，英语面试" class="headerlink" title="三，英语面试"></a>三，英语面试</h1><p>　　Good morning, dear professors. It’s a great honor for me to have this interview here today.<br>　　First, I’d like to briefly introduce myself. My name is Ma Jin and I come from the Logistics Management major at Xi’an Technological University. During my college years, I participated in some competitions and achieved results.  For example, I won the <strong>provincial second prize</strong> in the China Undergraduate Mathematical Contest in Modeling and the third prize in the “Internet plus” contest at my school;  I have also obtained some certificates, such as CET-4, National Computer Level 2 Examination for Python, Outstanding Communist Youth League Member and so on.<br>　　On top of that, The reason why I’m pursuing a master’s degree is that I wanna study the major I’m truly intrigued in and make achievements in my major.  I chose Ningbo University because I wanna find job in Ningbo. I studied here for my elementary and junior high school, and I really enjoy the life and customs here.<br>　　Finally, If I’m admitted, I will continue to learn and improve myself, as well as actively participate in my mentor’s project.<br>　　The above is my personal profile. Thank you for listening.</p><h2 id="3-1-常见问题"><a href="#3-1-常见问题" class="headerlink" title="3.1 常见问题"></a>3.1 常见问题</h2><p>1.介绍家乡</p><p>　　My hometown is Poyang County, Jiangxi Province.<br>　　Here is the largest freshwater lake —- Poyang Lake in China.<br>　　There are many places of interest in Jiangxi province, like Lushan Mountain、Teng Wang Pavilion、Sanqing Mountain and so on.<br>　　Besides，Jiangxi also has a deep red culture, Nanchang had the Nanchang Uprising, Jinggangshan had the revolutionary base, and Ruijin had the provisional central government.</p><p>2.爱好</p><p>　　In the process of learning, I like to record my learning results on my blog.<br>　　Now more than a thousand people have visited my blog;<br>　　In my spare time, I like playing pingpang with my friends.And other ball games.</p><p>3.最喜欢的书&#x2F;电影</p><p>　　My favorite book is 《Father and Son》, it’s the first book I have read, it tells about the daily fun between a father and a son, which also contains life philosophy.  Although this is the book I have read in my elementry school, I still remember it.<br>　　My favorite movie is 《Lucy》.  In the movie, when the human brain is 100 percent developed, it becomes information, like a supercomputer.    I think is a very good idea for future.  And maybe the future of AI will like it.</p><p>4.家庭</p><p>　　There are four people in my family, my parents, my elder sister and me.<br>　　My parents are both worker, they have worked here about 22 years. And they will try their best to support my study, and I am very grateful to my parents for their support.<br>　　My sister is a graduate student in Jiangxi Normal University.  She often help me about my study. Now she is a high school teacher in my hometown.</p><p>5.个人缺点&#x2F;优点</p><p>　　My weakness, I think I’m not good at providing emotional value, so maybe the conversation with girls is a little rough.<br>　　My good points. I love to learn and work hard, And I often study for hours on end.  In more detail, I have my own blog and I often record my study notes on my blog and share it with others. Now more than a thousand people have visited my blog.</p><p>6.遇到突发情况怎么办(emergency)</p><p>　　First, calm down and analyze the situation. I will not panic, because it will not help me to solve it.<br>　　Second, make reasonable decisions based on my own abilities;<br>　　Finally, follow up the resolution process I have made.<br>　　Then the emergency may no longer be urgent, and I can make it.</p><p>7.为什么选择计算机专业</p><p>　　I chose computer science because I’m intrigued in it, and I’m also  optimistic about the future of artificial intelligence.<br>　　I hope to become a talent in the field of computer science through professional study.</p><p>8.日常每周以及每天会保持多久的学习时间</p><p>　　Every day I use the computer to study, maybe 5 hours a day.<br>　　Weekends are also normal, so I study about 35 hours a week.</p><p>9.如何看待人工智能</p><p>　　I’m confident that AI has a bright future.  Now more and more people select AI to help them do their jobs. Although there are many aspects of AI cannot like humans, it can be combined with others and can run for a long time.  This is useful in some areas, such as automation and harsh environments.</p><p>10.未来计划</p><p>　　I plan to learn some basic knowledge this summer vacation.<br>　　In the first year, I will learn and expand the knowledge in the class, and at the same time I will start to read some new papers.<br>　　In the next two years, I will start my papers and participate in my mentor’s project.</p><p>11.英语重要吗</p><p>　　I think English is very important.<br>　　As a graduate student, it’s necessary to have English ability to attend meetings or read papers.<br>　　For our computer students, the new information and the new papers are often in English, so we should learn English well.</p><p>12.旅游景点</p><p>　　Lushan Mountain is located in Jiujiang County, every year many people travel there. On the mountain, sometimes, you can see the clouds under your feet, and as the same level with the sun. On top of that, You can also enjoy very healthy and fresh air in Lushan Mountain.</p><h2 id="3-2-通用单元"><a href="#3-2-通用单元" class="headerlink" title="3.2 通用单元"></a>3.2 通用单元</h2><p>1.对于解决某件事的问句<br>　　In order to solve it, I’m going to take three steps. First,  Second,  Finally,</p><p>2.常用搭配<br>　　Thank you for your question.<br>　　When it comes to sth.（重复问题中的关键字）<br>　　I’d like to mention sth.（回答中的关键字）</p><p>3.不会的<br>　　Sorry，I didn’t hear clearly , could you ask the question again?</p><p>4.问题结束<br>　　My answer is down, thank you.</p>]]></content>
    
    
    <categories>
      
      <category>考研</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>图神经网络-GNN</title>
    <link href="/2025/02/14/GNN/"/>
    <url>/2025/02/14/GNN/</url>
    
    <content type="html"><![CDATA[<h1 id="图神经网络（GNN）数学公式解析"><a href="#图神经网络（GNN）数学公式解析" class="headerlink" title="图神经网络（GNN）数学公式解析"></a>图神经网络（GNN）数学公式解析</h1><p>图神经网络（Graph Neural Networks, GNN）是一类专门用于处理图结构数据的深度学习模型。GNN 的核心思想是<strong>信息传递</strong>（Message Passing）：通过迭代地在节点之间传递和聚合邻居的信息，逐步更新节点的表示，最终用于节点分类、链接预测或图分类等任务。</p><hr><h2 id="1-图与初始表示"><a href="#1-图与初始表示" class="headerlink" title="1. 图与初始表示"></a>1. 图与初始表示</h2><p>设图为：<br>$$<br>\mathcal{G} &#x3D; (\mathcal{V}, \mathcal{E})<br>$$<br>其中 $\mathcal{V}$ 是节点集合，$\mathcal{E}$ 是边集合。对于每个节点 $v \in \mathcal{V}$，我们有一个初始特征向量：<br>$$<br>\mathbf{x}_v \in \mathbb{R}^d<br>$$<br>节点的初始隐藏状态：<br>$$<br>\mathbf{h}_v^{(0)} &#x3D; \mathbf{x}_v<br>$$</p><hr><h2 id="2-信息传递机制"><a href="#2-信息传递机制" class="headerlink" title="2. 信息传递机制"></a>2. 信息传递机制</h2><p>GNN 的核心步骤是<strong>信息传递</strong>（Message Passing），一般在每一层（或迭代步）进行。第 $k$ 层时，每个节点 $v$ 的隐藏状态 $\mathbf{h}_v^{(k)}$ 根据自身以及邻居节点的信息更新。一般来说，该过程可以拆分为三个步骤：</p><ol><li><p><strong>消息计算（Message）</strong><br>对于每条边 $(u, v) \in \mathcal{E}$，计算从节点 $u$ 到节点 $v$ 的消息：</p>$$\mathbf{m}_{uv}^{(k)} = \text{MESSAGE}^{(k)}\big( \mathbf{h}_u^{(k-1)}, \mathbf{h}_v^{(k-1)}, \mathbf{e}_{uv} \big)$$<p>其中 $\mathbf{e}_{uv}$ 表示边的特征（如果有）。</p></li><li><p><strong>消息聚合（Aggregate）</strong><br>将节点 $v$ 所有来自邻居的消息聚合成一个综合信息：</p>$$\mathbf{m}_v^{(k)} = \text{AGGREGATE}^{(k)}\left( \left\{ \mathbf{m}_{uv}^{(k)} : u \in \mathcal{N}(v) \right\} \right)$$<p>这里 $\mathcal{N}(v)$ 表示节点 $v$ 的邻居集合。常用的聚合函数有求和（sum）、平均（mean）和最大值（max）。</p></li><li><p><strong>状态更新（Update）</strong><br>根据当前节点的表示和聚合的信息更新节点状态：<br>$$<br>\mathbf{h}_v^{(k)} &#x3D; \text{UPDATE}^{(k)}\left( \mathbf{h}_v^{(k-1)}, \mathbf{m}_v^{(k)} \right)<br>$$</p></li></ol><p>综合上述步骤，节点 $v$ 的更新可以简写为：</p>$$\mathbf{h}_v^{(k)} = \text{UPDATE}^{(k)}\left( \mathbf{h}_v^{(k-1)},\, \text{AGGREGATE}^{(k)}\Big( \big\{ \text{MESSAGE}^{(k)}\big( \mathbf{h}_u^{(k-1)},\, \mathbf{h}_v^{(k-1)},\, \mathbf{e}_{uv} \big) : u \in \mathcal{N}(v) \big\} \Big) \right)$$<p>经过 $K$ 层的迭代后，每个节点获得了包含更丰富结构信息的表示 $\mathbf{h}_v^{(K)}$。</p><h2 id="3-Readout-层"><a href="#3-Readout-层" class="headerlink" title="3. Readout 层"></a>3. Readout 层</h2><p>在 GNN 任务中，我们通常面临两种主要的预测任务：</p><ol><li><strong>节点级任务（Node-Level Tasks）</strong>：例如节点分类、节点回归，直接使用最终的节点表示 $\mathbf{h}_v^{(K)}$ 作为特征输入到后续的分类器或回归模型。</li><li><strong>图级任务（Graph-Level Tasks）</strong>：例如分子分类、社交网络分析等，需要将整个图的信息汇总成一个固定长度的向量 $\mathbf{y}$，然后进行分类或回归。这一过程被称为 <strong>Readout</strong>。</li></ol><hr><h3 id="1-Readout-的数学定义"><a href="#1-Readout-的数学定义" class="headerlink" title="1. Readout 的数学定义"></a>1. Readout 的数学定义</h3><p>Readout 层的目标是将所有节点的最终表示聚合成一个全局图级表示 $ \mathbf{y}$：</p>$$\mathbf{y} = \text{READOUT}\Big( \big\{ \mathbf{h}_v^{(K)} : v \in \mathcal{V} \big\} \Big)$$<p>其中，READOUT 函数需要满足 <strong>排列不变性</strong>（Permutation Invariance），即不受节点顺序的影响。这与 GNN 本身的特性一致，因为图的结构不依赖于节点的排列顺序。</p><hr><h3 id="2-常见的-Readout-方法"><a href="#2-常见的-Readout-方法" class="headerlink" title="2. 常见的 Readout 方法"></a>2. 常见的 Readout 方法</h3><h4 id="1-全局池化（Global-Pooling）"><a href="#1-全局池化（Global-Pooling）" class="headerlink" title="(1) 全局池化（Global Pooling）"></a>(1) 全局池化（Global Pooling）</h4><p>最常见的 Readout 操作是使用池化（Pooling）方法对所有节点表示进行聚合，主要包括：</p><ul><li><strong>求和池化（Sum Pooling）</strong></li><li><strong>平均池化（Mean Pooling）</strong></li><li><strong>最大池化（Max Pooling）</strong></li></ul><ol><li><p>求和池化<br>$$<br>\mathbf{y} &#x3D; \sum_{v \in \mathcal{V}} \mathbf{h}_v^{(K)}<br>$$<br>这种方法适用于节点个数不同的图，并且保留了所有节点的信息。但是，如果节点数目变化较大，可能导致数值尺度不稳定。</p></li><li><p>平均池化<br>$$<br>\mathbf{y} &#x3D; \frac{1}{|\mathcal{V}|} \sum_{v \in \mathcal{V}} \mathbf{h}_v^{(K)}<br>$$<br>这种方法可以缓解求和池化的尺度问题，使得不同大小的图得到的向量具有相似的尺度。</p></li><li><p>最大池化<br>$$<br>\mathbf{y} &#x3D; \max_{v \in \mathcal{V}} \mathbf{h}_v^{(K)}<br>$$<br>这种方法选取每个维度上最大的值，适用于强调局部重要性信息的场景，但可能会丢失部分全局信息。</p></li></ol><hr><h4 id="2-注意力加权池化（Attention-Pooling）"><a href="#2-注意力加权池化（Attention-Pooling）" class="headerlink" title="(2) 注意力加权池化（Attention Pooling）"></a>(2) 注意力加权池化（Attention Pooling）</h4><p>全局池化方法对所有节点一视同仁，但在实际应用中，某些节点比其他节点更重要。因此，我们可以引入<strong>注意力机制</strong>，为不同节点分配不同的权重：</p>$$\alpha_v = \frac{\exp\left( \mathbf{w}^T \mathbf{h}_v^{(K)} \right)}{\sum_{u \in \mathcal{V}} \exp\left( \mathbf{w}^T \mathbf{h}_u^{(K)} \right)}$$<p>$$<br>\mathbf{y} &#x3D; \sum_{v \in \mathcal{V}} \alpha_v \mathbf{h}_v^{(K)}<br>$$</p><p>其中：</p><ul><li>$\mathbf{w}$ 是一个可学习的向量参数。</li><li>$\alpha_v$ 是归一化的注意力权重（类似于 softmax）。</li><li>通过训练，模型可以自动学习哪些节点的重要性较高。</li></ul><hr><h4 id="3-递归池化（Set2Set）"><a href="#3-递归池化（Set2Set）" class="headerlink" title="(3) 递归池化（Set2Set）"></a>(3) 递归池化（Set2Set）</h4><p>Set2Set（Vinyals et al., 2015）是一种用于集合数据的聚合方法，基于递归神经网络（RNN）和注意力机制：</p>$$\mathbf{q}_t = \text{LSTM}(\mathbf{q}_{t-1})$$$$\mathbf{y}_t = \sum_{v \in \mathcal{V}} \alpha_v^{(t)} \mathbf{h}_v^{(K)}$$$$\mathbf{y} = \text{Concat}(\mathbf{y}_T, \mathbf{y}_{T-1}, \dots)$$<p>其中：</p><ul><li>$\mathbf{q}_t$ 是一个动态查询向量。</li><li>LSTM 用于动态更新 $\mathbf{q}_t$。</li><li>通过多步计算，Set2Set 可以捕获更复杂的全局信息。</li></ul><hr><h3 id="3-Readout-在不同任务中的应用"><a href="#3-Readout-在不同任务中的应用" class="headerlink" title="3. Readout 在不同任务中的应用"></a>3. Readout 在不同任务中的应用</h3><table><thead><tr><th><strong>任务类型</strong></th><th><strong>Readout 方法</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td><strong>节点分类</strong></td><td>无需 Readout</td><td>直接用 $\mathbf{h}_v^{(K)}$</td></tr><tr><td><strong>图分类</strong></td><td>Sum, Mean, Max Pooling</td><td>一般场景</td></tr><tr><td><strong>大规模图分类</strong></td><td>Attention Pooling</td><td>关键节点影响较大</td></tr><tr><td><strong>复杂结构图</strong></td><td>Set2Set, Transformer Readout</td><td>需要更复杂的全局信息</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>从RNN到LSTM（包含代码实现）</title>
    <link href="/2025/02/08/RNN/"/>
    <url>/2025/02/08/RNN/</url>
    
    <content type="html"><![CDATA[<h1 id="一，RNN"><a href="#一，RNN" class="headerlink" title="一，RNN"></a>一，RNN</h1><p><img src="/2025/02/08/RNN/%E7%BB%93%E6%9E%84.jpg"></p><ul><li>红色：输入层$(X_i)$</li><li>绿色：隐藏层$(h_i)$</li><li>蓝色：输出层$(Y_i)$</li></ul><h2 id="1-内核公式"><a href="#1-内核公式" class="headerlink" title="1. 内核公式"></a><strong>1. 内核公式</strong></h2><ul><li><strong>核心思想</strong>：每个时间步（time step）接收当前输入和前一时刻的隐藏状态，生成当前输出和新的隐藏状态。</li><li><strong>核心公式</strong>：看似是每个进行计算，其实还是基于矩阵的。</li></ul><p>$$<br>h_t &#x3D; \sigma(W_{xh} x_t + W_{hh} h_{t-1} + b_h)<br>$$</p>$$y_t = W_{hy} h_t + b_y$$<ul><li>$ h_t $: 当前时刻的隐藏状态</li><li>$ x_t $: 当前时刻的输入</li><li>$ y_t $: 当前时刻的输出</li><li>$ W_{xh}, W_{hh}, W_{hy} $: 权重矩阵</li><li>$ \sigma $: 激活函数（如tanh或ReLU）</li></ul><p>在RNN中，<strong>权重矩阵的格式</strong>（即维度）是由输入维度、隐藏状态维度和输出维度共同决定的。以下是具体说明。</p><hr><h2 id="2-权重矩阵的格式（维度）"><a href="#2-权重矩阵的格式（维度）" class="headerlink" title="2. 权重矩阵的格式（维度）"></a>2. 权重矩阵的格式（维度）</h2><p>假设：</p><ul><li>输入向量 $ x_t $ 的维度为 $ d $（即 $ x_t \in \mathbb{R}^d $）。</li><li>隐藏状态 $ h_t $ 的维度为 $ D $（即 $ h_t \in \mathbb{R}^D $）。</li><li>输出向量 $ y_t $ 的维度为 $ k $（即 $ y_t \in \mathbb{R}^k $）。</li></ul><p>那么，权重矩阵的格式如下：</p><h3 id="1-输入到隐藏层的权重矩阵-W-xh"><a href="#1-输入到隐藏层的权重矩阵-W-xh" class="headerlink" title="(1) 输入到隐藏层的权重矩阵 $ W_{xh} $"></a>(1) 输入到隐藏层的权重矩阵 $ W_{xh} $</h3><ul><li><strong>维度</strong>：$ D \times d $</li><li><strong>作用</strong>：将输入 $ x_t $ 从 $ d $ 维映射到隐藏层的 $ D $ 维空间。</li><li><strong>公式</strong>：<br>$$<br>W_{xh} \in \mathbb{R}^{D \times d}, \quad W_{xh} x_t \in \mathbb{R}^D<br>$$</li></ul><h3 id="2-隐藏层到隐藏层的权重矩阵-W-hh"><a href="#2-隐藏层到隐藏层的权重矩阵-W-hh" class="headerlink" title="(2) 隐藏层到隐藏层的权重矩阵 $ W_{hh} $"></a>(2) 隐藏层到隐藏层的权重矩阵 $ W_{hh} $</h3><ul><li><strong>维度</strong>：$ D \times D $</li><li><strong>作用</strong>：将前一步的隐藏状态 $ h_{t-1} $ 映射到当前隐藏状态 $ h_t $ 的空间。</li><li><strong>公式</strong>：<br>$$<br>W_{hh} \in \mathbb{R}^{D \times D}, \quad W_{hh} h_{t-1} \in \mathbb{R}^D<br>$$</li></ul><h3 id="3-隐藏层到输出层的权重矩阵-W-hy"><a href="#3-隐藏层到输出层的权重矩阵-W-hy" class="headerlink" title="(3) 隐藏层到输出层的权重矩阵 $ W_{hy} $"></a>(3) 隐藏层到输出层的权重矩阵 $ W_{hy} $</h3><ul><li><strong>维度</strong>：$ k \times D $</li><li><strong>作用</strong>：将隐藏状态 $ h_t $ 从 $ D $ 维映射到输出 $ y_t $ 的 $ k $ 维空间。</li><li><strong>公式</strong>：<br>$$<br>W_{hy} \in \mathbb{R}^{k \times D}, \quad W_{hy} h_t \in \mathbb{R}^k<br>$$</li></ul><h3 id="4-偏置向量-b-h-和-b-y"><a href="#4-偏置向量-b-h-和-b-y" class="headerlink" title="(4) 偏置向量 $ b_h $ 和 $ b_y $"></a>(4) 偏置向量 $ b_h $ 和 $ b_y $</h3><ul><li>**隐藏层偏置 $ b_h $**：维度为 $ D $（即 $ b_h \in \mathbb{R}^D $）。</li><li>**输出层偏置 $ b_y $**：维度为 $ k $（即 $ b_y \in \mathbb{R}^k $）。</li></ul><hr><h2 id="3-具体示例"><a href="#3-具体示例" class="headerlink" title="3. 具体示例"></a>3. 具体示例</h2><p>假设：</p><ul><li>输入维度 $ d &#x3D; 3 $（例如一个3维的词向量）。</li><li>隐藏层维度 $ D &#x3D; 5 $。</li><li>输出维度 $ k &#x3D; 2 $（例如二分类任务）。</li></ul><p>那么，权重矩阵的格式为：</p><ol><li>$ W_{xh} \in \mathbb{R}^{5 \times 3} $</li><li>$ W_{hh} \in \mathbb{R}^{5 \times 5} $</li><li>$ W_{hy} \in \mathbb{R}^{2 \times 5} $</li><li>$ b_h \in \mathbb{R}^5 $</li><li>$ b_y \in \mathbb{R}^2 $</li></ol><hr><h2 id="4-权重矩阵的初始化"><a href="#4-权重矩阵的初始化" class="headerlink" title="4. 权重矩阵的初始化"></a>4. 权重矩阵的初始化</h2><p>在实际训练中，权重矩阵通常通过以下方式初始化：</p><ul><li><strong>随机初始化</strong>：从均匀分布或正态分布中随机采样。</li><li><strong>Xavier初始化</strong>：适用于Sigmoid或Tanh激活函数，初始化范围为 $ \left[-\sqrt{\frac{6}{d + D}}, \sqrt{\frac{6}{d + D}}\right] $。</li><li><strong>He初始化</strong>：适用于ReLU激活函数，初始化范围为 $ \left[-\sqrt{\frac{6}{d}}, \sqrt{\frac{6}{d}}\right] $。</li></ul><hr><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><ul><li><strong>权重矩阵的格式</strong>由输入维度 $ d $、隐藏层维度 $ D $ 和输出维度 $ k $ 决定。</li><li>$ W_{xh} $：$ D \times d $</li><li>$ W_{hh} $：$ D \times D $</li><li>$ W_{hy} $：$ k \times D $</li><li><strong>偏置向量</strong>：$ b_h \in \mathbb{R}^D $，$ b_y \in \mathbb{R}^k $</li></ul><p>通过这种设计，RNN能够灵活地处理不同维度的输入、隐藏状态和输出，同时确保时间步 $ t $ 的计算流程一致。</p><h1 id="二，LSTM"><a href="#二，LSTM" class="headerlink" title="二，LSTM"></a>二，LSTM</h1><p><img src="/2025/02/08/RNN/RNN1.jpg" alt="传统RNN"><br><img src="/2025/02/08/RNN/LSTM1.jpg" alt="LSTM的改进"></p><p><strong>LSTM（Long Short-Term Memory，长短期记忆网络）</strong> 是一种特殊的循环神经网络（RNN），专门设计用来解决传统RNN在处理长序列数据时的<strong>梯度消失</strong>和<strong>长程依赖</strong>问题。LSTM通过引入<strong>门控机制</strong>和<strong>记忆单元</strong>，能够有效地捕捉序列数据中的长期依赖关系，广泛应用于自然语言处理、语音识别、时间序列预测等领域。</p><hr><h2 id="1-LSTM的核心思想"><a href="#1-LSTM的核心思想" class="headerlink" title="1. LSTM的核心思想"></a><strong>1. LSTM的核心思想</strong></h2><p>LSTM的核心是<strong>记忆单元（Cell State）</strong>和<strong>门控机制</strong>。记忆单元负责保存长期信息，而门控机制（输入门、遗忘门、输出门）则控制信息的流动，决定哪些信息需要保留、哪些需要丢弃。</p><hr><h2 id="2-LSTM的结构"><a href="#2-LSTM的结构" class="headerlink" title="2. LSTM的结构"></a><strong>2. LSTM的结构</strong></h2><p><img src="/2025/02/08/RNN/LSTM.jpg"><br>$ \odot $ 表示逐元素相乘（Hadamard积），LSTM的每个时间步包含以下关键组件：</p><h3 id="1-记忆单元（Cell-State）"><a href="#1-记忆单元（Cell-State）" class="headerlink" title="(1) 记忆单元（Cell State）"></a><strong>(1) 记忆单元（Cell State）</strong></h3><ul><li>记忆单元 $ C_t $ 是LSTM的核心，负责保存长期信息。</li><li>它在时间步之间传递，并通过门控机制更新。</li></ul><h3 id="2-遗忘门（Forget-Gate）"><a href="#2-遗忘门（Forget-Gate）" class="headerlink" title="(2) 遗忘门（Forget Gate）"></a><strong>(2) 遗忘门（Forget Gate）</strong></h3><ul><li>决定从记忆单元中丢弃哪些信息。</li><li>公式：<br>$$<br>f_t &#x3D; \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)<br>$$<ul><li>$ f_t $ 是遗忘门的输出（范围在0到1之间）。</li><li>$ W_f $ 是权重矩阵，$ b_f $ 是偏置。</li><li>$ \sigma $ 是Sigmoid激活函数。</li></ul></li></ul><h3 id="3-输入门（Input-Gate）"><a href="#3-输入门（Input-Gate）" class="headerlink" title="(3) 输入门（Input Gate）"></a><strong>(3) 输入门（Input Gate）</strong></h3><ul><li>决定哪些新信息需要存储到记忆单元中。</li><li>公式：<br>$$<br>i_t &#x3D; \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)<br>$$  $$  g_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)  $$  <ul><li>$ i_t $ 是输入门的输出。</li><li>$ g_t $ 是候选记忆单元值。</li></ul></li></ul><h3 id="4-更新记忆单元"><a href="#4-更新记忆单元" class="headerlink" title="(4) 更新记忆单元"></a><strong>(4) 更新记忆单元</strong></h3><ul><li>结合遗忘门和输入门的信息，更新记忆单元：<br>$$<br>C_t &#x3D; f_t \odot C_{t-1} + i_t \odot g_t<br>$$<ul><li>$ \odot $ 表示逐元素相乘（Hadamard积）。</li></ul></li></ul><h3 id="5-输出门（Output-Gate）"><a href="#5-输出门（Output-Gate）" class="headerlink" title="(5) 输出门（Output Gate）"></a><strong>(5) 输出门（Output Gate）</strong></h3><ul><li>决定从记忆单元中输出哪些信息到隐藏状态。</li><li>公式：<br>$$<br>o_t &#x3D; \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)<br>$$  $$  h_t = o_t \odot \tanh(C_t)  $$  <ul><li>$ o_t $ 是输出门的输出。</li><li>$ h_t $ 是当前时间步的隐藏状态。</li></ul></li></ul><hr><h2 id="3-LSTM的工作流程"><a href="#3-LSTM的工作流程" class="headerlink" title="3. LSTM的工作流程"></a><strong>3. LSTM的工作流程</strong></h2><ol><li><strong>遗忘门</strong>决定从记忆单元中丢弃哪些信息。</li><li><strong>输入门</strong>决定将哪些新信息存储到记忆单元中。</li><li><strong>更新记忆单元</strong>，结合遗忘门和输入门的信息。</li><li><strong>输出门</strong>决定从记忆单元中输出哪些信息到隐藏状态。</li><li><strong>隐藏状态</strong> $ h_t $ 作为当前时间步的输出，并传递到下一个时间步。</li></ol><h2 id="4-生成输出-y-t-的公式"><a href="#4-生成输出-y-t-的公式" class="headerlink" title="4.生成输出 $ y_t $ 的公式"></a><strong>4.生成输出 $ y_t $ 的公式</strong></h2><ol><li><p><strong>线性变换</strong>：<br>$$<br>y_t &#x3D; W_{hy} \cdot h_t + b_y<br>$$</p><ul><li>$ W_{hy} \in \mathbb{R}^{k \times D} $: 输出层权重矩阵（$ k $ 是输出维度，$ D $ 是隐藏状态维度）。</li><li>$ b_y \in \mathbb{R}^k $: 输出层偏置。</li><li>$ h_t \in \mathbb{R}^D $: 当前时间步的隐藏状态。</li></ul></li><li><p><strong>激活函数（根据任务选择）</strong>：</p><ul><li><strong>分类任务（Softmax）</strong>：<br>$$<br>y_t &#x3D; \text{Softmax}(W_{hy} \cdot h_t + b_y)<br>$$</li><li><strong>二分类任务（Sigmoid）</strong>：<br>$$<br>y_t &#x3D; \sigma(W_{hy} \cdot h_t + b_y)<br>$$</li><li><strong>回归任务（线性激活）</strong>：<br>$$<br>y_t &#x3D; W_{hy} \cdot h_t + b_y<br>$$</li></ul></li></ol><h1 id="三，pytorch实现LSTM"><a href="#三，pytorch实现LSTM" class="headerlink" title="三，pytorch实现LSTM"></a>三，pytorch实现LSTM</h1><ul><li><p>因为RNN的效果和LSTM相差较大，因此这里只放LSTM的，将网络结构定义改变即可实现RNN。</p></li><li><p>词汇表和词嵌入映射均下载在本地。</p></li><li><p>数据为评论+类别，任务是10分类。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 加载 npz 文件</span><br>npz = np.load(<span class="hljs-string">&quot;C:\\Users\jimes\PycharmProjects\课程\PyTorch框架(2022重录)\第七章：LSTM文本分类实战\\text\THUCNews\data\embedding_Tencent.npz&quot;</span>)<br><span class="hljs-comment">#print(len(npz[&#x27;embeddings&#x27;]))  # 输出文件中包含的数组名称</span><br><span class="hljs-comment"># 打开文件并读取词汇表</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\jimes\\PycharmProjects\\课程\\PyTorch框架(2022重录)\\第七章：LSTM文本分类实战\\text\THUCNews\data\\vocab.pkl&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    vocab = pickle.load(file)<br><br><span class="hljs-comment"># 数据预加载</span><br>train_dataset = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./data/train.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        line = file.readline()  <span class="hljs-comment"># 使用readline()逐行读取</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> line:  <span class="hljs-comment"># 如果读到文件末尾，line为空字符串，退出循环</span><br>            <span class="hljs-keyword">break</span><br>        columns = line.strip().split(<span class="hljs-string">&quot;\t&quot;</span>)  <span class="hljs-comment"># 使用strip()去除首尾空白字符，然后按Tab分割</span><br>        train_dataset.append(columns)<br>test_dataset = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./data/dev.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        line = file.readline()  <span class="hljs-comment"># 使用readline()逐行读取</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> line:  <span class="hljs-comment"># 如果读到文件末尾，line为空字符串，退出循环</span><br>            <span class="hljs-keyword">break</span><br>        columns = line.strip().split(<span class="hljs-string">&quot;\t&quot;</span>)  <span class="hljs-comment"># 使用strip()去除首尾空白字符，然后按Tab分割</span><br>        test_dataset.append(columns)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(train_dataset)):<br>    ind1 = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">25</span>): <span class="hljs-comment"># 文字最大长度</span><br>        <span class="hljs-keyword">try</span>:<br>            ind1.append(vocab[train_dataset[i][<span class="hljs-number">0</span>][j]])<br>        <span class="hljs-keyword">except</span> KeyError:<br>            ind1.append(vocab[<span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span>])<br>        <span class="hljs-keyword">except</span> IndexError:<br>            ind1.append(vocab[<span class="hljs-string">&#x27;&lt;PAD&gt;&#x27;</span>])<br>    train_dataset[i][<span class="hljs-number">0</span>] = ind1<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(test_dataset)):<br>    ind2 = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">25</span>):  <span class="hljs-comment"># 文字最大长度</span><br>        <span class="hljs-keyword">try</span>:<br>            ind2.append(vocab[test_dataset[i][<span class="hljs-number">0</span>][j]])<br>        <span class="hljs-keyword">except</span> KeyError:<br>            ind2.append(vocab[<span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span>])<br>        <span class="hljs-keyword">except</span> IndexError:<br>            ind2.append(vocab[<span class="hljs-string">&#x27;&lt;PAD&gt;&#x27;</span>])<br>    test_dataset[i][<span class="hljs-number">0</span>] = ind2<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化数据集</span><br><span class="hljs-string">        data: 原始数据集，格式为 [[features, label], ...]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.data = data<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment">#返回数据集的大小</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        根据索引返回一个样本及其标签</span><br><span class="hljs-string">        idx: 样本索引</span><br><span class="hljs-string">        return: (features, label)</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        features, label = self.data[idx]<br>        <span class="hljs-comment"># 将 features 转换为 Tensor</span><br>        features = torch.tensor(features, dtype=torch.long)<br>        <span class="hljs-comment"># 将标签转换为 Tensor（假设标签是整数）</span><br>        label = torch.tensor(<span class="hljs-built_in">int</span>(label), dtype=torch.long)<br>        <span class="hljs-keyword">return</span> features, label<br>train_dataset = CustomDataset(train_dataset)<br>test_dataset = CustomDataset(test_dataset)<br><span class="hljs-comment"># 创建DataLoader</span><br>train_loader = DataLoader(<br>    train_dataset,<br>    batch_size=<span class="hljs-number">8</span>,<br>    shuffle=<span class="hljs-literal">False</span>)<br>test_loader = DataLoader(<br>    test_dataset,<br>    batch_size=<span class="hljs-number">8</span>,<br>    shuffle=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 词嵌入二维列表</span><br>embedding_matrix = torch.tensor(npz[<span class="hljs-string">&#x27;embeddings&#x27;</span>], dtype=torch.<span class="hljs-built_in">float</span>)<br><span class="hljs-comment"># 检查词嵌入的维度</span><br>vocab_size, embedding_dim = embedding_matrix.shape<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;词汇表大小: <span class="hljs-subst">&#123;vocab_size&#125;</span>, 词嵌入维度: <span class="hljs-subst">&#123;embedding_dim&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 定义RNN模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleLSTM</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers,  pad_idx, embedding_matrix=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化 RNN 网络</span><br><span class="hljs-string">        vocab_size: 词汇表大小</span><br><span class="hljs-string">        embedding_dim: 词嵌入维度</span><br><span class="hljs-string">        hidden_dim:  隐藏层维度</span><br><span class="hljs-string">        output_dim: 输出维度（类别数）</span><br><span class="hljs-string">        pad_idx: &lt;PAD&gt; 的索引</span><br><span class="hljs-string">        embedding_matrix: 预训练的词嵌入矩阵（可选）</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(SimpleLSTM, self).__init__()<br>        <span class="hljs-comment"># 词嵌入层</span><br>        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)<br>        <span class="hljs-keyword">if</span> embedding_matrix <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.embedding.weight = nn.Parameter(embedding_matrix, requires_grad=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 使用预训练的词嵌入</span><br>        <span class="hljs-comment"># LSTM 层</span><br>        self.hidden_size = hidden_dim<br>        self.num_layers = num_layers<br>        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 全连接层</span><br>        self.fc = nn.Linear(hidden_dim, output_dim)<br>        <span class="hljs-comment"># 激活函数</span><br>        self.softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        前向传播</span><br><span class="hljs-string">        x: 输入的序列数据，形状为 [batch_size, seq_len]</span><br><span class="hljs-string">        return: 输出的类别概率</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 将输入索引转换为嵌入向量</span><br>        x = self.embedding(x)  <span class="hljs-comment"># (batch_size, sequence_length) -&gt; (batch_size, sequence_length, embed_size)</span><br>        <span class="hljs-comment"># 初始化隐藏状态和细胞状态</span><br>        h0 = torch.zeros(self.num_layers, x.size(<span class="hljs-number">0</span>), self.hidden_size).to(x.device)<br>        c0 = torch.zeros(self.num_layers, x.size(<span class="hljs-number">0</span>), self.hidden_size).to(x.device)<br>        <span class="hljs-comment"># 前向传播LSTM</span><br>        _, (hidden, _) = self.lstm(x, (h0, c0))  <span class="hljs-comment"># hidden: (batch_size, sequence_length, hidden_size)</span><br>        <span class="hljs-comment"># 使用 LSTM 的最后一个隐藏状态</span><br>        hidden = hidden[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># [batch_size, hidden_dim]</span><br>        <span class="hljs-comment"># 全连接层</span><br>        output = self.fc(hidden)  <span class="hljs-comment"># [batch_size, output_dim]</span><br>        <span class="hljs-comment"># 激活函数</span><br>        <span class="hljs-keyword">return</span> self.softmax(output)<br><br><span class="hljs-comment"># 超参数</span><br>vocab_size = <span class="hljs-number">4762</span>  <span class="hljs-comment"># 词汇表大小</span><br>embedding_dim = <span class="hljs-number">200</span>  <span class="hljs-comment"># 词嵌入维度</span><br>hidden_dim = <span class="hljs-number">128</span>  <span class="hljs-comment">#  隐藏层维度</span><br>num_layers = <span class="hljs-number">2</span>   <span class="hljs-comment"># LSTM的层数</span><br>output_dim = <span class="hljs-number">10</span>  <span class="hljs-comment"># 输出类别数</span><br>pad_idx = <span class="hljs-number">4761</span>  <span class="hljs-comment"># &lt;PAD&gt; 的索引</span><br><span class="hljs-comment">#embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True) # 词嵌入不变</span><br><span class="hljs-comment"># 初始化模型</span><br>model = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, output_dim,num_layers, pad_idx, embedding_matrix)<br><br><span class="hljs-comment"># 定义损失函数和优化器</span><br>criterion = nn.NLLLoss()<br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br><br><span class="hljs-comment"># 训练模型</span><br>num_epochs = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_epochs)):<br>    model.train()<br>    total_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> train_loader:<br>        optimizer.zero_grad()<br>        outputs = model(inputs)  <span class="hljs-comment"># 实际对应forward函数</span><br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br>        total_loss += loss.item()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch [<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>], Loss: <span class="hljs-subst">&#123;total_loss/<span class="hljs-built_in">len</span>(train_loader):<span class="hljs-number">.4</span>f&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 测试网络</span><br>model.<span class="hljs-built_in">eval</span>()<br>correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> test_loader:<br>        outputs = model(inputs)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy of the network on the 10000 test: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * correct / total:<span class="hljs-number">.2</span>f&#125;</span>%&#x27;</span>)<br><br><span class="hljs-comment"># 保存模型</span><br>torch.save(model.state_dict(), <span class="hljs-string">&quot;LSTM_model.pth&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 加载 npz 文件</span><br>npz = np.load(<span class="hljs-string">&quot;C:\\Users\jimes\PycharmProjects\课程\PyTorch框架(2022重录)\第七章：LSTM文本分类实战\\text\THUCNews\data\embedding_Tencent.npz&quot;</span>)<br><span class="hljs-comment">#print(len(npz[&#x27;embeddings&#x27;]))  # 输出文件中包含的数组名称</span><br><span class="hljs-comment"># 打开文件并读取词汇表</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;C:\\Users\\jimes\\PycharmProjects\\课程\\PyTorch框架(2022重录)\\第七章：LSTM文本分类实战\\text\THUCNews\data\\vocab.pkl&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    vocab = pickle.load(file)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleLSTM</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers,  pad_idx, embedding_matrix=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化 RNN 网络</span><br><span class="hljs-string">        vocab_size: 词汇表大小</span><br><span class="hljs-string">        embedding_dim: 词嵌入维度</span><br><span class="hljs-string">        hidden_dim:  隐藏层维度</span><br><span class="hljs-string">        output_dim: 输出维度（类别数）</span><br><span class="hljs-string">        pad_idx: &lt;PAD&gt; 的索引</span><br><span class="hljs-string">        embedding_matrix: 预训练的词嵌入矩阵（可选）</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(SimpleLSTM, self).__init__()<br>        <span class="hljs-comment"># 词嵌入层</span><br>        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)<br>        <span class="hljs-keyword">if</span> embedding_matrix <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.embedding.weight = nn.Parameter(embedding_matrix, requires_grad=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 使用预训练的词嵌入</span><br>        <span class="hljs-comment"># LSTM 层</span><br>        self.hidden_size = hidden_dim<br>        self.num_layers = num_layers<br>        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 全连接层</span><br>        self.fc = nn.Linear(hidden_dim, output_dim)<br>        <span class="hljs-comment"># 激活函数</span><br>        self.softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        前向传播</span><br><span class="hljs-string">        x: 输入的序列数据，形状为 [batch_size, seq_len]</span><br><span class="hljs-string">        return: 输出的类别概率</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 将输入索引转换为嵌入向量</span><br>        x = self.embedding(x)  <span class="hljs-comment"># (batch_size, sequence_length) -&gt; (batch_size, sequence_length, embed_size)</span><br>        <span class="hljs-comment"># 初始化隐藏状态和细胞状态</span><br>        h0 = torch.zeros(self.num_layers, x.size(<span class="hljs-number">0</span>), self.hidden_size).to(x.device)<br>        c0 = torch.zeros(self.num_layers, x.size(<span class="hljs-number">0</span>), self.hidden_size).to(x.device)<br>        <span class="hljs-comment"># 前向传播LSTM</span><br>        _, (hidden, _) = self.lstm(x, (h0, c0))  <span class="hljs-comment"># hidden: (batch_size, sequence_length, hidden_size)</span><br>        <span class="hljs-comment"># 使用 LSTM 的最后一个隐藏状态</span><br>        hidden = hidden[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># [batch_size, hidden_dim]</span><br>        <span class="hljs-comment"># 全连接层</span><br>        output = self.fc(hidden)  <span class="hljs-comment"># [batch_size, output_dim]</span><br>        <span class="hljs-comment"># 激活函数</span><br>        <span class="hljs-keyword">return</span> self.softmax(output)<br><br><span class="hljs-comment"># 超参数</span><br>vocab_size = <span class="hljs-number">4762</span>  <span class="hljs-comment"># 词汇表大小</span><br>embedding_dim = <span class="hljs-number">200</span>  <span class="hljs-comment"># 词嵌入维度</span><br>hidden_dim = <span class="hljs-number">128</span>  <span class="hljs-comment"># RNN 隐藏层维度</span><br>num_layers = <span class="hljs-number">2</span>   <span class="hljs-comment"># RNN层数</span><br>output_dim = <span class="hljs-number">10</span>  <span class="hljs-comment"># 输出类别数</span><br>pad_idx = <span class="hljs-number">4761</span>  <span class="hljs-comment"># &lt;PAD&gt; 的索引</span><br><span class="hljs-comment"># 词嵌入二维列表</span><br>embedding_matrix = torch.tensor(npz[<span class="hljs-string">&#x27;embeddings&#x27;</span>], dtype=torch.<span class="hljs-built_in">float</span>)<br><span class="hljs-comment"># 检查词嵌入的维度</span><br>vocab_size, embedding_dim = embedding_matrix.shape<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;词汇表大小: <span class="hljs-subst">&#123;vocab_size&#125;</span>, 词嵌入维度: <span class="hljs-subst">&#123;embedding_dim&#125;</span>&quot;</span>)<br><span class="hljs-comment"># 加载模型参数</span><br>model = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, pad_idx, embedding_matrix)<br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;LSTM_model.pth&#x27;</span>))<br><span class="hljs-comment"># 将模型设置为评估模式</span><br>model.<span class="hljs-built_in">eval</span>()<br>xx = <span class="hljs-string">&#x27;在教育界会有一些新的教育方式&#x27;</span><br>categories = [<br>    <span class="hljs-string">&quot;finance&quot;</span>,<br>    <span class="hljs-string">&quot;realty&quot;</span>,<br>    <span class="hljs-string">&quot;stocks&quot;</span>,<br>    <span class="hljs-string">&quot;education&quot;</span>,<br>    <span class="hljs-string">&quot;science&quot;</span>,<br>    <span class="hljs-string">&quot;society&quot;</span>,<br>    <span class="hljs-string">&quot;politics&quot;</span>,<br>    <span class="hljs-string">&quot;sports&quot;</span>,<br>    <span class="hljs-string">&quot;game&quot;</span>,<br>    <span class="hljs-string">&quot;entertainment&quot;</span>]<br>x = []<br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">25</span>):<br>    <span class="hljs-keyword">try</span>:<br>        x.append(vocab[xx[j]])<br>    <span class="hljs-keyword">except</span> KeyError:<br>        x.append(vocab[<span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span>])<br>    <span class="hljs-keyword">except</span> IndexError:<br>        x.append(vocab[<span class="hljs-string">&#x27;&lt;PAD&gt;&#x27;</span>])<br><span class="hljs-comment"># 预测</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = model(torch.tensor(x).unsqueeze(<span class="hljs-number">0</span>))<br>    _, predicted = torch.<span class="hljs-built_in">max</span>(output, <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Predicted class: <span class="hljs-subst">&#123;categories[predicted.item()]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch数据集与数据预处理</title>
    <link href="/2025/01/26/pytorch%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <url>/2025/01/26/pytorch%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="一-PyTorch-内置数据集"><a href="#一-PyTorch-内置数据集" class="headerlink" title="一. PyTorch 内置数据集"></a>一. PyTorch 内置数据集</h1><p>PyTorch 通过 <code>torchvision.datasets</code> 模块提供了许多常用的数据集，例如：</p><ul><li><code>MNIST</code>：手写数字图像数据集，用于图像分类任务。</li><li><code>CIFAR</code>：包含 10 个类别、60000 张 32x32 的彩色图像数据集，用于图像分类任务。</li><li><code>COCO</code>：通用物体检测、分割、关键点检测数据集，包含超过 330k 个图像和 2.5M 个目标实例的大规模数据集。</li><li><code>ImageNet</code>：包含超过 1400 万张图像，用于图像分类和物体检测等任务。</li><li><code>STL-10</code>：包含 100k 张 96x96 的彩色图像数据集，用于图像分类任务。</li><li><code>Cityscapes</code>：包含 5000 张精细注释的城市街道场景图像，用于语义分割任务。</li><li><code>SQUAD</code>：用于机器阅读理解任务的数据集。</li></ul><p>以上数据集可以通过 <code>torchvision.datasets</code> 模块中的函数进行加载，也可以通过自定义的方式加载其他数据集。</p><ul><li><code>torchvision</code>： 一个图形库，提供了图片数据处理相关的 API 和数据集接口，包括数据集加载函数和常用的图像变换。</li><li><code>torchtext</code>： 自然语言处理工具包，提供了文本数据处理和建模的工具，包括数据预处理和数据加载的方式。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><br>train_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,                      <span class="hljs-comment"># 数据存储路径</span><br>    train=<span class="hljs-literal">True</span>,                    <span class="hljs-comment"># 训练集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 关闭下载</span><br>    transform=transform            <span class="hljs-comment"># 应用预处理</span><br>)<br><br>test_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,<br>    train=<span class="hljs-literal">False</span>,                   <span class="hljs-comment"># 测试集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 关闭下载</span><br>    transform=transform<br>)<br></code></pre></td></tr></table></figure><h1 id="二-定义数据集"><a href="#二-定义数据集" class="headerlink" title="二. 定义数据集"></a>二. 定义数据集</h1><h2 id="1-torch-utils-data-Dataset"><a href="#1-torch-utils-data-Dataset" class="headerlink" title="1. torch.utils.data.Dataset"></a>1. <code>torch.utils.data.Dataset</code></h2><ul><li><strong>作用</strong>：定义数据集的统一接口，需继承并实现关键方法。</li><li><strong>功能</strong>：<ul><li><code>__len__(self)</code>: 返回数据集的总样本数。</li><li><code>__getitem__(self, idx)</code>: 根据索引 <code>idx</code> 返回单个样本（数据 + 标签）。</li></ul></li><li>适用场景<ul><li>处理自定义格式数据（如非标准文件结构）。</li><li>需要复杂的数据预处理逻辑（如动态生成数据）。</li></ul></li><li>代码示例</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><span class="hljs-comment"># 自定义数据集类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, X_data, Y_data</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化数据集，X_data 和 Y_data 是两个列表或数组</span><br><span class="hljs-string">        X_data: 输入特征</span><br><span class="hljs-string">        Y_data: 目标标签</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.X_data = X_data<br>        self.Y_data = Y_data<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;返回数据集的大小&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.X_data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;返回指定索引的数据&quot;&quot;&quot;</span><br>        x = torch.tensor(self.X_data[idx], dtype=torch.float32)  <span class="hljs-comment"># 转换为 Tensor</span><br>        y = torch.tensor(self.Y_data[idx], dtype=torch.float32)<br>        <span class="hljs-keyword">return</span> x, y<br><br><span class="hljs-comment"># 示例数据</span><br>X_data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]  <span class="hljs-comment"># 输入特征</span><br>Y_data = [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment"># 目标标签</span><br><br><span class="hljs-comment"># 创建数据集实例</span><br>dataset = MyDataset(X_data, Y_data)<br></code></pre></td></tr></table></figure><h2 id="2-torch-utils-data-TensorDataset"><a href="#2-torch-utils-data-TensorDataset" class="headerlink" title="2. torch.utils.data.TensorDataset"></a>2. <code>torch.utils.data.TensorDataset</code></h2><ul><li><strong>作用</strong>：基于张量（Tensor）的数据集类，适合处理数据-标签对。</li><li><strong>功能</strong>：<ul><li>它接受多个张量作为输入（通常是数据和标签），并将它们组合成一个数据集。</li><li>直接支持批处理和迭代。</li></ul></li><li>适用场景<ul><li>处理自定义格式数据（如非标准文件结构）。</li><li>需要复杂的数据预处理逻辑（如动态生成数据）。</li></ul></li><li>代码示例</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset<br><br>data = torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">3</span>)  <span class="hljs-comment"># 100个样本，每个样本有3个特征</span><br>labels = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">100</span>,))  <span class="hljs-comment"># 100个标签，0或1</span><br>dataset = TensorDataset(data, labels)<br></code></pre></td></tr></table></figure><h1 id="三-加载数据集"><a href="#三-加载数据集" class="headerlink" title="三. 加载数据集"></a>三. 加载数据集</h1><h2 id="1-torch-utils-data-DataLoader"><a href="#1-torch-utils-data-DataLoader" class="headerlink" title="1. torch.utils.data.DataLoader"></a>1. <code>torch.utils.data.DataLoader</code></h2><ul><li><strong>作用</strong>：一个数据加载器，用于封装 Dataset 并提供高效的迭代功能。</li><li><strong>功能</strong>：<ul><li>支持<strong>批处理</strong>（batch_size）：将数据集分成小批量。</li><li>支持数据打乱（shuffle）：在每个 epoch 开始时打乱数据顺序。</li><li>支持多线程加载（num_workers）：加速数据加载过程。</li><li>drop_last：如果数据集中的样本数不能被 batch_size 整除，设置为 True 时，丢弃最后一个不完整的 batch。</li></ul></li><li>适用场景<ul><li>在训练模型时，通常会将 Dataset 传递给 DataLoader，以便高效地加载数据。</li></ul></li><li>代码示例</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-comment"># 创建 DataLoader 实例，batch_size 设置每次加载的样本数量</span><br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">2</span>, shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 打印加载的数据</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>    <span class="hljs-keyword">for</span> batch_idx, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Batch <span class="hljs-subst">&#123;batch_idx + <span class="hljs-number">1</span>&#125;</span>:&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Inputs: <span class="hljs-subst">&#123;inputs&#125;</span>&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Labels: <span class="hljs-subst">&#123;labels&#125;</span>&#x27;</span>)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">输出：</span><br><span class="hljs-string">Batch 1:</span><br><span class="hljs-string">Inputs: tensor([[3., 4.], [1., 2.]])</span><br><span class="hljs-string">Labels: tensor([0., 1.])</span><br><span class="hljs-string">Batch 2:</span><br><span class="hljs-string">Inputs: tensor([[7., 8.], [5., 6.]])</span><br><span class="hljs-string">Labels: tensor([0., 1.])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h2 id="2-torchvision-datasets-ImageFolder"><a href="#2-torchvision-datasets-ImageFolder" class="headerlink" title="2. torchvision.datasets.ImageFolder"></a>2. <code>torchvision.datasets.ImageFolder</code></h2><ul><li><strong>作用</strong>：这是一个专门用于加载图像数据的数据集类，适用于图像分类任务。</li><li><strong>功能</strong>：<ul><li>从文件夹中加载图像数据，每个子文件夹代表一个类别。</li><li>自动为每个图像分配标签（根据子文件夹名称）。</li><li>支持数据预处理（通过 transform 参数）。</li></ul></li><li>适用场景<ul><li>当你的图像数据按类别存储在文件夹中时，可以直接使用 ImageFolder。</li></ul></li><li>代码示例</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> ImageFolder<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br>transform = transforms.Compose([<br>    transforms.Resize((<span class="hljs-number">64</span>, <span class="hljs-number">64</span>)),<br>    transforms.ToTensor(),<br>])<br><br>dataset = ImageFolder(root=<span class="hljs-string">&#x27;path/to/image/folder&#x27;</span>, transform=transform)<br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="3-验证"><a href="#3-验证" class="headerlink" title="3. 验证"></a>3. 验证</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 检查 train_loader 的输出格式</span><br><span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> train_loader:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input shape:&quot;</span>, inputs.shape)  <span class="hljs-comment"># 应该是 [batch_size, seq_len]</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Label shape:&quot;</span>, labels.shape)  <span class="hljs-comment"># 应该是 [batch_size]</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input type:&quot;</span>, <span class="hljs-built_in">type</span>(inputs))   <span class="hljs-comment"># 应该是 &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Label type:&quot;</span>, <span class="hljs-built_in">type</span>(labels))   <span class="hljs-comment"># 应该是 &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h1 id="四-数据预处理"><a href="#四-数据预处理" class="headerlink" title="四. 数据预处理"></a>四. 数据预处理</h1><ul><li><code>transforms.Compose()</code>：将多个变换操作组合在一起。</li><li><code>transforms.Resize(size)</code>：调整图像大小。</li><li><code>transforms.ToTensor()</code>：将图像转换为 PyTorch 张量，值会被归一化到 [0, 1] 范围。</li><li><code>transforms.Normalize(mean, std)</code>：标准化图像数据，通常使用预训练模型时需要进行标准化处理。</li><li><code>transforms.CenterCrop(size)</code>：从图像中心裁剪指定大小的区域。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br><span class="hljs-comment"># 定义数据预处理的流水线</span><br>transform = transforms.Compose([<br>    transforms.Resize((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>)),  <span class="hljs-comment"># 将图像调整为 128x128</span><br>    transforms.ToTensor(),  <span class="hljs-comment"># 将图像转换为张量</span><br>    transforms.Normalize(mean=[<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], std=[<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])  <span class="hljs-comment"># 标准化</span><br>    transform = transforms.CenterCrop(<span class="hljs-number">128</span>)  <span class="hljs-comment"># 128*128的区域</span><br>])<br><br><span class="hljs-comment"># 加载图像</span><br>image = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;image.jpg&#x27;</span>)<br><br><span class="hljs-comment"># 应用预处理</span><br>image_tensor = transform(image)<br><span class="hljs-built_in">print</span>(image_tensor.shape)  <span class="hljs-comment"># 输出张量的形状</span><br></code></pre></td></tr></table></figure><h1 id="五-图像数据增强"><a href="#五-图像数据增强" class="headerlink" title="五. 图像数据增强"></a>五. 图像数据增强</h1><ul><li><code>transforms.RandomHorizontalFlip(p)</code>：随机水平翻转图像。</li><li><code>transforms.RandomRotation(degrees)</code>：随机旋转图像。</li><li><code>transforms.ColorJitter(brightness, contrast, saturation, hue)</code>：调整图像的亮度、对比度、饱和度和色调。</li><li><code>transforms.RandomCrop(size)</code>：随机裁剪指定大小的区域。</li><li><code>transforms.RandomResizedCrop(size)</code>：随机裁剪图像并调整到指定大小。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose([<br>    transform = transforms.RandomHorizontalFlip(p=<span class="hljs-number">0.5</span>),  <span class="hljs-comment"># 50% 概率翻转</span><br>    transform = transforms.RandomRotation(degrees=<span class="hljs-number">30</span>),  <span class="hljs-comment"># 随机旋转 -30 到 +30 度</span><br>    transform = transforms.ColorJitter(brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0.5</span>),<br>    transform = transforms.RandomCrop(<span class="hljs-number">128</span>),<br>    transform = transforms.RandomResizedCrop(<span class="hljs-number">224</span>)<br>])<br></code></pre></td></tr></table></figure><h1 id="六-用多个数据源（Multi-source-Dataset）"><a href="#六-用多个数据源（Multi-source-Dataset）" class="headerlink" title="六. 用多个数据源（Multi-source Dataset）"></a>六. 用多个数据源（Multi-source Dataset）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> ConcatDataset<br><br><span class="hljs-comment"># 假设 dataset1 和 dataset2 是两个 Dataset 对象</span><br>combined_dataset = ConcatDataset([dataset1, dataset2])<br>combined_loader = DataLoader(combined_dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h1 id="七-实例–加载MNIST-数据集，并应用转换。"><a href="#七-实例–加载MNIST-数据集，并应用转换。" class="headerlink" title="七. 实例–加载MNIST 数据集，并应用转换。"></a>七. 实例–加载MNIST 数据集，并应用转换。</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-comment"># 定义转换</span><br>transform = transforms.Compose([<br>    transforms.Resize((<span class="hljs-number">128</span>, <span class="hljs-number">128</span>)),<br>    transforms.ToTensor(),<br>    transforms.Normalize(mean=[<span class="hljs-number">0.5</span>], std=[<span class="hljs-number">0.5</span>])<br>])<br><br><span class="hljs-comment"># 加载数据集</span><br>train_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>, transform=transform, download=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 使用 DataLoader</span><br>train_loader = DataLoader(dataset=train_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 查看转换后的数据</span><br><span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> train_loader:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;图像张量大小:&quot;</span>, images.size())  <span class="hljs-comment"># [batch_size, 1, 128, 128]</span><br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">图像张量大小: torch.Size([<span class="hljs-number">32</span>, <span class="hljs-number">1</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基础--torch</title>
    <link href="/2025/01/26/pytorch%E7%9A%84torch/"/>
    <url>/2025/01/26/pytorch%E7%9A%84torch/</url>
    
    <content type="html"><![CDATA[<h1 id="PyTorch-的-torch-模块"><a href="#PyTorch-的-torch-模块" class="headerlink" title="PyTorch 的 torch 模块"></a>PyTorch 的 <code>torch</code> 模块</h1><p><code>torch</code> 是 PyTorch 的核心模块，提供了张量操作、数学运算、设备管理等功能。以下是其主要类和功能的详细介绍。</p><hr><h2 id="1-张量操作（Tensor-Operations）"><a href="#1-张量操作（Tensor-Operations）" class="headerlink" title="1. 张量操作（Tensor Operations）"></a>1. 张量操作（Tensor Operations）</h2><p><code>torch</code> 提供了丰富的张量操作函数，用于创建、操作和转换张量。</p><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><table><thead><tr><th>函数名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.tensor()</code></td><td>创建张量。</td></tr><tr><td><code>torch.zeros()</code></td><td>创建全零张量。</td></tr><tr><td><code>torch.ones()</code></td><td>创建全一张量。</td></tr><tr><td><code>torch.rand()</code></td><td>创建均匀分布随机张量。</td></tr><tr><td><code>torch.randn()</code></td><td>创建标准正态分布随机张量。</td></tr><tr><td><code>torch.arange()</code></td><td>创建等差序列张量。</td></tr><tr><td><code>torch.linspace()</code></td><td>创建等间隔序列张量。</td></tr><tr><td><code>torch.eye()</code></td><td>创建单位矩阵。</td></tr><tr><td><code>torch.cat()</code></td><td>沿指定维度拼接张量。</td></tr><tr><td><code>torch.stack()</code></td><td>沿新维度堆叠张量。</td></tr><tr><td><code>torch.split()</code></td><td>将张量分割为多个子张量。</td></tr><tr><td><code>torch.reshape()</code></td><td>改变张量形状。</td></tr><tr><td><code>torch.transpose()</code></td><td>转置张量。</td></tr><tr><td><code>torch.matmul()</code></td><td>矩阵乘法。</td></tr><tr><td><code>torch.sum()</code></td><td>计算张量元素和。</td></tr><tr><td><code>torch.mean()</code></td><td>计算张量元素均值。</td></tr><tr><td><code>torch.max()</code></td><td>计算张量元素最大值。</td></tr><tr><td><code>torch.min()</code></td><td>计算张量元素最小值。</td></tr></tbody></table><hr><h2 id="2-数学运算（Mathematical-Operations）"><a href="#2-数学运算（Mathematical-Operations）" class="headerlink" title="2. 数学运算（Mathematical Operations）"></a>2. 数学运算（Mathematical Operations）</h2><p><code>torch</code> 提供了丰富的数学运算函数。</p><h3 id="常用函数-1"><a href="#常用函数-1" class="headerlink" title="常用函数"></a>常用函数</h3><table><thead><tr><th>函数名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.add()</code></td><td>张量加法。</td></tr><tr><td><code>torch.sub()</code></td><td>张量减法。</td></tr><tr><td><code>torch.mul()</code></td><td>张量乘法（逐元素）。</td></tr><tr><td><code>torch.div()</code></td><td>张量除法（逐元素）。</td></tr><tr><td><code>torch.pow()</code></td><td>张量幂运算。</td></tr><tr><td><code>torch.sqrt()</code></td><td>张量平方根。</td></tr><tr><td><code>torch.exp()</code></td><td>张量指数运算。</td></tr><tr><td><code>torch.log()</code></td><td>张量对数运算。</td></tr><tr><td><code>torch.sin()</code></td><td>张量正弦函数。</td></tr><tr><td><code>torch.cos()</code></td><td>张量余弦函数。</td></tr><tr><td><code>torch.tanh()</code></td><td>张量双曲正切函数。</td></tr><tr><td><code>torch.abs()</code></td><td>张量绝对值。</td></tr><tr><td><code>torch.clamp()</code></td><td>将张量元素限制在指定范围内。</td></tr></tbody></table><hr><h2 id="3-设备管理（Device-Management）"><a href="#3-设备管理（Device-Management）" class="headerlink" title="3. 设备管理（Device Management）"></a>3. 设备管理（Device Management）</h2><p><code>torch</code> 提供了设备管理功能，支持在 CPU 和 GPU 之间切换。</p><h3 id="常用函数-2"><a href="#常用函数-2" class="headerlink" title="常用函数"></a>常用函数</h3><table><thead><tr><th>函数名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.cuda.is_available()</code></td><td>检查 GPU 是否可用。</td></tr><tr><td><code>torch.device()</code></td><td>指定设备（如 <code>&#39;cuda&#39;</code> 或 <code>&#39;cpu&#39;</code>）。</td></tr><tr><td><code>torch.to()</code></td><td>将张量或模型移动到指定设备。</td></tr><tr><td><code>torch.cuda.empty_cache()</code></td><td>清空 GPU 缓存。</td></tr></tbody></table><hr><h2 id="4-自动微分（Autograd）"><a href="#4-自动微分（Autograd）" class="headerlink" title="4. 自动微分（Autograd）"></a>4. 自动微分（Autograd）</h2><p><code>torch</code> 的 <code>autograd</code> 模块支持自动微分，用于计算梯度。</p><h3 id="常用函数-3"><a href="#常用函数-3" class="headerlink" title="常用函数"></a>常用函数</h3><table><thead><tr><th>函数名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.tensor(requires_grad=True)</code></td><td>创建需要计算梯度的张量。</td></tr><tr><td><code>torch.backward()</code></td><td>计算梯度。</td></tr><tr><td><code>torch.grad()</code></td><td>计算指定变量的梯度。</td></tr><tr><td><code>torch.no_grad()</code></td><td>禁用梯度计算（用于推理或冻结参数）。</td></tr><tr><td><code>torch.detach()</code></td><td>返回一个不需要梯度的新张量。</td></tr></tbody></table><hr><h2 id="5-随机数生成（Random-Number-Generation）"><a href="#5-随机数生成（Random-Number-Generation）" class="headerlink" title="5. 随机数生成（Random Number Generation）"></a>5. 随机数生成（Random Number Generation）</h2><p><code>torch</code> 提供了随机数生成功能。</p><h3 id="常用函数-4"><a href="#常用函数-4" class="headerlink" title="常用函数"></a>常用函数</h3><table><thead><tr><th>函数名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.manual_seed()</code></td><td>设置随机种子。</td></tr><tr><td><code>torch.rand()</code></td><td>生成均匀分布随机数。</td></tr><tr><td><code>torch.randn()</code></td><td>生成标准正态分布随机数。</td></tr><tr><td><code>torch.randint()</code></td><td>生成整数随机数。</td></tr><tr><td><code>torch.randperm()</code></td><td>生成随机排列。</td></tr></tbody></table><hr><h2 id="6-文件操作（File-Operations）"><a href="#6-文件操作（File-Operations）" class="headerlink" title="6. 文件操作（File Operations）"></a>6. 文件操作（File Operations）</h2><p><code>torch</code> 提供了模型和张量的保存与加载功能。</p><h3 id="常用函数-5"><a href="#常用函数-5" class="headerlink" title="常用函数"></a>常用函数</h3><table><thead><tr><th>函数名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.save()</code></td><td>保存模型或张量。</td></tr><tr><td><code>torch.load()</code></td><td>加载模型或张量。</td></tr><tr><td><code>torch.load_state_dict()</code></td><td>加载模型参数。</td></tr><tr><td><code>torch.save_state_dict()</code></td><td>保存模型参数。</td></tr></tbody></table><hr><h2 id="7-其他功能"><a href="#7-其他功能" class="headerlink" title="7. 其他功能"></a>7. 其他功能</h2><p><code>torch</code> 还提供了许多其他功能，如分布式训练、FFT、稀疏张量等。</p><h3 id="常用模块"><a href="#常用模块" class="headerlink" title="常用模块"></a>常用模块</h3><table><thead><tr><th>模块名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>torch.distributed</code></td><td>分布式训练支持。</td></tr><tr><td><code>torch.fft</code></td><td>快速傅里叶变换。</td></tr><tr><td><code>torch.sparse</code></td><td>稀疏张量支持。</td></tr><tr><td><code>torch.jit</code></td><td>模型脚本化和优化。</td></tr><tr><td><code>torch.onnx</code></td><td>将模型导出为 ONNX 格式。</td></tr></tbody></table><hr><h2 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h2><h3 id="1-创建张量"><a href="#1-创建张量" class="headerlink" title="1. 创建张量"></a>1. 创建张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建张量</span><br>x = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>y = torch.zeros(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)  <span class="hljs-comment"># 2x3 全零张量</span><br>z = torch.rand(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)   <span class="hljs-comment"># 3x3 随机张量</span><br></code></pre></td></tr></table></figure><h3 id="2-数学运算"><a href="#2-数学运算" class="headerlink" title="2. 数学运算"></a>2. 数学运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>b = torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>])<br><br><span class="hljs-comment"># 加法</span><br>c = torch.add(a, b)<br><br><span class="hljs-comment"># 矩阵乘法</span><br>d = torch.matmul(a.unsqueeze(<span class="hljs-number">0</span>), b.unsqueeze(<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><h3 id="3-自动微分"><a href="#3-自动微分" class="headerlink" title="3. 自动微分"></a>3. 自动微分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.tensor(<span class="hljs-number">2.0</span>, requires_grad=<span class="hljs-literal">True</span>)<br>y = x**<span class="hljs-number">2</span> + <span class="hljs-number">3</span>*x + <span class="hljs-number">1</span><br>y.backward()<br><span class="hljs-built_in">print</span>(x.grad)  <span class="hljs-comment"># 输出梯度值</span><br></code></pre></td></tr></table></figure><h3 id="4-设备管理"><a href="#4-设备管理" class="headerlink" title="4. 设备管理"></a>4. 设备管理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>x = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]).to(device)<br></code></pre></td></tr></table></figure><h3 id="5-保存与加载模型"><a href="#5-保存与加载模型" class="headerlink" title="5. 保存与加载模型"></a>5. 保存与加载模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 保存模型</span><br>torch.save(model.state_dict(), <span class="hljs-string">&quot;model.pth&quot;</span>)<br><br><span class="hljs-comment"># 加载模型</span><br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model.pth&quot;</span>))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基础--torch.nn</title>
    <link href="/2025/01/26/pytorch%E5%BB%BA%E7%AB%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2025/01/26/pytorch%E5%BB%BA%E7%AB%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="一，PyTorch-torch-nn模块（核心）"><a href="#一，PyTorch-torch-nn模块（核心）" class="headerlink" title="一，PyTorch torch.nn模块（核心）"></a>一，PyTorch torch.nn模块（核心）</h1><p><code>nn.Module</code> 是 PyTorch 中所有自定义神经网络模型的基类。PyTorch 提供了许多内置的模块（类），这些模块都继承自 <code>nn.Module</code>，可以直接用于构建神经网络。以下是一些常用的类和它们的用途：</p><hr><h2 id="1-基础层（Layers）"><a href="#1-基础层（Layers）" class="headerlink" title="1. 基础层（Layers）"></a>1. 基础层（Layers）</h2><p>这些是神经网络的基本构建块。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.Linear</code></td><td>全连接层（线性变换），用于实现 $(y &#x3D; x·W^T + b)$。</td></tr><tr><td><code>nn.Conv2d</code></td><td>二维卷积层，用于处理图像数据。</td></tr><tr><td><code>nn.Conv1d</code></td><td>一维卷积层，用于处理序列数据（如时间序列或文本）。</td></tr><tr><td><code>nn.Conv3d</code></td><td>三维卷积层，用于处理三维数据（如视频或医学图像）。</td></tr><tr><td><code>nn.MaxPool2d</code></td><td>二维最大池化层，用于下采样。</td></tr><tr><td><code>nn.AvgPool2d</code></td><td>二维平均池化层，用于下采样。</td></tr><tr><td><code>nn.Dropout</code></td><td>Dropout 层，用于防止过拟合。</td></tr><tr><td><code>nn.Dropout2d</code></td><td>2D Dropout 层，用于防止过拟合。</td></tr><tr><td><code>nn.BatchNorm2d</code></td><td>二维批归一化层，用于加速训练并提高模型稳定性。</td></tr><tr><td><code>nn.LayerNorm</code></td><td>层归一化，适用于小批量或动态输入。</td></tr><tr><td><code>nn.Embedding</code></td><td>嵌入层，用于将离散值（如单词索引）映射到连续向量空间。</td></tr><tr><td><code>nn.Flatten</code></td><td>展平层，将多维输入展平为一维。</td></tr></tbody></table><hr><h2 id="2-激活函数（Activation-Functions）"><a href="#2-激活函数（Activation-Functions）" class="headerlink" title="2. 激活函数（Activation Functions）"></a>2. 激活函数（Activation Functions）</h2><p>这些类实现了常见的激活函数。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.ReLU</code></td><td>ReLU 激活函数。</td></tr><tr><td><code>nn.Sigmoid</code></td><td>Sigmoid 激活函数。</td></tr><tr><td><code>nn.Tanh</code></td><td>Tanh 激活函数。</td></tr><tr><td><code>nn.LeakyReLU</code></td><td>LeakyReLU 激活函数。</td></tr><tr><td><code>nn.Softmax</code></td><td>Softmax 激活函数，用于多分类问题的输出层。</td></tr><tr><td><code>nn.LogSoftmax</code></td><td>LogSoftmax 激活函数，通常与 <code>nn.NLLLoss</code> 结合使用。</td></tr></tbody></table><hr><h2 id="3-损失函数（Loss-Functions）"><a href="#3-损失函数（Loss-Functions）" class="headerlink" title="3. 损失函数（Loss Functions）"></a>3. 损失函数（Loss Functions）</h2><p>这些类实现了常见的损失函数。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.CrossEntropyLoss</code></td><td>交叉熵损失，用于多分类问题。</td></tr><tr><td><code>nn.MSELoss</code></td><td>均方误差损失，用于回归问题。</td></tr><tr><td><code>nn.BCELoss</code></td><td>二分类交叉熵损失，用于二分类问题。</td></tr><tr><td><code>nn.BCEWithLogitsLoss</code></td><td>结合 Sigmoid 和二分类交叉熵损失，数值稳定性更好。</td></tr><tr><td><code>nn.L1Loss</code></td><td>L1 损失（绝对误差），用于回归问题。</td></tr><tr><td><code>nn.NLLLoss</code></td><td>负对数似然损失，通常与 <code>nn.LogSoftmax</code> 结合使用。</td></tr><tr><td><code>nn.HingeEmbeddingLoss</code></td><td>用于二分类或回归问题，支持间隔损失。</td></tr></tbody></table><hr><h2 id="4-容器类（Containers）"><a href="#4-容器类（Containers）" class="headerlink" title="4. 容器类（Containers）"></a>4. 容器类（Containers）</h2><p>这些类用于组合多个模块。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.Sequential</code></td><td>顺序容器，按顺序执行多个模块。</td></tr><tr><td><code>nn.ModuleList</code></td><td>模块列表，用于动态创建子模块。</td></tr><tr><td><code>nn.ModuleDict</code></td><td>模块字典，用于通过名称访问子模块。</td></tr></tbody></table><hr><h2 id="5-循环神经网络（RNN）"><a href="#5-循环神经网络（RNN）" class="headerlink" title="5. 循环神经网络（RNN）"></a>5. 循环神经网络（RNN）</h2><p>这些类用于处理序列数据。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.RNN</code></td><td>基础循环神经网络层。</td></tr><tr><td><code>nn.LSTM</code></td><td>长短期记忆网络（LSTM），适用于长序列建模。</td></tr><tr><td><code>nn.GRU</code></td><td>门控循环单元（GRU），计算效率比 LSTM 更高。</td></tr><tr><td><code>nn.RNNCell</code></td><td>单个 RNN 单元，用于自定义 RNN 结构。</td></tr><tr><td><code>nn.LSTMCell</code></td><td>单个 LSTM 单元，用于自定义 LSTM 结构。</td></tr><tr><td><code>nn.GRUCell</code></td><td>单个 GRU 单元，用于自定义 GRU 结构。</td></tr></tbody></table><hr><h2 id="6-Transformer-相关"><a href="#6-Transformer-相关" class="headerlink" title="6. Transformer 相关"></a>6. Transformer 相关</h2><p>这些类用于实现 Transformer 模型。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.Transformer</code></td><td>完整的 Transformer 模型。</td></tr><tr><td><code>nn.TransformerEncoder</code></td><td>Transformer 编码器。</td></tr><tr><td><code>nn.TransformerDecoder</code></td><td>Transformer 解码器。</td></tr><tr><td><code>nn.MultiheadAttention</code></td><td>多头注意力机制。</td></tr></tbody></table><hr><h2 id="7-工具类（Utilities）"><a href="#7-工具类（Utilities）" class="headerlink" title="7. 工具类（Utilities）"></a>7. 工具类（Utilities）</h2><p>这些类提供了额外的工具功能。</p><table><thead><tr><th>类名</th><th>用途描述</th></tr></thead><tbody><tr><td><code>nn.Identity</code></td><td>恒等映射，直接返回输入。</td></tr><tr><td><code>nn.Parameter</code></td><td>可学习参数，通常用于自定义层。</td></tr><tr><td><code>nn.utils.clip_grad_norm_</code></td><td>梯度裁剪，防止梯度爆炸。</td></tr><tr><td><code>nn.utils.rnn.pack_padded_sequence</code></td><td>用于处理变长序列数据。</td></tr><tr><td><code>nn.utils.rnn.pad_packed_sequence</code></td><td>将打包的序列解包为填充后的序列。</td></tr></tbody></table><hr><h2 id="8-自定义模块模板"><a href="#8-自定义模块模板" class="headerlink" title="8. 自定义模块模板"></a>8. 自定义模块模板</h2><p>你可以通过继承 <code>nn.Module</code> 创建自定义模块。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(CustomLayer, self).__init__()<br>        self.linear = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)<br>        self.dropout = nn.Dropout(<span class="hljs-number">0.5</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.linear(x)<br>        x = self.dropout(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h2 id="9-例子"><a href="#9-例子" class="headerlink" title="9. 例子"></a>9. 例子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F <span class="hljs-comment"># 激活函数等</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):  <span class="hljs-comment">#继承PyTorch中所有神经网络模块的基类</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()  <span class="hljs-comment"># 初始化父类 nn.Module</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        1. 初始化一个内部字典 _modules，用于存储子模块（如 nn.Linear、nn.Conv2d 等）。</span><br><span class="hljs-string">        2. 初始化一个内部字典 _parameters，用于存储模型的可学习参数（如权重和偏置）。</span><br><span class="hljs-string">        3. 初始化其他内部状态，例如钩子函数、设备信息等。</span><br><span class="hljs-string">        如果你不调用 super().__init__()，这些基础设施将不会被初始化，导致模型无法正常工作。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">128</span>)  <span class="hljs-comment"># 输入层 784 (28x28), 隐藏层 128</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)   <span class="hljs-comment"># 隐藏层 64</span><br>        self.fc3 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)    <span class="hljs-comment"># 输出层 10 (10个数字类别)</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)            <span class="hljs-comment"># 展平输入图像</span><br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)                <span class="hljs-comment"># 最后一层不使用激活函数（配合CrossEntropyLoss）</span><br>        <span class="hljs-keyword">return</span> F.log_softmax(x, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 使用log_softmax输出概率</span><br></code></pre></td></tr></table></figure><h1 id="二，建立神经网络"><a href="#二，建立神经网络" class="headerlink" title="二，建立神经网络"></a>二，建立神经网络</h1><h2 id="2-1-基本流程"><a href="#2-1-基本流程" class="headerlink" title="2.1 基本流程"></a>2.1 基本流程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn          <span class="hljs-comment"># 神经网络模块</span><br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F <span class="hljs-comment"># 激活函数等</span><br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim     <span class="hljs-comment"># 优化器</span><br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms <span class="hljs-comment"># 数据集和预处理</span><br><br><span class="hljs-comment"># 设置随机种子保证可重复性</span><br>torch.manual_seed(<span class="hljs-number">42</span>)<br><br><br><br><span class="hljs-comment"># 1. 数据准备</span><br>transform = transforms.Compose([<br>    transforms.ToTensor(),         <span class="hljs-comment"># 将PIL图像转为Tensor (0-1范围)</span><br>    transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,)) <span class="hljs-comment"># 标准化：(input - mean)/std</span><br>])<br><br>train_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,                      <span class="hljs-comment"># 数据存储路径</span><br>    train=<span class="hljs-literal">True</span>,                    <span class="hljs-comment"># 训练集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 开启或关闭下载</span><br>    transform=transform            <span class="hljs-comment"># 应用预处理</span><br>)<br>test_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,<br>    train=<span class="hljs-literal">False</span>,                   <span class="hljs-comment"># 测试集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 开启或关闭下载</span><br>    transform=transform<br>)<br><br>train_loader = torch.utils.data.DataLoader(<br>    train_dataset,<br>    batch_size=<span class="hljs-number">64</span>,  <span class="hljs-comment"># 每批加载64个样本</span><br>    shuffle=<span class="hljs-literal">True</span>    <span class="hljs-comment"># 打乱数据顺序</span><br>)<br>test_loader = torch.utils.data.DataLoader(<br>    test_dataset,<br>    batch_size=<span class="hljs-number">1000</span> <span class="hljs-comment"># 测试时使用更大的批次</span><br>)<br><br><br><br><span class="hljs-comment"># 2. 定义神经网络模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):  <span class="hljs-comment">#继承PyTorch中所有神经网络模块的基类</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()  <span class="hljs-comment"># 初始化父类 nn.Module</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        1. 初始化一个内部字典 _modules，用于存储子模块（如 nn.Linear、nn.Conv2d 等）。</span><br><span class="hljs-string">        2. 初始化一个内部字典 _parameters，用于存储模型的可学习参数（如权重和偏置）。</span><br><span class="hljs-string">        3. 初始化其他内部状态，例如钩子函数、设备信息等。</span><br><span class="hljs-string">        如果你不调用 super().__init__()，这些基础设施将不会被初始化，导致模型无法正常工作。</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">128</span>)  <span class="hljs-comment"># 输入层 784 (28x28), 隐藏层 128</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)   <span class="hljs-comment"># 隐藏层 64</span><br>        self.fc3 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)    <span class="hljs-comment"># 输出层 10 (10个数字类别)</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)            <span class="hljs-comment"># 展平输入图像</span><br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)                <span class="hljs-comment"># 最后一层不使用激活函数（配合CrossEntropyLoss）</span><br>        <span class="hljs-keyword">return</span> F.log_softmax(x, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 使用log_softmax输出概率</span><br><br><br><br><span class="hljs-comment"># 3. 初始化模型、损失函数和优化器</span><br>model = Net()                           <span class="hljs-comment"># 初始化模型</span><br>criterion = nn.CrossEntropyLoss()       <span class="hljs-comment"># 损失函数，自动包含softmax</span><br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)   <span class="hljs-comment"># 优化器</span><br><br><br><br><span class="hljs-comment"># 4. 训练过程</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    model.train()<br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        optimizer.zero_grad()          <span class="hljs-comment"># 梯度清零</span><br>        output = model(data)           <span class="hljs-comment"># 前向传播</span><br>        loss = criterion(output, target)  <span class="hljs-comment"># 确定损失函数</span><br>        loss.backward()                <span class="hljs-comment"># 反向传播</span><br>        optimizer.step()               <span class="hljs-comment"># 参数更新</span><br><br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:       <span class="hljs-comment"># 打印损失值</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Train Epoch: <span class="hljs-subst">&#123;epoch&#125;</span> [<span class="hljs-subst">&#123;batch_idx * <span class="hljs-built_in">len</span>(data)&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_loader.dataset)&#125;</span>&#x27;</span><br>                  <span class="hljs-string">f&#x27; (<span class="hljs-subst">&#123;<span class="hljs-number">100.</span> * batch_idx / <span class="hljs-built_in">len</span>(train_loader):<span class="hljs-number">.0</span>f&#125;</span>%)]\tLoss: <span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.6</span>f&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># 5. 测试过程</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># 切换到评估模式</span><br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 关闭梯度计算</span><br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            output = model(data)<br>            test_loss += criterion(output, target).item()<br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item()<br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset)<br>    accuracy = <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;\nTest set: Average loss: <span class="hljs-subst">&#123;test_loss:<span class="hljs-number">.4</span>f&#125;</span>, Accuracy: <span class="hljs-subst">&#123;correct&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(test_loader.dataset)&#125;</span> (<span class="hljs-subst">&#123;accuracy:<span class="hljs-number">.2</span>f&#125;</span>%)\n&#x27;</span>)<br><br><span class="hljs-comment"># 6. 运行训练和测试</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>):  <span class="hljs-comment"># 训练5个epoch</span><br>    train(epoch)<br>    test()<br><br><span class="hljs-comment"># 7. 保存模型</span><br>torch.save(model.state_dict(), <span class="hljs-string">&quot;mnist_model.pth&quot;</span>)<br><br><span class="hljs-comment"># 加载保存的模型</span><br>model = Net()<br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;mnist_model.pth&quot;</span>))<br>model.<span class="hljs-built_in">eval</span>()<br><br><span class="hljs-comment"># 单个样本预测</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    sample = test_dataset[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].unsqueeze(<span class="hljs-number">0</span>)<br>    output = model(sample)<br>    prediction = output.argmax(dim=<span class="hljs-number">1</span>).item()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Predicted digit: <span class="hljs-subst">&#123;prediction&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="2-2-数据预览"><a href="#2-2-数据预览" class="headerlink" title="2.2 数据预览"></a>2.2 数据预览</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment"># 图像数据需转换为Tensor</span><br><span class="hljs-comment"># 获取一个样本</span><br>image, label = train_dataset[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 第0个样本</span><br><span class="hljs-comment"># 调整张量维度顺序：PyTorch是 (C, H, W)，Matplotlib需要 (H, W, C)</span><br>image = image.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)<br><span class="hljs-comment"># 显示图片</span><br>plt.imshow(image)<br>plt.title(<span class="hljs-string">f&quot;Label: <span class="hljs-subst">&#123;label&#125;</span>&quot;</span>)<br>plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="2-3-使用数据模型"><a href="#2-3-使用数据模型" class="headerlink" title="2.3 使用数据模型"></a>2.3 使用数据模型</h2><h3 id="2-3-1-加载模型权重"><a href="#2-3-1-加载模型权重" class="headerlink" title="2.3.1 加载模型权重"></a>2.3.1 加载模型权重</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义相同的模型架构</span><br>model = SimpleModel()<br><br><span class="hljs-comment"># 加载权重</span><br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;model_weights.pth&#x27;</span>))<br><br><span class="hljs-comment"># 设置模型为评估模式（关闭 Dropout 和 BatchNorm 等）</span><br>model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure><h3 id="2-3-2-加载整个模型"><a href="#2-3-2-加载整个模型" class="headerlink" title="2.3.2 加载整个模型"></a>2.3.2 加载整个模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 直接加载整个模型</span><br>model = torch.load(<span class="hljs-string">&#x27;model.pth&#x27;</span>)<br><br><span class="hljs-comment"># 设置模型为评估模式</span><br>model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure><table><thead><tr><th align="center"><strong>特性</strong></th><th align="center"><strong>加载模型权重</strong></th><th align="center"><strong>加载整个模型</strong></th></tr></thead><tbody><tr><td align="center"><strong>保存内容</strong></td><td align="center">仅保存模型参数（<code>state_dict</code>）</td><td align="center">保存模型结构和参数</td></tr><tr><td align="center"><strong>加载方式</strong></td><td align="center">需要先定义模型结构，再加载权重</td><td align="center">直接加载模型</td></tr><tr><td align="center"><strong>文件体积</strong></td><td align="center">较小</td><td align="center">较大</td></tr><tr><td align="center"><strong>代码依赖</strong></td><td align="center">低（只需定义相同的模型结构）</td><td align="center">高（需要与保存时的代码完全一致）</td></tr><tr><td align="center"><strong>灵活性</strong></td><td align="center">高（可加载到不同的模型架构中）</td><td align="center">低（只能加载到相同的模型架构中）</td></tr><tr><td align="center"><strong>适用场景</strong></td><td align="center">跨项目、跨版本使用，模型结构可能变化</td><td align="center">快速实验，代码不变的情况下使用</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>transformer架构(带公式与代码)</title>
    <link href="/2025/01/22/transformer/"/>
    <url>/2025/01/22/transformer/</url>
    
    <content type="html"><![CDATA[<p>NLP的救星：transformer架构<br>当然不只是NLP，如今transformer的注意力机制几乎可以做任何事。</p><hr><h1 id="一，传统RNN的缺陷"><a href="#一，传统RNN的缺陷" class="headerlink" title="一，传统RNN的缺陷"></a>一，传统RNN的缺陷</h1><ul><li>只能串行，对于较长序列的问题效率较低。</li><li>在处理长序列时难以捕捉到长期依赖关系，只能有效利用较短的上下文信息。</li><li>反向传播时，由于参数共享和多次连乘的特性，容易出现梯度消失或梯度爆炸的问题，导致模型难以训练或无法收敛。</li></ul><hr><h1 id="二，transformer（编码器）的核心——-self-attention，自注意力机制"><a href="#二，transformer（编码器）的核心——-self-attention，自注意力机制" class="headerlink" title="二，transformer（编码器）的核心——(self-attention，自注意力机制)"></a>二，transformer（编码器）的核心——(self-attention，自注意力机制)</h1><ol><li><p>假设输入序列是 $ n $ 个词，每个词被编码为维度 $ d_{model} $（如 512）的向量，输入矩阵为：<br>$$<br>X \in \mathbb{R}^{n \times d_{\text {model }}}<br>$$</p></li><li><p>自注意力通过三个<strong>可学习的权重矩阵</strong>，将输入映射为 $ Query（Q）、Key（K）、Value（V）$：<br>$$<br>Q&#x3D;X \cdot W^{Q}, \quad K&#x3D;X \cdot W^{K}, \quad V&#x3D;X \cdot W^{V}<br>$$<br>$ W^{Q},W^{K},W^{V} \in \mathbb{R}^{d_{\text {model}} \times d_{k}} ，d_{k} $是每个头的维度（如 64）。</p><ul><li>每个词生成对应的 Q、K、V 向量，用于后续计算。</li><li>在自注意力机制中，求的是序列内各词的关联度。</li><li>在普通注意力机制中，计算一个序列（如源序列）与另一个序列（如目标序列）之间的关系。</li></ul></li><li><p>对每个 Query 向量$Q_i$，计算它与所有 key 向量$K_j$的相似度：<br>$$ \text{Attention Score}(Q_i,K_j)&#x3D;\frac{Q_i\cdot K_j^T}{\sqrt{d_k}} $$</p><ul><li><strong>点积</strong>：衡量两个向量的相似度（值越大越相关）。</li><li><strong>缩放因子</strong>$\sqrt{d_k}$：防止点积结果过大导致梯度消失（尤其在维度较高时）。</li></ul></li><li><p>最后对注意力分数进行 Softmax 即可得到权重分布。</p></li><li><p>用注意力权重对 Value 向量加权求和，得到当前词的最终表示：<br>$$<br>\mathrm{Output}&#x3D;\text{Attention Weights}\cdot V<br>$$</p></li><li><p>多头注意力（Multi-Head Attention）<br>为了捕捉不同类型的依赖关系，Transformer 使用 多个独立的注意力头：</p><ul><li>将 Q、K、V 拆分为 h 个头（如 8 个头），每个头维度为均分总维度。</li><li>每个头独立计算注意力，得到 h 个输出矩阵。</li><li>拼接所有头的输出，并通过线性变换合并为最终结果。</li></ul></li></ol><h1 id="三，总体结构"><a href="#三，总体结构" class="headerlink" title="三，总体结构"></a>三，总体结构</h1><p><img src="/2025/01/22/transformer/transformer%E7%BB%93%E6%9E%84.jpg"></p><ul><li>Add：残差连接</li><li>Norm：层归一化</li></ul><p>输入序列 → 词嵌入 + 位置编码 → 编码器（多头自注意力 + FFN） → 编码器输出<br>↓<br>解码器输入 → 词嵌入 + 位置编码 → 掩码自注意力 → 编码器-解码器注意力 → FFN → 输出概率</p><h2 id="3-1-整体架构"><a href="#3-1-整体架构" class="headerlink" title="3.1 整体架构"></a>3.1 整体架构</h2><ul><li>由 <strong>编码器（Encoder）</strong> 和 <strong>解码器（Decoder）</strong> 组成，堆叠多层（原始论文中为 6 层）。</li><li>完全依赖<strong>自注意力机制</strong>，无需循环（RNN）或卷积（CNN）。</li><li>Q，K，V的权重矩阵通过解码器的输出进行反向传播。</li></ul><hr><h2 id="3-2-编码器（Encoder）"><a href="#3-2-编码器（Encoder）" class="headerlink" title="3.2 编码器（Encoder）"></a>3.2 编码器（Encoder）</h2><p><strong>作用</strong>：将输入序列转换为一系列富含上下文信息的表示。<br>每层编码器结构：</p><ol><li><strong>多头自注意力层（Multi-Head Self-Attention）</strong><ul><li>计算输入序列内部关系，拆分多个头并行处理。</li></ul></li><li><strong>前馈神经网络（FFN）</strong><ul><li>每个位置独立处理，维度扩展后压缩（如 <code>512 → 2048 → 512</code>）。</li></ul></li></ol><p><strong>每小层附加操作</strong>：</p><ul><li><strong>残差连接</strong>：每个子层输出与输入相加。</li><li><strong>层归一化</strong>：对残差结果进行归一化。</li></ul><hr><h2 id="3-3-解码器（Decoder）"><a href="#3-3-解码器（Decoder）" class="headerlink" title="3.3 解码器（Decoder）"></a>3.3 解码器（Decoder）</h2><p><strong>作用</strong>：根据编码器的输出和已生成的部分输出序列，逐步生成目标序列。<br>每层解码器结构：</p><ol><li><strong>掩码多头自注意力层（Masked Multi-Head Self-Attention）</strong><ul><li>通过掩码避免模型看到未来信息。就是给注意力分数加上值，后面的变量<strong>减无穷大</strong>使得分数被抑制，否则加0。</li><li>同时还可以调整模型动态输入不同长度的序列。</li></ul></li><li><strong>编码器-解码器注意力层（Cross-Attention）</strong><ul><li>Key 和 Value 来自编码器输出，Query 来自解码器输入。</li></ul></li><li><strong>前馈神经网络（FFN）</strong>：与编码器结构相同。</li></ol><p><strong>每小层附加操作</strong>：</p><ul><li>残差连接 + 层归一化（每个子层后应用）。</li></ul><hr><h2 id="3-4-输入处理"><a href="#3-4-输入处理" class="headerlink" title="3.4 输入处理"></a>3.4 输入处理</h2><ol><li><strong>词嵌入（Embedding）</strong><ul><li>将词转换为固定维度向量（如 512 维）。</li></ul></li><li><strong>位置编码（Positional Encoding）</strong><ul><li>使用正弦&#x2F;余弦函数或可学习参数生成位置信息。</li><li>公式示例（正弦编码）：$ PE_{(pos, 2i)} &#x3D; \sin\left(\frac{pos}{10000^{2i&#x2F;d}}\right), \quad PE_{(pos, 2i+1)} &#x3D; \cos\left(\frac{pos}{10000^{2i&#x2F;d}}\right)$</li></ul></li></ol><hr><h2 id="3-5-注意力机制"><a href="#3-5-注意力机制" class="headerlink" title="3.5 注意力机制"></a>3.5 注意力机制</h2><h3 id="单头注意力公式"><a href="#单头注意力公式" class="headerlink" title="单头注意力公式"></a>单头注意力公式</h3><p>$$<br>\text{f}(Q) &#x3D; \text{Attention}(Q, K, V) &#x3D; \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V<br>$$</p><h3 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h3><ul><li>将 (Q, K, V) 拆分到多个头（如 8 头），独立计算后拼接结果。</li></ul><hr><ul><li>Query（Q）：表示当前词希望“查询”其他词的信息。</li><li>Key（K）：表示其他词提供的“索引标签”，用于与 Query 匹配。</li><li>Value（V）：表示其他词的实际内容，最终通过权重聚合到输出中。</li></ul><table><thead><tr><th align="center">场景</th><th align="center">输入来源</th><th align="center">不同值的原因</th></tr></thead><tbody><tr><td align="center">自注意力</td><td align="center">同一层的同一输入序列</td><td align="center">投影矩阵不同</td></tr><tr><td align="center">交叉注意力</td><td align="center">Q：解码器输入；K&#x2F;V：编码器输出</td><td align="center">来源不同层</td></tr></tbody></table><hr><h2 id="3-6-输出生成"><a href="#3-6-输出生成" class="headerlink" title="3.6 输出生成"></a>3.6 输出生成</h2><ul><li>解码器最后一层输出通过线性层 + Softmax 生成概率分布。</li><li><strong>训练</strong>：Teacher Forcing（输入真实历史词）。</li><li><strong>推理</strong>：自回归生成（逐步预测词）。</li></ul><hr><h2 id="3-7-任务类型"><a href="#3-7-任务类型" class="headerlink" title="3.7 任务类型"></a>3.7 任务类型</h2><ol><li>编码器-解码器架构（如机器翻译）</li><li>仅编码器架构（如文本分类）</li><li>仅解码器架构（如文本生成）</li><li>对于不同长度的输入序列，分别生成 Q、K、V 矩阵，并计算自注意力。或使用“填充”与“掩码”。</li></ol><hr><h1 id="四，具体结构问题"><a href="#四，具体结构问题" class="headerlink" title="四，具体结构问题"></a>四，具体结构问题</h1><ul><li>编码器和解码器是独立的模块，但解码器的<strong>每一层</strong>都会通过 交叉注意力（Cross-Attention） 访问编码器的<strong>最终输出</strong>。<ul><li>输入序列 → [编码器层1 → 编码器层2 → … → 编码器层N] → 编码器最终输出 ↓↓↓<br>  解码器层1 → 解码器层2 → … → 解码器层N → 输出概率</li></ul></li><li>编码器与解码器宏观上都只有一个，但是它们里面都可以添加多层，例如编码器中有多个（多头自注意力+FFN），解码器中有多个（掩码多头自注意力+交叉注意力+FFN）</li></ul><h1 id="五，利用编码器对中文句子进行分类"><a href="#五，利用编码器对中文句子进行分类" class="headerlink" title="五，利用编码器对中文句子进行分类"></a>五，利用编码器对中文句子进行分类</h1><ul><li>这里的代码只用到了编码器，并不牵扯解码器。因为两者都用一般用于语言翻译、对话等任务，这里只进行分类，因此没必要。</li><li>用解码器时输出会变得很难，本人技术还不到位。有待提高。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 加载 npz 文件</span><br>npz = np.load(<span class="hljs-string">&quot;.\data\embedding_Tencent.npz&quot;</span>)<br><span class="hljs-comment">#print(len(npz[&#x27;embeddings&#x27;]))  # 输出文件中包含的数组名称</span><br><span class="hljs-comment"># 打开文件并读取词汇表</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;.\data\\vocab.pkl&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    vocab = pickle.load(file)<br><br><span class="hljs-comment"># 数据预加载</span><br>train_dataset = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./data/train.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        line = file.readline()  <span class="hljs-comment"># 使用readline()逐行读取</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> line:  <span class="hljs-comment"># 如果读到文件末尾，line为空字符串，退出循环</span><br>            <span class="hljs-keyword">break</span><br>        columns = line.strip().split(<span class="hljs-string">&quot;\t&quot;</span>)  <span class="hljs-comment"># 使用strip()去除首尾空白字符，然后按Tab分割</span><br>        train_dataset.append(columns)<br>test_dataset = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./data/dev.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        line = file.readline()  <span class="hljs-comment"># 使用readline()逐行读取</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> line:  <span class="hljs-comment"># 如果读到文件末尾，line为空字符串，退出循环</span><br>            <span class="hljs-keyword">break</span><br>        columns = line.strip().split(<span class="hljs-string">&quot;\t&quot;</span>)  <span class="hljs-comment"># 使用strip()去除首尾空白字符，然后按Tab分割</span><br>        test_dataset.append(columns)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(train_dataset)):<br>    ind1 = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>        <span class="hljs-keyword">try</span>:<br>            ind1.append(vocab[train_dataset[i][<span class="hljs-number">0</span>][j]])<br>        <span class="hljs-keyword">except</span> KeyError:<br>            ind1.append(vocab[<span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span>])<br>        <span class="hljs-keyword">except</span> IndexError:<br>            ind1.append(vocab[<span class="hljs-string">&#x27;&lt;PAD&gt;&#x27;</span>])<br>    train_dataset[i][<span class="hljs-number">0</span>] = ind1<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(test_dataset)):<br>    ind2 = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>        <span class="hljs-keyword">try</span>:<br>            ind2.append(vocab[test_dataset[i][<span class="hljs-number">0</span>][j]])<br>        <span class="hljs-keyword">except</span> KeyError:<br>            ind2.append(vocab[<span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span>])<br>        <span class="hljs-keyword">except</span> IndexError:<br>            ind2.append(vocab[<span class="hljs-string">&#x27;&lt;PAD&gt;&#x27;</span>])<br>    test_dataset[i][<span class="hljs-number">0</span>] = ind2<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        初始化数据集</span><br><span class="hljs-string">        data: 原始数据集，格式为 [[features, label], ...]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.data = data<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment">#返回数据集的大小</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        根据索引返回一个样本及其标签</span><br><span class="hljs-string">        idx: 样本索引</span><br><span class="hljs-string">        return: (features, label)</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        features, label = self.data[idx]<br>        <span class="hljs-comment"># 将 features 转换为 Tensor</span><br>        features = torch.tensor(features, dtype=torch.long)<br>        <span class="hljs-comment"># 将标签转换为 Tensor（假设标签是整数）</span><br>        label = torch.tensor(<span class="hljs-built_in">int</span>(label), dtype=torch.long)<br>        <span class="hljs-keyword">return</span> features, label<br>train_dataset = CustomDataset(train_dataset)<br>test_dataset = CustomDataset(test_dataset)<br><span class="hljs-comment"># 创建DataLoader</span><br>train_loader = DataLoader(<br>    train_dataset,<br>    batch_size=<span class="hljs-number">8</span>,<br>    shuffle=<span class="hljs-literal">False</span>)<br>test_loader = DataLoader(<br>    test_dataset,<br>    batch_size=<span class="hljs-number">8</span>,<br>    shuffle=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 词嵌入二维列表</span><br>embedding_matrix = torch.tensor(npz[<span class="hljs-string">&#x27;embeddings&#x27;</span>], dtype=torch.<span class="hljs-built_in">float</span>)<br><span class="hljs-comment"># 检查词嵌入的维度</span><br>vocab_size, embedding_dim = embedding_matrix.shape<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;词汇表大小: <span class="hljs-subst">&#123;vocab_size&#125;</span>, 词嵌入维度: <span class="hljs-subst">&#123;embedding_dim&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, model_dim, num_heads, num_encoder_layers, dim_feedforward, dropout=<span class="hljs-number">0.1</span>, embedding_matrix=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(TransformerModel, self).__init__()<br>        <span class="hljs-comment"># 嵌入层</span><br>        self.embedding = nn.Embedding(input_dim, model_dim)<br>        <span class="hljs-keyword">if</span> embedding_matrix <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.embedding.weight = nn.Parameter(embedding_matrix, requires_grad=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 使用预训练的词嵌入</span><br>        <span class="hljs-comment"># Transformer Encoder</span><br>        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout)<br>        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)<br>        <span class="hljs-comment"># 输出层</span><br>        self.fc_out = nn.Linear(model_dim, <span class="hljs-number">10</span>)  <span class="hljs-comment"># num_classes 是标签的数量</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, src</span>):<br>        <span class="hljs-comment"># 嵌入输入</span><br>        src_embedded = self.embedding(src) <span class="hljs-comment"># 输出(batch_size, seq_len, model_dim)</span><br>        <span class="hljs-comment"># 输入(seq_len, batch_size, model_dim)</span><br>        transformer_output = self.transformer_encoder(src_embedded.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># 恢复维度</span><br>        transformer_output = transformer_output.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 取编码器的最后一个时间步或全局池化</span><br>        <span class="hljs-comment"># 这里假设取最后一个时间步的隐藏状态</span><br>        pooled_output = transformer_output[:, -<span class="hljs-number">1</span>, :]<br>        <span class="hljs-comment"># 输出层</span><br>        output = self.fc_out(pooled_output)<br>        <span class="hljs-keyword">return</span> output<br><br><span class="hljs-comment"># 参数设置</span><br>input_dim = <span class="hljs-number">4762</span>       <span class="hljs-comment"># 词汇表大小</span><br>model_dim = <span class="hljs-number">200</span>        <span class="hljs-comment"># 模型维度,将每个单词或标记转换为多少维的密集向量</span><br>num_heads = <span class="hljs-number">4</span>          <span class="hljs-comment"># 编码器头数,确保 model_dim 能被 num_heads 整除</span><br>num_encoder_layers = <span class="hljs-number">2</span> <span class="hljs-comment"># 编码器层数,包含多头注意力层和前馈网络层</span><br>dim_feedforward = <span class="hljs-number">400</span>  <span class="hljs-comment"># 前馈网络的维度,通常设置为 model_dim 的 2-4 倍</span><br>dropout = <span class="hljs-number">0.1</span>          <span class="hljs-comment"># Dropout概率</span><br>num_classes = <span class="hljs-number">10</span>       <span class="hljs-comment"># 假设有 10 个类别</span><br><br><span class="hljs-comment"># 初始化模型</span><br>model = TransformerModel(input_dim, model_dim, num_heads, num_encoder_layers, dim_feedforward, dropout, embedding_matrix)<br>criterion = nn.CrossEntropyLoss()  <span class="hljs-comment"># 分类任务使用交叉熵损失,包含softmax</span><br>optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">0.0001</span>)<br><br><span class="hljs-comment"># 训练函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, train_loader, criterion, optimizer, device</span>):<br>    model.train()<br>    total_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> src, tgt <span class="hljs-keyword">in</span> train_loader:<br>        src, tgt = src.to(device), tgt.to(device)<br>        <span class="hljs-comment"># 前向传播</span><br>        optimizer.zero_grad()<br>        output = model(src)  <span class="hljs-comment"># 只传入 src</span><br>        <span class="hljs-comment"># 计算损失</span><br>        loss = criterion(output, tgt)  <span class="hljs-comment"># tgt 的形状是 [batch_size]</span><br>        <span class="hljs-comment"># 反向传播和优化</span><br>        loss.backward()<br>        optimizer.step()<br>        total_loss += loss.item()<br>    <span class="hljs-keyword">return</span> total_loss / <span class="hljs-built_in">len</span>(train_loader)<br><br><span class="hljs-comment"># 测试函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, test_loader, criterion, device</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    total_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> src, tgt <span class="hljs-keyword">in</span> test_loader:<br>            src, tgt = src.to(device), tgt.to(device)<br>            <span class="hljs-comment"># 前向传播</span><br>            output = model(src)<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(output.data, <span class="hljs-number">1</span>)<br>            total += tgt.size(<span class="hljs-number">0</span>)<br>            correct += (predicted == tgt).<span class="hljs-built_in">sum</span>().item()<br>            <span class="hljs-comment"># 计算损失</span><br>            loss = criterion(output, tgt)<br>            total_loss += loss.item()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy of the network on the 10000 test: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * correct / total:<span class="hljs-number">.2</span>f&#125;</span>%&#x27;</span>)<br>    <span class="hljs-keyword">return</span> total_loss / <span class="hljs-built_in">len</span>(test_loader)<br><span class="hljs-comment"># Accuracy of the network on the 10000 test: 85.40%</span><br><span class="hljs-comment"># 设备设置</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>model = model.to(device)<br><br><span class="hljs-comment"># 训练和测试循环</span><br>num_epochs = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_epochs)):<br>    train_loss = train(model, train_loader, criterion, optimizer, device)<br>    test_loss = evaluate(model, test_loader, criterion, device)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch [<span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>], Train Loss: <span class="hljs-subst">&#123;train_loss:<span class="hljs-number">.4</span>f&#125;</span>, Test Loss: <span class="hljs-subst">&#123;test_loss:<span class="hljs-number">.4</span>f&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># 保存模型</span><br>torch.save(model.state_dict(), <span class="hljs-string">&quot;transformer_classify_model.pth&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 加载 npz 文件</span><br>npz = np.load(<span class="hljs-string">&quot;.\data\embedding_Tencent.npz&quot;</span>)<br><span class="hljs-comment"># 打开文件并读取词汇表</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;.\data\\vocab.pkl&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> file:<br>    vocab = pickle.load(file)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_dim, model_dim, num_heads, num_encoder_layers, dim_feedforward, dropout=<span class="hljs-number">0.1</span>, embedding_matrix=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(TransformerModel, self).__init__()<br>        <span class="hljs-comment"># 嵌入层</span><br>        self.embedding = nn.Embedding(input_dim, model_dim)<br>        <span class="hljs-keyword">if</span> embedding_matrix <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.embedding.weight = nn.Parameter(embedding_matrix, requires_grad=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 使用预训练的词嵌入</span><br>        <span class="hljs-comment"># Transformer Encoder</span><br>        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout)<br>        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)<br>        <span class="hljs-comment"># 输出层</span><br>        self.fc_out = nn.Linear(model_dim, <span class="hljs-number">10</span>)  <span class="hljs-comment"># num_classes 是标签的数量</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, src</span>):<br>        <span class="hljs-comment"># 嵌入输入</span><br>        src_embedded = self.embedding(src) <span class="hljs-comment"># 输出(batch_size, seq_len, model_dim)</span><br>        <span class="hljs-comment"># 输入(seq_len, batch_size, model_dim)</span><br>        transformer_output = self.transformer_encoder(src_embedded.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>))<br>        <span class="hljs-comment"># 恢复维度</span><br>        transformer_output = transformer_output.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 取编码器的最后一个时间步或全局池化</span><br>        <span class="hljs-comment"># 这里假设取最后一个时间步的隐藏状态</span><br>        pooled_output = transformer_output[:, -<span class="hljs-number">1</span>, :]<br>        <span class="hljs-comment"># 输出层</span><br>        output = self.fc_out(pooled_output)<br>        <span class="hljs-keyword">return</span> output<br><br><span class="hljs-comment"># 参数设置</span><br>input_dim = <span class="hljs-number">4762</span>       <span class="hljs-comment"># 词汇表大小</span><br>model_dim = <span class="hljs-number">200</span>        <span class="hljs-comment"># 模型维度,将每个单词或标记转换为多少维的密集向量</span><br>num_heads = <span class="hljs-number">4</span>          <span class="hljs-comment"># 编码器头数,确保 model_dim 能被 num_heads 整除</span><br>num_encoder_layers = <span class="hljs-number">2</span> <span class="hljs-comment"># 编码器层数,包含多头注意力层和前馈网络层</span><br>dim_feedforward = <span class="hljs-number">400</span>  <span class="hljs-comment"># 前馈网络的维度,通常设置为 model_dim 的 2-4 倍</span><br>dropout = <span class="hljs-number">0.1</span>          <span class="hljs-comment"># Dropout概率</span><br>num_classes = <span class="hljs-number">10</span>       <span class="hljs-comment"># 假设有 10 个类别</span><br><br><span class="hljs-comment"># 词嵌入二维列表</span><br>embedding_matrix = torch.tensor(npz[<span class="hljs-string">&#x27;embeddings&#x27;</span>], dtype=torch.<span class="hljs-built_in">float</span>)<br><span class="hljs-comment"># 检查词嵌入的维度</span><br>vocab_size, embedding_dim = embedding_matrix.shape<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;词汇表大小: <span class="hljs-subst">&#123;vocab_size&#125;</span>, 词嵌入维度: <span class="hljs-subst">&#123;embedding_dim&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 初始化模型</span><br>model = TransformerModel(input_dim, model_dim, num_heads, num_encoder_layers, dim_feedforward, dropout, embedding_matrix)<br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;transformer_classify_model.pth&#x27;</span>))<br><span class="hljs-comment"># 将模型设置为评估模式</span><br>model.<span class="hljs-built_in">eval</span>()<br>xx = <span class="hljs-string">&#x27;中国和美国关系不是很好&#x27;</span><br>categories = [<br>    <span class="hljs-string">&quot;finance&quot;</span>,<br>    <span class="hljs-string">&quot;realty&quot;</span>,<br>    <span class="hljs-string">&quot;stocks&quot;</span>,<br>    <span class="hljs-string">&quot;education&quot;</span>,<br>    <span class="hljs-string">&quot;science&quot;</span>,<br>    <span class="hljs-string">&quot;society&quot;</span>,<br>    <span class="hljs-string">&quot;politics&quot;</span>,<br>    <span class="hljs-string">&quot;sports&quot;</span>,<br>    <span class="hljs-string">&quot;game&quot;</span>,<br>    <span class="hljs-string">&quot;entertainment&quot;</span>]<br>x = []<br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>    <span class="hljs-keyword">try</span>:<br>        x.append(vocab[xx[j]])<br>    <span class="hljs-keyword">except</span> KeyError:<br>        x.append(vocab[<span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span>])<br>    <span class="hljs-keyword">except</span> IndexError:<br>        x.append(vocab[<span class="hljs-string">&#x27;&lt;PAD&gt;&#x27;</span>])<br><br><span class="hljs-comment"># 预测</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = model(torch.tensor(x).unsqueeze(<span class="hljs-number">0</span>))<br>    <span class="hljs-built_in">print</span>(output)<br>    _, predicted = torch.<span class="hljs-built_in">max</span>(output, <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Predicted class: <span class="hljs-subst">&#123;categories[predicted.item()]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络（CNN，包含代码实现）</title>
    <link href="/2025/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2025/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="一，卷积是在卷什么？"><a href="#一，卷积是在卷什么？" class="headerlink" title="一，卷积是在卷什么？"></a>一，卷积是在卷什么？</h1><p>······卷积神经网络是在图像识别领域的霸主之一，它可以对<strong>图片或视频</strong>进行卷积操作来提取特征，卷积可以捕捉到图像中的局部特征而不受其位置的影响，从而进行预测或分类。<br>图片主要分两种：</p><ul><li>灰度图：灰度图可以量化为一个二维张量（矩阵），行列即为像素，值即为灰度值。</li><li>RGB颜色模型：RGB图可以量化为一个三维张量（矩阵），行列即为像素，每一层的值分别为红绿蓝的程度值。</li></ul><p>由于灰度图无法识别颜色区别，所以在很多情况下使用RGB颜色模型。</p><h1 id="二，什么是卷积？"><a href="#二，什么是卷积？" class="headerlink" title="二，什么是卷积？"></a>二，什么是卷积？</h1><p>在卷积神经网络中，卷积操作是指将一个可移动的小窗口（称为数据窗口）与图像进行<strong>逐元素相乘然后相加</strong>的操作。这个小窗口其实是一组待优化的权重，它可以被看作是一个特定的滤波器（filter）或卷积核。现在的卷积核往往是3×3的，因为GPU提供商对于这种规格的计算有优化，速度较快。<br><img src="/2025/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/卷积.jpg" width="100%"><br>上图中蓝色的框就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）。</p><h1 id="三，卷积计算过程"><a href="#三，卷积计算过程" class="headerlink" title="三，卷积计算过程"></a>三，卷积计算过程</h1><img src="/2025/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/卷积映射.jpg" width="100%">从上图可以看出，每卷积一次，图像的行列数量都会减少。同样的，这样的步骤如何进行也就出现了新的问题：<ul><li>步长stride：每次滑动的位置步长，（为1最好）。</li><li>卷积核的个数：决定输出的depth厚度，对于RGB颜色模型即为 3。</li><li>填充值zero-padding：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除，而且还可以防止边缘数据被忽视，加若干圈0可以保证边缘数据被卷积到的次数增加。</li></ul><p>以上图为例，那么：</p><ul><li>数据窗口每次移动两个步长取 3*3 的局部数据，即 stride&#x3D;2</li><li>两个神经元，即 depth&#x3D;2 ，意味着有两个滤波器。</li><li>zero-padding&#x3D;1</li></ul><h1 id="四，卷积核与神经元的区别"><a href="#四，卷积核与神经元的区别" class="headerlink" title="四，卷积核与神经元的区别"></a>四，卷积核与神经元的区别</h1><img src="/2025/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/卷积核.jpg" width="100%">上面红框中的部分便可以理解为一个滤波器，即卷积核的累乘求和代替的神经元的累乘求和。多个滤波器叠加便成了卷积层。<h1 id="五，卷积神经网络结构"><a href="#五，卷积神经网络结构" class="headerlink" title="五，卷积神经网络结构"></a>五，卷积神经网络结构</h1><ol><li><p>输入层<br>输入层接收原始图像数据。图像通常由三个颜色通道（红、绿、蓝）组成，形成一个二维矩阵，表示像素的强度值。</p></li><li><p>卷积和激活<br>卷积层将输入图像与卷积核进行卷积操作。然后，通过应用激活函数（如ReLU）来引入非线性。这一步使网络能够学习复杂的特征。<br>即 卷积 ——&gt; 激活函数。</p></li><li><p>池化层<br>池化层通过减小特征图的大小来减少计算复杂性。它通过<strong>选择池化窗口内的最大值或平均值</strong>来实现。这有助于提取最重要的特征。</p></li><li><p>多层堆叠<br>CNN通常由<strong>多个卷积和池化层</strong>的堆叠组成，以逐渐提取更高级别的特征。深层次的特征可以表示更复杂的模式。</p></li><li><p>全连接和输出<br>最后，全连接层将提取的特征映射转化为网络的最终输出。这里还需考虑<strong>偏置</strong>。</p></li></ol><h1 id="六，pytorch实现CNN"><a href="#六，pytorch实现CNN" class="headerlink" title="六，pytorch实现CNN"></a>六，pytorch实现CNN</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn          <span class="hljs-comment"># 神经网络模块</span><br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F <span class="hljs-comment"># 激活函数等</span><br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim     <span class="hljs-comment"># 优化器</span><br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms <span class="hljs-comment"># 数据集和预处理</span><br><br><span class="hljs-comment"># 设置随机种子保证可重复性</span><br>torch.manual_seed(<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 数据准备</span><br>transform = transforms.Compose([<br>    transforms.ToTensor(),         <span class="hljs-comment"># 将PIL图像转为Tensor (0-1范围)</span><br>    transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,)) <span class="hljs-comment"># 标准化：(input - mean)/std,归一化到[-1, 1]</span><br>])<br><br>train_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,                 <span class="hljs-comment"># 数据存储路径</span><br>    train=<span class="hljs-literal">True</span>,                    <span class="hljs-comment"># 训练集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 关闭下载</span><br>    transform=transform            <span class="hljs-comment"># 应用预处理</span><br>)<br><br>test_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,<br>    train=<span class="hljs-literal">False</span>,                   <span class="hljs-comment"># 测试集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 关闭下载</span><br>    transform=transform<br>)<br><br>train_loader = torch.utils.data.DataLoader(<br>    train_dataset,<br>    batch_size=<span class="hljs-number">64</span>,  <span class="hljs-comment"># 每批加载64个样本</span><br>    shuffle=<span class="hljs-literal">False</span>    <span class="hljs-comment"># 打乱数据顺序</span><br>)<br><br>test_loader = torch.utils.data.DataLoader(<br>    test_dataset,<br>    batch_size=<span class="hljs-number">1000</span>,  <span class="hljs-comment"># 测试时使用更大的批次</span><br>    shuffle=<span class="hljs-literal">False</span>    <span class="hljs-comment"># 打乱数据顺序</span><br>)<br><br><span class="hljs-comment"># 定义CNN网络模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleCNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleCNN, self).__init__()<br>        <span class="hljs-comment"># 第一个卷积层</span><br>        self.conv1 = nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        in_channels:输入数据的通道数</span><br><span class="hljs-string">        out_channels:输出数据的通道数,即卷积层中滤波器的数量</span><br><span class="hljs-string">        kernel_size:卷积核（滤波器）的大小,3*3</span><br><span class="hljs-string">        padding:输入数据的边缘填充的像素数.</span><br><span class="hljs-string">        当 kernel_size=3 且 padding=1 时，输出特征图的高度和宽度与输入相同</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># 第二个卷积层</span><br>        self.conv2 = nn.Conv2d(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 最大池化层</span><br>        self.pool = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        在每个 2x2 的区域内，取最大值作为输出。</span><br><span class="hljs-string">        kernel_size:池化窗口的大小</span><br><span class="hljs-string">        stride:池化窗口滑动的步长</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># 全连接层</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">128</span>)  <span class="hljs-comment"># MNIST图像经过两次池化后大小为7x7</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># MNIST有10个类别</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 通过第一个卷积层和激活函数</span><br>        x = F.relu(self.conv1(x))<br>        <span class="hljs-comment"># 通过第一个池化层</span><br>        x = self.pool(x)<br>        <span class="hljs-comment"># 通过第二个卷积层和激活函数</span><br>        x = F.relu(self.conv2(x))<br>        <span class="hljs-comment"># 通过第二个池化层</span><br>        x = self.pool(x)<br>        <span class="hljs-comment"># 展平张量</span><br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">64</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>)<br>        <span class="hljs-comment"># 通过第一个全连接层和激活函数</span><br>        x = F.relu(self.fc1(x))<br>        <span class="hljs-comment"># 通过第二个全连接层</span><br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 实例化网络</span><br>model = SimpleCNN()<br><br><span class="hljs-comment"># 定义损失函数和优化器</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.001</span>)<br><br><span class="hljs-comment"># 训练网络</span><br>num_epochs = <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    model.train()<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        <span class="hljs-comment"># 清零梯度</span><br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># 前向传播</span><br>        outputs = model(inputs)<br>        <span class="hljs-comment"># 计算损失</span><br>        loss = criterion(outputs, labels)<br>        <span class="hljs-comment"># 反向传播</span><br>        loss.backward()<br>        <span class="hljs-comment"># 更新权重</span><br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:  <span class="hljs-comment"># 每100个batch打印一次损失</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch [<span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>], Step [<span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_loader)&#125;</span>], Loss: <span class="hljs-subst">&#123;running_loss / <span class="hljs-number">100</span>:<span class="hljs-number">.4</span>f&#125;</span>&#x27;</span>)<br>            running_loss = <span class="hljs-number">0.0</span><br><br><span class="hljs-comment"># 测试网络</span><br>model.<span class="hljs-built_in">eval</span>()<br>correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> test_loader:<br>        outputs = model(inputs)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy of the network on the 10000 test images: <span class="hljs-subst">&#123;<span class="hljs-number">100</span> * correct / total:<span class="hljs-number">.2</span>f&#125;</span>%&#x27;</span>)<br><br><span class="hljs-comment"># 保存模型</span><br>torch.save(model.state_dict(), <span class="hljs-string">&quot;CNN_model.pth&quot;</span>)<br><br></code></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn          <span class="hljs-comment"># 神经网络模块</span><br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F <span class="hljs-comment"># 激活函数等</span><br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms <span class="hljs-comment"># 数据集和预处理</span><br><span class="hljs-comment"># 设置随机种子保证可重复性</span><br>torch.manual_seed(<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 数据准备</span><br>transform = transforms.Compose([<br>    transforms.ToTensor(),         <span class="hljs-comment"># 将PIL图像转为Tensor (0-1范围)</span><br>    transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,)) <span class="hljs-comment"># 标准化：(input - mean)/std</span><br>])<br><br>train_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,                 <span class="hljs-comment"># 数据存储路径</span><br>    train=<span class="hljs-literal">True</span>,                    <span class="hljs-comment"># 训练集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 关闭下载</span><br>    transform=transform            <span class="hljs-comment"># 应用预处理</span><br>)<br><br>test_dataset = datasets.MNIST(<br>    <span class="hljs-string">&#x27;./data&#x27;</span>,<br>    train=<span class="hljs-literal">False</span>,                   <span class="hljs-comment"># 测试集</span><br>    download=<span class="hljs-literal">False</span>,                <span class="hljs-comment"># 关闭下载</span><br>    transform=transform<br>)<br><br><span class="hljs-comment"># 定义神经网络模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleCNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleCNN, self).__init__()<br>        <span class="hljs-comment"># 第一个卷积层</span><br>        self.conv1 = nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        in_channels:输入数据的通道数</span><br><span class="hljs-string">        out_channels:输出数据的通道数,即卷积层中滤波器的数量，输出的特征图的通道数</span><br><span class="hljs-string">        kernel_size:卷积核（滤波器）的大小,3*3</span><br><span class="hljs-string">        padding:输入数据的边缘填充的像素数.</span><br><span class="hljs-string">        当 kernel_size=3 且 padding=1 时，输出特征图的高度和宽度与输入相同</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># 第二个卷积层</span><br>        self.conv2 = nn.Conv2d(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 最大池化层</span><br>        self.pool = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        在每个 2x2 的区域内，取最大值作为输出。</span><br><span class="hljs-string">        kernel_size:池化窗口的大小</span><br><span class="hljs-string">        stride:池化窗口滑动的步长</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-comment"># 全连接层</span><br>        self.fc1 = nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">128</span>)  <span class="hljs-comment"># MNIST图像经过两次池化后大小为7x7</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># MNIST有10个类别</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 通过第一个卷积层和激活函数</span><br>        x = F.relu(self.conv1(x))<br>        <span class="hljs-comment"># 通过第一个池化层</span><br>        x = self.pool(x)<br>        <span class="hljs-comment"># 通过第二个卷积层和激活函数</span><br>        x = F.relu(self.conv2(x))<br>        <span class="hljs-comment"># 通过第二个池化层</span><br>        x = self.pool(x)<br>        <span class="hljs-comment"># 展平张量</span><br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">64</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>)<br>        <span class="hljs-comment"># 通过第一个全连接层和激活函数</span><br>        x = F.relu(self.fc1(x))<br>        <span class="hljs-comment"># 通过第二个全连接层</span><br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 加载模型参数</span><br>model = SimpleCNN()<br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;CNN_model.pth&#x27;</span>))<br>model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 将模型设置为评估模式</span><br><br><span class="hljs-comment"># 推理</span><br><span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 禁用梯度计算</span><br>    <span class="hljs-keyword">for</span> image, label <span class="hljs-keyword">in</span> test_dataset:<br>        output = model(image.unsqueeze(<span class="hljs-number">0</span>))  <span class="hljs-comment"># 前向传播, 添加批量维度</span><br>        prediction = output.argmax(dim=<span class="hljs-number">1</span>).item()  <span class="hljs-comment"># 获取预测类别</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Predicted: <span class="hljs-subst">&#123;prediction&#125;</span>, Actual: <span class="hljs-subst">&#123;label&#125;</span>&#x27;</span>)<br><br><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-comment"># 加载单张图像</span><br>image_path = <span class="hljs-string">&#x27;path_to_your_image.png&#x27;</span>  <span class="hljs-comment"># 替换为你的图像路径</span><br>image = Image.<span class="hljs-built_in">open</span>(image_path).convert(<span class="hljs-string">&#x27;L&#x27;</span>)  <span class="hljs-comment"># 转换为灰度图像</span><br><br><span class="hljs-comment"># 预处理</span><br>image = transform(image).unsqueeze(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 添加batch维度</span><br><br><span class="hljs-comment"># 推理</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = model(image)<br>    _, predicted = torch.<span class="hljs-built_in">max</span>(output, <span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Predicted: <span class="hljs-subst">&#123;predicted.item()&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>神经网络基础（带数学公式、代码）</title>
    <link href="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/"/>
    <url>/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="一，神经网络结构"><a href="#一，神经网络结构" class="headerlink" title="一，神经网络结构"></a>一，神经网络结构</h1><img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/神经网络结构.jpg" width="40%"><ul><li>输入层：最简单的一层，每个结点就是一个变量，结点值就是变量值。</li><li>隐藏层：最复杂的一层，可以有多层，根据实际问题复杂情况进行选择。每个结点都为一个神经元。</li><li>输出层：如果是分类任务，输出层的结点数即为类别数，每个输出层结点也是一个神经元，但还附带分类器实现值到概率的转换。</li></ul><h1 id="二，前向传播（神经元的计算过程）"><a href="#二，前向传播（神经元的计算过程）" class="headerlink" title="二，前向传播（神经元的计算过程）"></a>二，前向传播（神经元的计算过程）</h1><p><img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/神经元.jpg" width="40%">    <img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/神经元组合.jpg" width="40%"></p><ul><li>前一层每个结点都有一个权值，Sum即为前一层所有结点的带权求和，Sgn即为激活函数，其目的是实现非线性组合以及实现最小梯度下降算法满足反向传播条件。</li></ul><h2 id="2-1激活函数"><a href="#2-1激活函数" class="headerlink" title="2.1激活函数"></a>2.1激活函数</h2><h3 id="2-1-1-饱和神经元激活函数"><a href="#2-1-1-饱和神经元激活函数" class="headerlink" title="2.1.1 饱和神经元激活函数"></a>2.1.1 饱和神经元激活函数</h3><ul><li>饱和的含义是任意 x 的输入，其对应的 y 输出的取值范围都位于一个区间内。</li></ul><ol><li>Sigmoid函数 $$ f(x)&#x3D;\frac{1}{1+e^{-x} } $$  <img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/sigmoid-1.jpg"><ul><li>函数输出范围是[0，1]，已经不太受欢迎了</li><li>函数输出不是以 0 为中心的，梯度可能就会向特定方向移动，从而降低权重更新的效率。</li><li>函数执行指数运算，计算机运行得较慢，比较消耗计算资源。</li></ul></li><li>Tanh函数  $$ f(x)&#x3D;\frac{e^{x}-e^{-x} }{e^{x}+e^{-x}} $$  <img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/tanh-1.jpg"><ul><li>函数输出范围是[-1，1]，以 0 为中心，不会向特定方向移动</li><li>依然进行的是指数运算</li></ul></li></ol><ul><li>上述两种激活函数在 x 值离中心较远时均会出现梯度消失现象。</li></ul><h3 id="2-1-2-非饱和神经元激活函数"><a href="#2-1-2-非饱和神经元激活函数" class="headerlink" title="2.1.2 非饱和神经元激活函数"></a>2.1.2 非饱和神经元激活函数</h3><ol><li>Relu函数  $$ f(x)&#x3D;\max (0,x) $$  <img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/relu-1.jpg"><ul><li>输出不是以0为中心的.</li><li>当输入为负时，梯度为0。这个神经元及之后的神经元梯度永远为0，不再对任何数据有所响应。因此学习率应当设置得较小。</li></ul></li><li>Leaky Relu函数  $$ f(x)&#x3D;\max (\alpha x,x) $$  <img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/LRelu-1.jpg"><ul><li>函数中的α，需要通过先验知识人工赋值（一般设为0.01）</li><li>有些近似线性，导致在复杂分类中效果不好</li><li>尚未完全证明 Leaky ReLU 总是比 ReLU 更好</li></ul></li></ol><h1 id="三，反向传播（链式法则）"><a href="#三，反向传播（链式法则）" class="headerlink" title="三，反向传播（链式法则）"></a>三，反向传播（链式法则）</h1><ul><li>损失函数对前一层对应结点的变量求偏导，中间隔着激活函数就用链式法则。</li><li>对于设定的步长，偏导函数值的<strong>相反数</strong>即为权重调整的大小。</li><li>用相反数是是为了满足变量的变化与函数变化的关系。</li></ul><h2 id="1-数学背景"><a href="#1-数学背景" class="headerlink" title="1. 数学背景"></a>1. 数学背景</h2><p>在神经网络中，每一层的线性输出 $ Z $ 和激活值 $ A $ 的关系如下：</p><p>$$<br>Z &#x3D; X \cdot W + b<br>$$</p><p>$$<br>A &#x3D; \sigma(Z)<br>$$</p><p>其中：</p><ul><li>$ X $ 是输入（或前一层的激活值）。</li><li>$ W $ 是权重矩阵。</li><li>$ b $ 是偏置向量。</li><li>$ \sigma $ 是激活函数（如 Sigmoid）。</li></ul><p>损失函数 $ L $ 对权重 $ W $ 的偏导数 $ \frac{\partial L}{\partial W} $ 可以通过链式法则计算：</p><p>$$<br>\frac{\partial L}{\partial W} &#x3D; \frac{\partial L}{\partial Z} \cdot \frac{\partial Z}{\partial W}<br>$$</p><hr><h2 id="2-链式法则的展开"><a href="#2-链式法则的展开" class="headerlink" title="2. 链式法则的展开"></a>2. 链式法则的展开</h2><h3 id="1-计算-frac-partial-L-partial-Z"><a href="#1-计算-frac-partial-L-partial-Z" class="headerlink" title="(1) 计算 $ \frac{\partial L}{\partial Z} $"></a>(1) 计算 $ \frac{\partial L}{\partial Z} $</h3><ul><li>$ \frac{\partial L}{\partial Z} $ 是损失函数对线性输出 $ Z $ 的偏导数，通常记作 $ dZ $。</li><li>对于输出层，$ dZ $ 可以直接通过损失函数和激活函数的导数计算得到。</li><li>对于隐藏层，$ dZ $ 通过后一层的梯度传播而来。</li></ul><h3 id="2-计算-frac-partial-Z-partial-W"><a href="#2-计算-frac-partial-Z-partial-W" class="headerlink" title="(2) 计算 $ \frac{\partial Z}{\partial W} $"></a>(2) 计算 $ \frac{\partial Z}{\partial W} $</h3><ul><li><p>线性输出 $ Z $ 对权重 $ W $ 的偏导数是输入 $ X $（或前一层的激活值 $ A_{\text{prev}} $）。</p></li><li><p>这是因为：</p><p>$$<br>Z &#x3D; X \cdot W + b<br>$$</p><p>对 $ W $ 求偏导时，$ X $ 是常数，因此：</p><p>$$<br>\frac{\partial Z}{\partial W} &#x3D; X^T<br>$$</p></li></ul><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><h3 id="1-前向传播"><a href="#1-前向传播" class="headerlink" title="(1) 前向传播"></a>(1) 前向传播</h3><p>$$<br>Z &#x3D; X \cdot W + b<br>$$</p><p>$$<br>A &#x3D; \sigma(Z)<br>$$</p><h3 id="2-反向传播"><a href="#2-反向传播" class="headerlink" title="(2) 反向传播"></a>(2) 反向传播</h3><ol><li><p>计算输出层的梯度 $ dZ $：</p><p>$$<br>dZ &#x3D; \frac{\partial L}{\partial Z} &#x3D; A - Y<br>$$</p></li><li><p>计算权重梯度 $ dW $：</p><p>$$<br>dW &#x3D; \frac{\partial L}{\partial W} &#x3D; X^T \cdot dZ<br>$$</p></li><li><p>更新权重：</p><p>$$<br>W &#x3D; W - \alpha \cdot dW<br>$$</p></li></ol><h1 id="四，Softmax分类器"><a href="#四，Softmax分类器" class="headerlink" title="四，Softmax分类器"></a>四，Softmax分类器</h1><p>Softmax函数：$$ Softmax(x)&#x3D;\frac{e^{x_i} }{ {\textstyle \sum_{i}^{}e^{x_i}} } $$   <img src="/2025/01/19/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E5%B8%A6%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%89/softmax-1.jpg"></p><ul><li>Softmax函数一般用于最后一层输出层，实现将最后的计算值转化为不同类别的概率，其中概率最大的就是预测类别。</li><li>用指数函数进行累加是为了增大不同值之间的区分度。</li></ul><h1 id="五，代码"><a href="#五，代码" class="headerlink" title="五，代码"></a>五，代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid_derivative</span>(<span class="hljs-params">sigmoid_x</span>):<br>    <span class="hljs-keyword">return</span> sigmoid_x * (<span class="hljs-number">1</span> - sigmoid_x)<br><br><span class="hljs-comment"># 初始化网络参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">initialize_parameters</span>(<span class="hljs-params">layer_dims</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    layer_dims: 列表，表示每一层的神经元数量，例如 [input_size, hidden_size1, hidden_size2, ..., output_size]</span><br><span class="hljs-string">    return: 参数字典，包含每一层的 W 和 b</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    np.random.seed(<span class="hljs-number">42</span>)<br>    parameters = &#123;&#125;<br>    L = <span class="hljs-built_in">len</span>(layer_dims)  <span class="hljs-comment"># 网络的总层数</span><br><br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L):<br>        parameters[<span class="hljs-string">f&#x27;W<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] = np.random.randn(layer_dims[l-<span class="hljs-number">1</span>], layer_dims[l]) * <span class="hljs-number">0.01</span><br>        parameters[<span class="hljs-string">f&#x27;b<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] = np.zeros((<span class="hljs-number">1</span>, layer_dims[l]))<br><br>    <span class="hljs-keyword">return</span> parameters<br><br><span class="hljs-comment"># 前向传播</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_propagation</span>(<span class="hljs-params">X, parameters</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    X: 输入数据</span><br><span class="hljs-string">    parameters: 参数字典</span><br><span class="hljs-string">    return: 最后一层的输出 A，以及缓存（包含每一层的 Z 和 A）</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    caches = []<br>    A = X<br>    L = <span class="hljs-built_in">len</span>(parameters) // <span class="hljs-number">2</span>  <span class="hljs-comment"># 网络的总层数（不包括输入层）</span><br><br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L+<span class="hljs-number">1</span>):<br>        W = parameters[<span class="hljs-string">f&#x27;W<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>]<br>        b = parameters[<span class="hljs-string">f&#x27;b<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>]<br>        Z = np.dot(A, W) + b  <span class="hljs-comment"># 全连接</span><br>        A = sigmoid(Z)  <span class="hljs-comment"># 激活函数</span><br>        caches.append((Z, A))  <span class="hljs-comment"># 缓存每一层的 Z 和 A</span><br><br>    <span class="hljs-keyword">return</span> A, caches<br><br><span class="hljs-comment"># 计算损失</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_loss</span>(<span class="hljs-params">A2, Y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    A2: 最后一层的输出</span><br><span class="hljs-string">    Y: 真实标签</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    m = Y.shape[<span class="hljs-number">0</span>]<br>    loss = -np.<span class="hljs-built_in">sum</span>(Y * np.log(A2) + (<span class="hljs-number">1</span> - Y) * np.log(<span class="hljs-number">1</span> - A2)) / m<br>    <span class="hljs-keyword">return</span> loss<br><br><span class="hljs-comment"># 反向传播</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">backward_propagation</span>(<span class="hljs-params">X, Y, parameters, caches</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    X: 输入数据</span><br><span class="hljs-string">    Y: 真实标签</span><br><span class="hljs-string">    parameters: 参数字典</span><br><span class="hljs-string">    caches: 缓存（包含每一层的 Z 和 A）</span><br><span class="hljs-string">    return: 梯度字典，包含每一层的 dW 和 db</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    gradients = &#123;&#125;<br>    L = <span class="hljs-built_in">len</span>(parameters) // <span class="hljs-number">2</span>  <span class="hljs-comment"># 网络的总层数（不包括输入层）</span><br>    m = X.shape[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-comment"># 最后一层的梯度</span><br>    A = caches[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]  <span class="hljs-comment"># 最后一层的输出</span><br>    dZ = A - Y<br>    dW = np.dot(caches[-<span class="hljs-number">2</span>][<span class="hljs-number">1</span>].T, dZ) / m  <span class="hljs-comment"># 倒数第二层的 A 是倒数第一层的输入</span><br>    db = np.<span class="hljs-built_in">sum</span>(dZ, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>) / m<br>    gradients[<span class="hljs-string">f&#x27;dW<span class="hljs-subst">&#123;L&#125;</span>&#x27;</span>] = dW<br>    gradients[<span class="hljs-string">f&#x27;db<span class="hljs-subst">&#123;L&#125;</span>&#x27;</span>] = db<br><br>    <span class="hljs-comment"># 从倒数第二层到第一层的梯度</span><br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L)):<br>        dA_prev = np.dot(dZ, parameters[<span class="hljs-string">f&#x27;W<span class="hljs-subst">&#123;l+<span class="hljs-number">1</span>&#125;</span>&#x27;</span>].T) <span class="hljs-comment"># 变化量的大小</span><br>        dZ = dA_prev * sigmoid_derivative(caches[l-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>])  <span class="hljs-comment"># 变化量与偏导值的乘积，即反向传播的变化量</span><br>        dW = np.dot(caches[l-<span class="hljs-number">2</span>][<span class="hljs-number">1</span>].T, dZ) / m <span class="hljs-keyword">if</span> l &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> np.dot(X.T, dZ) / m <span class="hljs-comment"># 损失函数对权重 W 的偏导数，Z=WX+B</span><br>        db = np.<span class="hljs-built_in">sum</span>(dZ, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>) / m<br>        gradients[<span class="hljs-string">f&#x27;dW<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] = dW<br>        gradients[<span class="hljs-string">f&#x27;db<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] = db<br><br>    <span class="hljs-keyword">return</span> gradients<br><br><span class="hljs-comment"># 更新参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update_parameters</span>(<span class="hljs-params">parameters, gradients, learning_rate</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    parameters: 参数字典</span><br><span class="hljs-string">    gradients: 梯度字典</span><br><span class="hljs-string">    learning_rate: 学习率</span><br><span class="hljs-string">    return: 更新后的参数字典</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    L = <span class="hljs-built_in">len</span>(parameters) // <span class="hljs-number">2</span><br><br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L+<span class="hljs-number">1</span>):<br>        parameters[<span class="hljs-string">f&#x27;W<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] -= learning_rate * gradients[<span class="hljs-string">f&#x27;dW<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] <span class="hljs-comment"># 梯度下降</span><br>        parameters[<span class="hljs-string">f&#x27;b<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] -= learning_rate * gradients[<span class="hljs-string">f&#x27;db<span class="hljs-subst">&#123;l&#125;</span>&#x27;</span>] <span class="hljs-comment"># 梯度下降</span><br><br>    <span class="hljs-keyword">return</span> parameters<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">X, Y, layer_dims, learning_rate, epochs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    X: 输入数据</span><br><span class="hljs-string">    Y: 真实标签</span><br><span class="hljs-string">    layer_dims: 列表，表示每一层的神经元数量</span><br><span class="hljs-string">    learning_rate: 学习率</span><br><span class="hljs-string">    epochs: 训练轮数</span><br><span class="hljs-string">    return: 训练后的参数字典</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    parameters = initialize_parameters(layer_dims)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        A, caches = forward_propagation(X, parameters)<br>        loss = compute_loss(A, Y)<br>        gradients = backward_propagation(X, Y, parameters, caches)<br>        parameters = update_parameters(parameters, gradients, learning_rate)<br>        <span class="hljs-built_in">print</span>(gradients)<br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;i&#125;</span>, Loss: <span class="hljs-subst">&#123;loss&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> parameters<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">X, parameters</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    X: 输入数据</span><br><span class="hljs-string">    parameters: 参数字典</span><br><span class="hljs-string">    return: 预测结果</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    A, _ = forward_propagation(X, parameters)<br>    predictions = np.<span class="hljs-built_in">round</span>(A)<br>    <span class="hljs-keyword">return</span> predictions<br><br><span class="hljs-comment"># 示例数据</span><br>X = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br>Y = np.array([[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>]])<br><br><span class="hljs-comment"># 定义网络结构</span><br>layer_dims = [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>]  <span class="hljs-comment"># 输入层 2 个神经元，两个隐藏层各 4 个神经元，输出层 1 个神经元</span><br><br><span class="hljs-comment"># 训练网络</span><br>learning_rate = <span class="hljs-number">0.1</span><br>epochs = <span class="hljs-number">10000</span><br>parameters = train(X, Y, layer_dims, learning_rate, epochs)<br><br><span class="hljs-comment"># 预测</span><br>predictions = predict(X, parameters)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Predictions:&quot;</span>, predictions)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>数据库系统概论笔记</title>
    <link href="/2025/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <url>/2025/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章   绪论"></a>第一章   绪论</h1><h2 id="1-1-数据库系统概述"><a href="#1-1-数据库系统概述" class="headerlink" title="1.1 数据库系统概述"></a><strong>1.1 数据库系统概述</strong></h2><h3 id="1-1-1-数据库的四个基本概念"><a href="#1-1-1-数据库的四个基本概念" class="headerlink" title="1.1.1 数据库的四个基本概念"></a><strong>1.1.1 数据库的四个基本概念</strong></h3><ol><li><p><strong>数据（Data）</strong>：描述事务的符号记录</p></li><li><p><strong>数据库（DB）</strong></p><ul><li>概括地讲，数据库具有<strong>永久存储</strong>、<strong>有组织</strong>和<strong>可共享</strong>的三个基本特点。</li><li>严格地讲，数据库是<strong>长期存储在计算机内、有组织的、可共享的大量数据的集合</strong>。数据库中的数据按一定的数据模型组织、描述和存储，具有较小的冗余、较高的数据独立性和易扩展性，并可为各种用户共享。</li></ul></li><li><p><strong>数据库管理系统（DBMS）</strong>：<strong>位于用户和操作系统之间的一层数据管理软件</strong>。和操作系统一样是计算机的基础软件。</p><pre><code class="hljs">主要功能：           1，数据定义功能           2，数据组织、存储和管理功能           3，数据操纵功能           4，数据库的事务管理和运行管理功能           5，数据库的建立和维护功能           6，其他功能（通信功能、数据转换功能、互访和互操作功能等）</code></pre></li><li><p><strong>数据库系统（DBS）</strong></p><ul><li>是由数据库、数据库管理系统（及其应用开发工具）、应用程序和数据库管理员（DBA）和用户组成的<strong>存储、管理、处理和维护数据的系统</strong>。</li><li>特点：<strong>数据结构化、数据共享性、数据独立性、DBMS的统一管理和控制</strong>。</li><li>数据独立性分为物理独立性和逻辑独立性。物理独立性意味着用户无需关心数据在磁盘上的存储方式，逻辑独立性指出即使数据库的逻辑结构发生变化，用户的应用程序也无需修改。</li></ul></li></ol><h3 id="1-1-2-数据库的发展阶段"><a href="#1-1-2-数据库的发展阶段" class="headerlink" title="1.1.2 数据库的发展阶段"></a><strong>1.1.2 数据库的发展阶段</strong></h3><table><thead><tr><th align="center">特点</th><th align="center">人工管理阶段</th><th align="center">文件系统阶段</th><th align="center">数据库系统阶段</th></tr></thead><tbody><tr><td align="center">数据管理者</td><td align="center">用户</td><td align="center">文件系统</td><td align="center">数据库管理系统</td></tr><tr><td align="center">数据面向的对象</td><td align="center">某一应用程序</td><td align="center">某一应用</td><td align="center">现实世界（某组织等）</td></tr><tr><td align="center">数据共享程度</td><td align="center">无共享，冗余度极大</td><td align="center">共享性差，冗余度大</td><td align="center">共享性高，冗余度小</td></tr><tr><td align="center">数据独立性</td><td align="center">不独立，完全依赖于程序</td><td align="center">独立性差</td><td align="center">具有高度的物理独立性和一定的逻辑独立性</td></tr><tr><td align="center">数据的结构化</td><td align="center">无结构</td><td align="center">记录内有结构，整体无结构</td><td align="center">整体结构化，用数据模型描述</td></tr><tr><td align="center">数据控制能力</td><td align="center">应用程序自己控制</td><td align="center">应用程序自己控制</td><td align="center">数据库管理系统控制</td></tr></tbody></table><h2 id="1-2-数据模型"><a href="#1-2-数据模型" class="headerlink" title="1.2 数据模型"></a><strong>1.2 数据模型</strong></h2><ul><li><p>对现实世界数据特征的抽象。</p><p>  第一类：  概念模型（信息模型）<br>  第二类：  逻辑模型，物理模型<br>  现实世界 —&gt; 信息世界（概念模型）—&gt; 机器世界<br>  现实世界 —-数据库设计人员—&gt; 概念模型，逻辑模型 —-数据库管理系统—-&gt; 物理模型</p></li></ul><h3 id="1-2-1-概念模型"><a href="#1-2-1-概念模型" class="headerlink" title="1.2.1 概念模型"></a><strong>1.2.1 概念模型</strong></h3><p>也称信息模型，它是按用户观点来对数据和信息建模，主要<strong>用于数据库设计</strong>。</p><ul><li>实体：客观存在并且可相互区别的事务</li><li>属性：实体所具有的某一特性</li><li>码：唯一标识实体的属性</li><li>实体型：用实体名及其属性集合来抽象和刻画同类实体</li><li>实体集：同一类型实体的集合</li><li>联系：实体之间的联系通常是指不同实体集之间的联系。实体之间的联系有一对一、一对多和多对多等联系。</li></ul><p>表示方法：<strong>E-R 图</strong>，分为实体、属性、关系三个核心部分，实体是长方形，属性是椭圆形，关系为菱形。</p><h3 id="1-2-2-逻辑模型"><a href="#1-2-2-逻辑模型" class="headerlink" title="1.2.2 逻辑模型"></a><strong>1.2.2 逻辑模型</strong></h3><p>按计算机系统的观点对数据建模，主要<strong>用于数据库管理系统的实现</strong>。</p><ul><li>层次模型</li><li>网状模型</li><li><strong>关系模型</strong></li><li>面向对象数据模型</li><li>对象关系数据模型</li><li>半结构化数据模型</li></ul><h3 id="1-2-3-物理模型"><a href="#1-2-3-物理模型" class="headerlink" title="1.2.3 物理模型"></a><strong>1.2.3 物理模型</strong></h3><p>对数据最底层的抽象，它描述数据在系统内部的表示方法和存取方法，或在磁盘&#x2F;磁带上的<strong>存储方式和存取方法</strong>，是面向计算机系统的。</p><h3 id="1-2-4-数据模型的组成要素"><a href="#1-2-4-数据模型的组成要素" class="headerlink" title="1.2.4 数据模型的组成要素"></a><strong>1.2.4 数据模型的组成要素</strong></h3><ul><li>数据结构</li><li>数据操作</li><li>数据的完整性约束：实体完整性，参照完整性，用户定义的完整性。</li></ul><h2 id="1-3-常用的数据模型"><a href="#1-3-常用的数据模型" class="headerlink" title="1.3 常用的数据模型"></a><strong>1.3 常用的数据模型</strong></h2><h3 id="1-3-1-层次模型（类似树与B树）"><a href="#1-3-1-层次模型（类似树与B树）" class="headerlink" title="1.3.1 层次模型（类似树与B树）"></a><strong>1.3.1 层次模型（类似树与B树）</strong></h3><h3 id="1-3-2-网状模型"><a href="#1-3-2-网状模型" class="headerlink" title="1.3.2 网状模型"></a><strong>1.3.2 网状模型</strong></h3><h3 id="1-3-1-关系模型（二维表）"><a href="#1-3-1-关系模型（二维表）" class="headerlink" title="1.3.1 关系模型（二维表）"></a><strong>1.3.1 关系模型（二维表）</strong></h3><ul><li>关系：一张表</li><li>关系模式：表头，表示为：关系名（属性1，属性2···）</li><li>元组：一行</li><li>属性：一列</li><li>码：唯一确定一个元组的属性组</li><li>域：属性的取值范围</li><li>分量：元组中的一个属性值（必须是不可分的数据项）</li><li>非规范关系：表中有表</li></ul><p>查询效率较低。</p><h2 id="1-4-数据库系统的结构"><a href="#1-4-数据库系统的结构" class="headerlink" title="1.4 数据库系统的结构"></a><strong>1.4 数据库系统的结构</strong></h2><h3 id="1-4-1-模式的概念"><a href="#1-4-1-模式的概念" class="headerlink" title="1.4.1 模式的概念"></a><strong>1.4.1 模式的概念</strong></h3><p>是<strong>数据库中全体数据的逻辑结构和特征的描述</strong>，它仅仅涉及型的描述，不涉及具体的值。一个具体值成为模式的一个实例。</p><ul><li>型：对某一类数据的结构和属性的说明。</li><li>值：型的一个具体赋值。</li></ul><p>模式是相对稳定的，实例是相对变动的。</p><h3 id="1-4-2-三级模式结构"><a href="#1-4-2-三级模式结构" class="headerlink" title="1.4.2 三级模式结构"></a><strong>1.4.2 三级模式结构</strong></h3><ol><li><strong>模式</strong>：也称逻辑模式&#x2F;概念模式，是<strong>数据库中全体数据的逻辑结构和特征的描述</strong>，是所有用户的公共数据视图。</li><li><strong>外模式</strong>：也称子模式或用户模式，它是数据库用户（包括应用程序员和最终用户）能够看见和使用的<strong>局部数据的逻辑结构和特征的描述</strong>，是数据库用户的数据视图，是与某一应用有关的数据的逻辑表示。</li><li><strong>内模式</strong>：也称存储模式，一个数据库只有一个内模式。它是<strong>数据物理结构和存储方式的描述</strong>，是数据在数据库内部的组织方式。</li></ol><h3 id="1-4-3-二级映像"><a href="#1-4-3-二级映像" class="headerlink" title="1.4.3 二级映像"></a><strong>1.4.3 二级映像</strong></h3><ol><li><strong>外模式&#x2F;模式映像</strong>：当模式改变时，由数据库管理员对各个外模式&#x2F;模式映像作相应改变，可以使外模式保持不变，应用程序不必修改。保证了数据与程序的<strong>逻辑独立性</strong>。</li><li><strong>模式&#x2F;内模式映像</strong>：当数据库的存储结构改变时，由数据库管理员对模式&#x2F;内模式映像作相应改变，可以使模式保持不变，从而应用程序也不用改变。保证了数据与程序的<strong>物理独立性</strong>。</li></ol><h3 id="1-4-4-联系"><a href="#1-4-4-联系" class="headerlink" title="1.4.4 联系"></a><strong>1.4.4 联系</strong></h3><ul><li>应用程序：外部视图 &lt;—&gt; 子模式</li><li>DBMS：模式 &lt;—&gt; 子模式</li><li>操作系统的存取方式：存储方式 &lt;—-&gt; 物理组织</li></ul><h2 id="1-5-数据库系统的组成"><a href="#1-5-数据库系统的组成" class="headerlink" title="1.5 数据库系统的组成"></a><strong>1.5 数据库系统的组成</strong></h2><ul><li>硬件平台及数据</li><li>软件</li><li>人员<ul><li><strong>数据库管理员</strong><ul><li>①决定数据库中的信息内容和结构</li><li>②决定数据库的存储结构和存取策略</li><li>③定义数据的安全性要求和完整性约束条件</li><li>④监控数据库的使用和运行</li><li>⑤数据库的改进和重组、重构</li></ul></li><li><strong>系统分析员</strong>：应用系统的需求分析和规范说明。</li><li><strong>数据库设计人员</strong>：数据库中数据的确定及数据库各级模式的设计。</li><li><strong>应用程序员</strong>：设计和编写应用系统的程序模块，并进行调试和安装。</li><li>用户：通过用户接口使用数据库。</li></ul></li></ul><h1 id="第二章-关系数据库"><a href="#第二章-关系数据库" class="headerlink" title="第二章 关系数据库"></a>第二章 关系数据库</h1><h2 id="2-1-关系数据结构及形式化定义"><a href="#2-1-关系数据结构及形式化定义" class="headerlink" title="2.1 关系数据结构及形式化定义"></a>2.1 关系数据结构及形式化定义</h2><h3 id="2-1-1-关系"><a href="#2-1-1-关系" class="headerlink" title="2.1.1 关系"></a>2.1.1 关系</h3><ul><li><p>目（度）：属性数</p></li><li><p>候选码：能唯一标识元组的最小属性组</p></li><li><p>超码：候选码+其它属性</p></li><li><p>主码：候选码中的一个（主关键字）</p></li><li><p>主属性：候选码的<strong>诸属性</strong>（其中之一）</p></li><li><p>非主属性（非码属性）：不包含在任何候选码中的属性</p></li><li><p>全码：所有属性都是候选码</p></li><li><p>关系的类型：基本关系（基本表），查询表，视图表</p><pre><code class="hljs">  基本关系：实际存储数据的逻辑表示。  查询表：查询结果对应的表。  视图表：导出表，虚表，不对应实际存储的数据。</code></pre></li></ul><p>元组&#x3D;记录</p><h3 id="2-1-2-关系模式"><a href="#2-1-2-关系模式" class="headerlink" title="2.1.2 关系模式"></a>2.1.2 关系模式</h3><p>R（U,D,DOM,F）</p><ul><li>R 关系名</li><li>U 所有属性名</li><li>D 属性来自哪些域</li><li>DOM 属性和域的映射</li><li>F 属性间的依赖关系</li></ul><p>一般简化为R（U）</p><h2 id="2-2-关系操作（语言）"><a href="#2-2-关系操作（语言）" class="headerlink" title="2.2 关系操作（语言）"></a>2.2 关系操作（语言）</h2><p>特点：集合操作方式，即操作的对象和结果都是集合。</p><ul><li>插入</li><li>查询，基本操作：<strong>选择、投影、并、差、笛卡尔积</strong><ul><li>非基本：</li><li><strong>连接</strong>：R⋈S &#x3D; 先选择+笛卡尔积（再投影）</li><li><strong>除</strong>：<img src="/2025/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%99%A4%E6%B3%95.jpg"><ul><li>R（X,Y），其中Y为共有属性。</li></ul></li><li><strong>交</strong>：R∩S &#x3D; R-(R-S)</li></ul></li><li>删除</li><li>修改</li></ul><h3 id="2-2-1-关系数据库基于数学上的关系代数运算和关系演算运算"><a href="#2-2-1-关系数据库基于数学上的关系代数运算和关系演算运算" class="headerlink" title="2.2.1 关系数据库基于数学上的关系代数运算和关系演算运算"></a>2.2.1 关系数据库基于数学上的关系代数运算和关系演算运算</h3><ul><li>关系数据语言：<ul><li>关系代数语言</li><li>关系演算语言</li><li>以上双重特点（SQL）</li></ul></li></ul><h3 id="2-2-2-SQL语言"><a href="#2-2-2-SQL语言" class="headerlink" title="2.2.2 SQL语言"></a>2.2.2 SQL语言</h3><h2 id="2-3-关系的完整性"><a href="#2-3-关系的完整性" class="headerlink" title="2.3 关系的完整性"></a>2.3 关系的完整性</h2><h3 id="2-3-1-实体完整性：主属性非空"><a href="#2-3-1-实体完整性：主属性非空" class="headerlink" title="2.3.1 实体完整性：主属性非空"></a>2.3.1 实体完整性：主属性非空</h3><h3 id="2-3-2-参照完整性：外码与主码之间的引用规则"><a href="#2-3-2-参照完整性：外码与主码之间的引用规则" class="headerlink" title="2.3.2 参照完整性：外码与主码之间的引用规则"></a>2.3.2 参照完整性：外码与主码之间的引用规则</h3><ul><li>外码：其它关系的主码（可以是本关系）。</li><li>外码取值为空值或主码值。</li><li>为空表示该记录与其它关系无关。</li></ul><h3 id="2-3-3-用户定义的完整性（CHECK）"><a href="#2-3-3-用户定义的完整性（CHECK）" class="headerlink" title="2.3.3 用户定义的完整性（CHECK）"></a>2.3.3 用户定义的完整性（CHECK）</h3><p>可选，实体完整性与参照完整性必须有。</p><h2 id="2-4-关系代数"><a href="#2-4-关系代数" class="headerlink" title="2.4 关系代数"></a>2.4 关系代数</h2><p><img src="/2025/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E4%BB%A3%E6%95%B0%E8%AF%AD%E8%A8%80.png"><br><img src="/2025/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%9D%A1%E4%BB%B6%E8%A1%A8%E8%BE%BE%E5%BC%8F.jpg"></p><h3 id="2-4-1-传统的集合运算（以元组为单位）"><a href="#2-4-1-传统的集合运算（以元组为单位）" class="headerlink" title="2.4.1 传统的集合运算（以元组为单位）"></a>2.4.1 传统的集合运算（以元组为单位）</h3><ol><li>并</li><li>差：R-S，在R中删掉S中也有的。</li><li>交</li><li>笛卡尔积</li></ol><ul><li>交并运算的两个关系都要有<strong>相同的属性</strong>。</li><li>差运算的两个关系<strong>属性个数</strong>和对应<strong>属性域</strong>必须相同。</li><li>交并差均是以元组为单位的操作。</li></ul><h3 id="2-4-2-专门的关系运算"><a href="#2-4-2-专门的关系运算" class="headerlink" title="2.4.2 专门的关系运算"></a>2.4.2 专门的关系运算</h3><ol><li><p>选择：在R中符合F条件的元组。</p></li><li><p>投影：R中的A列。（<strong>自动去重</strong>）</p></li><li><p>连接：R与S的笛卡尔积中满足条件的元组。</p><ul><li>等值连接 —&gt; 自然连接（合并同名属性） —保留悬浮元组–&gt; （左&#x2F;右）外连接</li></ul></li><li><p>除：R÷S，R、S相交属性中R对应独立属性的象集包含S的独立属性值。</p><ul><li>A属性的象集：除A属性外其它属性在特定A值下的不重复集合</li></ul></li></ol><h1 id="第三章-SQL语言"><a href="#第三章-SQL语言" class="headerlink" title="第三章 SQL语言"></a>第三章 SQL语言</h1><h2 id="3-1-SQL概述"><a href="#3-1-SQL概述" class="headerlink" title="3.1 SQL概述"></a>3.1 SQL概述</h2><ul><li>SQL 是 Structed Query Language 的缩写，意思是<strong>结构化查询语言</strong>，是关系数据库的标准语言。（通用、功能极强）</li><li>SQL对大小写不敏感。</li></ul><h2 id="3-1-1-SQL的特点"><a href="#3-1-1-SQL的特点" class="headerlink" title="3.1.1 SQL的特点"></a>3.1.1 SQL的特点</h2><ul><li>集<strong>数据定义语言（DDL）,数据操纵语言（DML），数据控制语言（DCL），数据查询语言</strong>的功能于一体。</li></ul><ol><li><strong>综合统一</strong><ul><li>可以独立完成数据库生命周期中的全部活动：<ul><li>定义和修改、删除关系模式，定义和删除试图，插入数据，建立数据库。</li><li>对数据库中的数据进行查询和更新。</li><li>数据库重构和维护。</li><li>数据库安全性、完整性控制，以及事务控制。</li><li>嵌入式SQL和动态SQL定义。</li></ul></li><li>用户在数据库投入运行后，可根据需要随时逐步修改模式，不影响数据库的运行。</li><li>数据操作府统一。</li></ul></li><li><strong>高度非过程化</strong><ul><li>用户无需了解存取路径。</li></ul></li><li><strong>面向集合的操作方式（集合 &#x3D; 表 &#x2F; 关系）</strong></li><li><strong>以同一种语法结构提供多种使用方式</strong></li><li><strong>语言简洁，易学易用</strong><table><thead><tr><th align="center">SQL功能</th><th align="center">动词</th></tr></thead><tbody><tr><td align="center">数据查询</td><td align="center">SELECT</td></tr><tr><td align="center">数据定义</td><td align="center">CREATE,DROP,ALTER</td></tr><tr><td align="center">数据操纵</td><td align="center">INSERT,UPDATE,DELETE</td></tr><tr><td align="center">数据控制</td><td align="center">GRANT,REVOKE</td></tr></tbody></table></li></ol><h2 id="3-2-数据定义"><a href="#3-2-数据定义" class="headerlink" title="3.2 数据定义"></a>3.2 数据定义</h2><table><thead><tr><th align="center">数据类型</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">CHAR(n)</td><td align="center">长度为n的定长字符串</td></tr><tr><td align="center">VARCHAR(n)</td><td align="center">最大长度为n的变长字符串</td></tr><tr><td align="center">INT</td><td align="center">长整数（4字节）</td></tr><tr><td align="center">SMALLINT</td><td align="center">短整数（2字节）</td></tr><tr><td align="center">BIGINT</td><td align="center">大整数（8字节）</td></tr><tr><td align="center">NUMERIC(p,q)</td><td align="center">定点数，p位数字，小数点后有q位</td></tr><tr><td align="center">DECIMAL(p,q)</td><td align="center">定点数，p位数字，小数点后有q位</td></tr><tr><td align="center">FLOAT(n)</td><td align="center">可选精度的浮点数，精度至少为n位数字</td></tr><tr><td align="center">BOOLEAN</td><td align="center">逻辑布尔量</td></tr><tr><td align="center">DATE</td><td align="center">年-月-日</td></tr><tr><td align="center">TIME</td><td align="center">时-分-秒</td></tr></tbody></table><table><thead><tr><th align="center">操作对象</th><th align="center">创建</th><th align="center">删除</th><th align="center">修改</th></tr></thead><tbody><tr><td align="center">模式</td><td align="center">CREATE SCHEMA</td><td align="center">DROP SCHEMA</td><td align="center">|</td></tr><tr><td align="center">表</td><td align="center">CREATE TABLE</td><td align="center">DROP TABLE</td><td align="center">ALTER TABLE</td></tr><tr><td align="center">视图</td><td align="center">CREATE VIEW</td><td align="center">DROP VIEW</td><td align="center">|</td></tr><tr><td align="center">索引</td><td align="center">CREATE INDEX</td><td align="center">DROP INDEX</td><td align="center">ALTER INDEX</td></tr></tbody></table><h3 id="3-2-1-模式的定义与删除"><a href="#3-2-1-模式的定义与删除" class="headerlink" title="3.2.1 模式的定义与删除"></a>3.2.1 模式的定义与删除</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 定义</span><br><span class="hljs-keyword">CREATE</span> SCHEMA <span class="hljs-operator">&lt;</span>模式名<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">AUTHORIZATION</span> <span class="hljs-operator">&lt;</span>用户名<span class="hljs-operator">&gt;</span>;<br><span class="hljs-keyword">CREATE</span> SCHEMA &quot;S-T&quot; <span class="hljs-keyword">AUTHORIZATION</span> Panzhicheng;<br><br><span class="hljs-comment">-- 删除</span><br><span class="hljs-keyword">DROP</span> SCHEMA <span class="hljs-operator">&lt;</span>模式名<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>CASCADE <span class="hljs-operator">|</span> RESTRICT<span class="hljs-operator">&gt;</span>;<br><span class="hljs-comment">-- CASCADE 级联：删除模式的同时也会把该模式的所有数据库对象删除。</span><br><span class="hljs-comment">-- RESTRICT 限制：如果该模式下有下属对象，比如表视图，就拒绝这个删除语句的执行。</span><br></code></pre></td></tr></table></figure><h3 id="3-2-2-基本表的定义、修改与删除"><a href="#3-2-2-基本表的定义、修改与删除" class="headerlink" title="3.2.2 基本表的定义、修改与删除"></a>3.2.2 基本表的定义、修改与删除</h3><p>1.定义</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span> (<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>数据类型<span class="hljs-operator">&gt;</span> [<span class="hljs-operator">&lt;</span>列级完整性约束条件<span class="hljs-operator">&gt;</span>]<br>[,(<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>数据类型<span class="hljs-operator">&gt;</span> [<span class="hljs-operator">&lt;</span>列级完整性约束条件<span class="hljs-operator">&gt;</span>]]···<br>                    [,表级完整性约束条件]);<br><span class="hljs-comment">-- 关键字可忽略大小写</span><br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">User</span>(name <span class="hljs-type">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">primary</span> key,  <span class="hljs-comment">-- 列级完整性约束条件（name为主码）</span><br>                  age <span class="hljs-type">int</span>,<br>                  sex <span class="hljs-type">char</span>(<span class="hljs-number">1</span>) <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> <span class="hljs-keyword">default</span> <span class="hljs-string">&#x27;男&#x27;</span>,  <span class="hljs-comment">-- 列级完整性约束条件（not null，默认条件）</span><br>                  <span class="hljs-keyword">FOREIGN</span> KEY (name) <span class="hljs-keyword">REFERENCES</span> Student(name)); <span class="hljs-comment">-- 表级完整性约束条件，name是外码，被参照表是Student</span><br></code></pre></td></tr></table></figure><p>2.修改</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span><br>[<span class="hljs-keyword">ADD</span> [<span class="hljs-keyword">COLUMN</span>] <span class="hljs-operator">&lt;</span>新列名<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>数据类型<span class="hljs-operator">&gt;</span> [完整性约束]] <span class="hljs-comment">-- 增加新列，列级完整性约束条件</span><br>[<span class="hljs-keyword">ADD</span> <span class="hljs-operator">&lt;</span>表级完整性约束<span class="hljs-operator">&gt;</span>] <span class="hljs-operator">/</span><span class="hljs-operator">/</span>增加表级完整性约束条件<br>[<span class="hljs-keyword">DROP</span> [<span class="hljs-keyword">COLUMN</span>] <span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span>[<span class="hljs-operator">&lt;</span>CASCADE <span class="hljs-operator">|</span> RESTRICT<span class="hljs-operator">&gt;</span>]] <span class="hljs-operator">/</span><span class="hljs-operator">/</span>删除列<br>[<span class="hljs-keyword">DROP</span> <span class="hljs-keyword">CONSTRAINT</span> <span class="hljs-operator">&lt;</span>完整性约束名<span class="hljs-operator">&gt;</span>[<span class="hljs-operator">&lt;</span>CASCADE <span class="hljs-operator">|</span> RESTRICT<span class="hljs-operator">&gt;</span>]] <span class="hljs-comment">-- 删除指定完整性约束条件</span><br>[<span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">COLUMN</span> <span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span><span class="hljs-operator">&lt;</span>新的数据类型<span class="hljs-operator">&gt;</span>] <span class="hljs-operator">/</span><span class="hljs-operator">/</span>修改列数据类型<br>[RENAME <span class="hljs-keyword">COLUMN</span> <span class="hljs-operator">&lt;</span>旧列名<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">TO</span> <span class="hljs-operator">&lt;</span>新列名<span class="hljs-operator">&gt;</span>]; <span class="hljs-operator">/</span><span class="hljs-operator">/</span>修改列名<br></code></pre></td></tr></table></figure><p>3.删除</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span>[<span class="hljs-operator">&lt;</span>CASCADE <span class="hljs-operator">|</span> RESTRICT<span class="hljs-operator">&gt;</span>];<br><span class="hljs-comment">-- CASCADE 如果表有外码，视图，触发器，也会强行删除。</span><br><span class="hljs-comment">-- RESTRICT 反之。</span><br></code></pre></td></tr></table></figure><h3 id="3-2-3-索引的建立、修改与删除"><a href="#3-2-3-索引的建立、修改与删除" class="headerlink" title="3.2.3 索引的建立、修改与删除"></a>3.2.3 索引的建立、修改与删除</h3><ul><li>数据量比较大的时候，查询耗时大，建立索引可以有效减少时间消耗。</li><li>索引可以建立在一列或多列上。</li><li>用户无法显式地选择索引。<blockquote><p>索引类型：</p><ul><li>顺序文件上的索引</li><li>B+树索引</li><li>散列（hash）索引</li><li>位图索引</li></ul></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 建立</span><br><span class="hljs-keyword">CREATE</span> [<span class="hljs-keyword">UNIQUE</span>] [CLUSTER] INDEX <span class="hljs-operator">&lt;</span>索引名<span class="hljs-operator">&gt;</span><br><span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span> (<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span>[<span class="hljs-operator">&lt;</span>次序<span class="hljs-operator">&gt;</span>][,<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span>[<span class="hljs-operator">&lt;</span>次序<span class="hljs-operator">&gt;</span>]]···)；<span class="hljs-comment">-- 升序：ASC（默认），降序：DESC</span><br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">UNIQUE</span> INDEX Stusno<br><span class="hljs-keyword">ON</span> Student(Sno);<br><br><span class="hljs-comment">-- UNIQUE 唯一索引</span><br><span class="hljs-comment">-- CLUSTER 聚簇索引：物理顺序与索引的逻辑顺序相同，比如买书。</span><br><br><br><span class="hljs-comment">-- 修改</span><br><span class="hljs-keyword">ALTER</span> INDEX <span class="hljs-operator">&lt;</span>旧索引名<span class="hljs-operator">&gt;</span> RENAME <span class="hljs-keyword">TO</span> <span class="hljs-operator">&lt;</span>新索引名<span class="hljs-operator">&gt;</span>;<br><br><span class="hljs-comment">-- 删除</span><br><span class="hljs-keyword">DROP</span> INDEX <span class="hljs-operator">&lt;</span>索引名<span class="hljs-operator">&gt;</span>;<br></code></pre></td></tr></table></figure><h3 id="3-2-4-数据字典"><a href="#3-2-4-数据字典" class="headerlink" title="3.2.4 数据字典"></a>3.2.4 数据字典</h3><ul><li>数据字典是关系数据库管理系统内部的一组系统表，它记录了数据库中<strong>所有的定义信息</strong>。</li><li>包括关系模式定义、视图定义、索引定义、完整性约束定义、各类用户对数据库的操作权限、统计信息等。</li><li>关系数据库管理系统在执行SQL 的数据定义语句时，实际上就是在更新数据字典表中的相应信息。</li></ul><h2 id="3-3-数据查询"><a href="#3-3-数据查询" class="headerlink" title="3.3 数据查询"></a>3.3 数据查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 基础架构</span><br><span class="hljs-keyword">SELECT</span> [<span class="hljs-keyword">ALL</span> <span class="hljs-operator">|</span> <span class="hljs-keyword">DISTINCT</span>] <span class="hljs-operator">&lt;</span>目标表达式<span class="hljs-operator">&gt;</span> [, <span class="hljs-operator">&lt;</span>目标表达式<span class="hljs-operator">&gt;</span>...] ... <span class="hljs-comment">-- DISTINCT：去重</span><br><span class="hljs-keyword">FROM</span> <span class="hljs-operator">&lt;</span>表名或视图名<span class="hljs-operator">&gt;</span> [, <span class="hljs-operator">&lt;</span>表名或视图名<span class="hljs-operator">&gt;</span>..]     <span class="hljs-comment">-- 或者再写个子查询</span><br>[<span class="hljs-keyword">WHERE</span> <span class="hljs-operator">&lt;</span>条件表达式<span class="hljs-operator">&gt;</span>]     <span class="hljs-comment">-- 不能用聚集函数</span><br>[<span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> <span class="hljs-operator">&lt;</span>列名 <span class="hljs-number">1</span><span class="hljs-operator">&gt;</span> [<span class="hljs-keyword">HAVING</span> <span class="hljs-operator">&lt;</span>条件表达式<span class="hljs-operator">&gt;</span>]] <span class="hljs-comment">-- HAVING是分组后的筛选，WHERE是分组前</span><br>[<span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> <span class="hljs-operator">&lt;</span>列名 <span class="hljs-number">2</span><span class="hljs-operator">&gt;</span> [<span class="hljs-keyword">ASC</span> <span class="hljs-operator">|</span> <span class="hljs-keyword">DESC</span>]];<br><br><span class="hljs-comment">-- 常用模式</span><br><span class="hljs-keyword">SELECT</span> ···  <span class="hljs-keyword">FROM</span> ···  <span class="hljs-keyword">WHERE</span> ··· <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> ··· <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> ··· ；<br></code></pre></td></tr></table></figure><ul><li>重点：顺序为   where  –&gt;  group by  –&gt;  having</li></ul><p>以下查询根据这三个表：</p><ul><li>学生表：student(*sno,sname,ssex,sage,sdept)</li><li>课程表：course(*cno,cname,cpno,ccredit)</li><li>学生选课表：sc(*sno,cno,grade)</li></ul><h3 id="3-3-1-单表查询"><a href="#3-3-1-单表查询" class="headerlink" title="3.3.1 单表查询"></a>3.3.1 单表查询</h3><table><thead><tr><th align="center">查询条件</th><th align="center">谓词</th></tr></thead><tbody><tr><td align="center">比较</td><td align="center">&#x3D;, &lt;, &gt; ,&lt;&#x3D;, &gt;&#x3D;, !&#x3D;, NOT+比较</td></tr><tr><td align="center">确定范围</td><td align="center">BETWEEN X AND Y,NOT BETWEEN X AND Y</td></tr><tr><td align="center">确定集合</td><td align="center">IN,NOT IN</td></tr><tr><td align="center">字符匹配</td><td align="center">LIKE,NOT LIKE</td></tr><tr><td align="center">空值</td><td align="center">ISNULL,ISNOTNULL</td></tr><tr><td align="center">逻辑运算</td><td align="center">AND,OR,NOT</td></tr></tbody></table><ul><li>between：双边闭区间</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 例子</span><br><span class="hljs-comment">-- 起别名，表达式，处理函数</span><br><span class="hljs-keyword">SELECT</span> sname <span class="hljs-keyword">as</span> <span class="hljs-string">&#x27;姓名&#x27;</span>,<span class="hljs-number">2023</span><span class="hljs-operator">-</span>sage <span class="hljs-string">&#x27;出生年月&#x27;</span>,<span class="hljs-built_in">LOWER</span>(sdept) <span class="hljs-keyword">FROM</span> student;<br><span class="hljs-comment">-- 全选</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student;<br><span class="hljs-comment">-- 年龄范围 BETWEEN</span><br><span class="hljs-keyword">SELECT</span> sname,<span class="hljs-number">2023</span><span class="hljs-operator">-</span>sage,sdept <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sage <span class="hljs-keyword">BETWEEN</span> <span class="hljs-number">20</span> <span class="hljs-keyword">AND</span> <span class="hljs-number">25</span>;<br><span class="hljs-comment">-- 集合，IN</span><br><span class="hljs-keyword">SELECT</span> sname,<span class="hljs-number">2023</span><span class="hljs-operator">-</span>sage <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sdept <span class="hljs-keyword">IN</span> (<span class="hljs-string">&#x27;CS&#x27;</span>,<span class="hljs-string">&#x27;IS&#x27;</span>);<br><span class="hljs-comment">-- 字符匹配，模糊查询，LIKE，查找刘姓学生</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sname <span class="hljs-keyword">LIKE</span> <span class="hljs-string">&#x27;刘%&#x27;</span>; <span class="hljs-comment">-- %：任意长度。</span><br>  <span class="hljs-comment">-- _：单个长度任意字符</span><br><span class="hljs-comment">-- 不想使用%和_模糊查找可以使用\转义，\_  \%</span><br><br><span class="hljs-comment">-- ORDER BY</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sname <span class="hljs-keyword">LIKE</span> <span class="hljs-string">&#x27;刘%&#x27;</span> <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> grade <span class="hljs-keyword">ASC</span>; <span class="hljs-comment">-- 升序，默认升序</span><br><span class="hljs-comment">-- 先grade排，再sage排</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> grade <span class="hljs-keyword">ASC</span>,sage <span class="hljs-keyword">ASC</span>;<br></code></pre></td></tr></table></figure><table><thead><tr><th align="center">聚集函数</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">COUNT(*)</td><td align="center">统计元组个数</td></tr><tr><td align="center">COUNT([ALL&#x2F;DISTINCT]&lt;列名&gt;)</td><td align="center">统计列中值的个数</td></tr><tr><td align="center">SUM([ALL&#x2F;DISTINCT]&lt;列名&gt;)</td><td align="center">计算一列值的总和（必须数值型）</td></tr><tr><td align="center">AVG([ALL&#x2F;DISTINCT]&lt;列名&gt;)</td><td align="center">计算一列值的平均值（必须数值型）</td></tr><tr><td align="center">MAX([ALL&#x2F;DISTINCT]&lt;列名&gt;)</td><td align="center">求一列值中的最大值</td></tr><tr><td align="center">MIN([ALL&#x2F;DISTINCT]&lt;列名&gt;)</td><td align="center">求一列值中的最小值</td></tr></tbody></table><ul><li>聚集函数不能用在WHERE子句中</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 例子</span><br><span class="hljs-comment">-- 查询学生总人数</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-built_in">COUNT</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">FROM</span> student;<br><span class="hljs-comment">-- 计算一号课程的平均成绩</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-built_in">AVG</span>(grade) <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">WHERE</span> cno<span class="hljs-operator">=</span><span class="hljs-number">1</span>;<br><span class="hljs-comment">-- 计算学号为202123学生的总成绩</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-built_in">SUM</span>(grade) <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">WHERE</span> sno<span class="hljs-operator">=</span><span class="hljs-number">202123</span>;<br><span class="hljs-comment">-- 求各个课程号的选课人数</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-built_in">COUNT</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> cno;<br></code></pre></td></tr></table></figure><h3 id="3-3-2-连接查询"><a href="#3-3-2-连接查询" class="headerlink" title="3.3.2 连接查询"></a>3.3.2 连接查询</h3><p>本质上就是FROM后有多个表，相当于引用了<strong>多表的笛卡尔积</strong>，其它操作与单表查询相同。</p><ul><li>等值连接</li><li>自身连接</li><li>外连接：保留不符合条件的元组</li><li>多表连接：两个以上的表进行查询</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 例子</span><br><span class="hljs-comment">-- 等值连接</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student stu,sc <span class="hljs-keyword">WHERE</span> stu.sno <span class="hljs-operator">=</span> sc.sno; <span class="hljs-comment">-- 引用的两个表是笛卡尔积形式</span><br><span class="hljs-comment">-- 自然连接(等值连接去掉重复属性列)</span><br><span class="hljs-keyword">SELECT</span> stu.cno,stu.sname,sc.cno <span class="hljs-keyword">FROM</span> student stu,sc <span class="hljs-keyword">WHERE</span> stu.sno <span class="hljs-operator">=</span> sc.sno;<br><span class="hljs-comment">-- 自身连接(给同一个表起两个别名)</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> course f,course s <span class="hljs-keyword">WHERE</span> f.cpno <span class="hljs-operator">=</span> s.cno;<br><span class="hljs-comment">-- 外连接</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> course f <span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> course s <span class="hljs-keyword">on</span> f.cpno <span class="hljs-operator">=</span> s.cno; <span class="hljs-comment">-- 左外连接(保留所有f)</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> course f <span class="hljs-keyword">right</span> <span class="hljs-keyword">join</span> course s <span class="hljs-keyword">on</span> f.cpno <span class="hljs-operator">=</span> s.cno; <span class="hljs-comment">-- 右外连接(保留所有s)</span><br><br></code></pre></td></tr></table></figure><h3 id="3-3-3-嵌套查询-往往可用连接查询解决"><a href="#3-3-3-嵌套查询-往往可用连接查询解决" class="headerlink" title="3.3.3 嵌套查询(往往可用连接查询解决)"></a>3.3.3 嵌套查询(往往可用连接查询解决)</h3><p>从后往前写</p><ul><li>查询块：一个 SELECT–FROM–WHERE 语句。</li><li>嵌套查询：一个查询块在另一个查询块的 WHERE 或 HAVING 语句中。</li><li>父查询：上层查询块。</li><li>子查询：下层查询块。（不能使用 ORDER BY 语句）</li><li>不相关子查询：子查询的查询条件不依赖于父查询。</li><li>相关子查询：子查询的查询条件依赖于父查询。</li></ul><p>1.带有 IN 谓词的子查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student stu <span class="hljs-keyword">WHERE</span> sno <span class="hljs-keyword">in</span> (<span class="hljs-keyword">SELECT</span> sno <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">WHERE</span> cno<span class="hljs-operator">=</span><span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure><p>2.带有 ANY,ALL 谓词的子查询（配合比较运算符）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> sno,cno <span class="hljs-keyword">FROM</span> sc x <span class="hljs-comment">-- 使用聚集函数</span><br><span class="hljs-keyword">WHERE</span> grade <span class="hljs-operator">&gt;=</span> (<br>    <span class="hljs-keyword">SELECT</span> <span class="hljs-built_in">AVG</span>(grade) <span class="hljs-keyword">FROM</span> sc y <span class="hljs-keyword">WHERE</span> x.sno<span class="hljs-operator">=</span>y.sno<br>    );<br><br><span class="hljs-keyword">SELECT</span> sname,sage <span class="hljs-keyword">FROM</span> student  <span class="hljs-comment">-- 一个值</span><br><span class="hljs-keyword">WHERE</span> sage <span class="hljs-operator">&gt;=</span><span class="hljs-keyword">ANY</span>(<br>    <span class="hljs-keyword">SELECT</span> sage <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sdept<span class="hljs-operator">=</span><span class="hljs-string">&#x27;CS&#x27;</span><br>    ) <span class="hljs-keyword">AND</span> sdept <span class="hljs-operator">!=</span> <span class="hljs-string">&#x27;CS&#x27;</span>;<br><br><span class="hljs-keyword">SELECT</span> sname,sage <span class="hljs-keyword">FROM</span> student  <span class="hljs-comment">-- 所有值</span><br><span class="hljs-keyword">WHERE</span> sage <span class="hljs-operator">&gt;=</span><span class="hljs-keyword">ALL</span>(<br>    <span class="hljs-keyword">SELECT</span> sage <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sdept<span class="hljs-operator">=</span><span class="hljs-string">&#x27;CS&#x27;</span><br>    ) <span class="hljs-keyword">AND</span> sdept <span class="hljs-operator">!=</span> <span class="hljs-string">&#x27;CS&#x27;</span>;<br></code></pre></td></tr></table></figure><p>3.带有（NOT）EXISTS 谓词的子查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-number">1.</span>存在量词，有一个或多个记录存在于。<br><span class="hljs-number">2.</span>带有 <span class="hljs-keyword">EXISTS</span> 谓词的子查询不返回任何数据，只产生逻辑值<span class="hljs-string">&#x27;true&#x27;</span>和<span class="hljs-string">&#x27;false&#x27;</span>。<br>若内层查询结果为空，则外层的<span class="hljs-keyword">WHERE</span>子句返回假值<span class="hljs-string">&#x27;false&#x27;</span>;<br>        若内层查询结果非空，则外层的<span class="hljs-keyword">WHERE</span>子句返回假值<span class="hljs-string">&#x27;TRUE&#x27;</span>;<br>    <span class="hljs-number">3.</span>目标列表达式通常是<span class="hljs-operator">*</span>，因为具体列名无实际意义。<br><span class="hljs-keyword">SELECT</span> sname <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> <span class="hljs-keyword">EXISTS</span> (<br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">WHERE</span> sno<span class="hljs-operator">=</span>student.sno <span class="hljs-keyword">AND</span> cno<span class="hljs-operator">=</span><span class="hljs-string">&#x27;1&#x27;</span><br>);  <span class="hljs-comment">-- 返回sname存在子查询中的记录。</span><br><br></code></pre></td></tr></table></figure><h3 id="3-3-4-集合查询"><a href="#3-3-4-集合查询" class="headerlink" title="3.3.4 集合查询"></a>3.3.4 集合查询</h3><ul><li><strong>并操作</strong>：UNION[all]</li><li><strong>交操作</strong>：INTERSECT</li><li><strong>差操作</strong>：EXCEPT</li><li>加all不去重</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-comment">-- 1. 并操作</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sdept<span class="hljs-operator">=</span><span class="hljs-string">&#x27;cs&#x27;</span><br><span class="hljs-keyword">UNION</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> ssge<span class="hljs-operator">=</span><span class="hljs-number">19</span>;<br><br><span class="hljs-comment">-- 2. 交操作</span><br><span class="hljs-keyword">SELECT</span> sno <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">WHERE</span> cno<span class="hljs-operator">=</span><span class="hljs-string">&#x27;1&#x27;</span><br><span class="hljs-keyword">INTERSECT</span><br><span class="hljs-keyword">SELECT</span> sno <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">WHERE</span> cno<span class="hljs-operator">=</span><span class="hljs-string">&#x27;2&#x27;</span>;<br><br><span class="hljs-comment">-- 3. 差操作(前-后)</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sdept<span class="hljs-operator">=</span><span class="hljs-string">&#x27;cs&#x27;</span><br><span class="hljs-keyword">EXCEPT</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> ssge <span class="hljs-operator">&lt;=</span> <span class="hljs-number">19</span>;<br></code></pre></td></tr></table></figure><h3 id="3-3-5-基于派生表的查询"><a href="#3-3-5-基于派生表的查询" class="headerlink" title="3.3.5 基于派生表的查询"></a>3.3.5 基于派生表的查询</h3><p>子查询出现在 FROM 子句中，成为临时<strong>派生表</strong>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- FROM子句中的派生表必须指定别名。</span><br><span class="hljs-comment">-- 派生表中的SELECT语句包含聚集函数时需要为其指定别名。</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> sc,(<span class="hljs-keyword">SELECT</span> sno,<span class="hljs-built_in">AVG</span>(grade) avg_grade <span class="hljs-keyword">FROM</span> sc <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> sno) <span class="hljs-keyword">as</span> savg<br><span class="hljs-keyword">WHERE</span> sc.sno <span class="hljs-operator">=</span> savg.sno <span class="hljs-keyword">AND</span> sc.grade <span class="hljs-operator">&gt;</span> savg.avg_grade;<br><br></code></pre></td></tr></table></figure><h2 id="3-4-数据更新"><a href="#3-4-数据更新" class="headerlink" title="3.4 数据更新"></a>3.4 数据更新</h2><h3 id="3-4-1-插入"><a href="#3-4-1-插入" class="headerlink" title="3.4.1 插入"></a>3.4.1 插入</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 1. 插入元组 ------------------------------</span><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span> [(<span class="hljs-operator">&lt;</span>属性列 <span class="hljs-number">1</span><span class="hljs-operator">&gt;</span> [, <span class="hljs-operator">&lt;</span>属性列 <span class="hljs-number">2</span><span class="hljs-operator">&gt;</span> ...])]<br><span class="hljs-keyword">VALUES</span> (<span class="hljs-operator">&lt;</span>常量 <span class="hljs-number">1</span><span class="hljs-operator">&gt;</span> [, <span class="hljs-operator">&lt;</span>常量 <span class="hljs-number">2</span><span class="hljs-operator">&gt;</span>...]);<br><span class="hljs-comment">-- 不指明属性则必须每个属性按序都有；指明则则按照指明的顺序，少的空值。</span><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> student<br><span class="hljs-keyword">VALUES</span> (<span class="hljs-number">201215128</span>,<span class="hljs-string">&#x27;陈东&#x27;</span>,<span class="hljs-string">&#x27;男&#x27;</span>,<span class="hljs-number">18</span>,<span class="hljs-string">&#x27;IS&#x27;</span>);<br><br><span class="hljs-comment">-- 2. 插入子查询结果 ---------------------------------</span><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span> [(<span class="hljs-operator">&lt;</span>属性列 <span class="hljs-number">1</span><span class="hljs-operator">&gt;</span> [, <span class="hljs-operator">&lt;</span>属性列 <span class="hljs-number">2</span><span class="hljs-operator">&gt;</span> ...])]<br>子查询；<br><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> student(sname,sage)<br><span class="hljs-keyword">SELECT</span> sname,sage <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sage<span class="hljs-operator">&gt;</span><span class="hljs-number">18</span>;<br></code></pre></td></tr></table></figure><h3 id="3-4-2-修改"><a href="#3-4-2-修改" class="headerlink" title="3.4.2 修改"></a>3.4.2 修改</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">UPDATE</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span><br><span class="hljs-keyword">SET</span> <span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;=</span><span class="hljs-operator">&lt;</span>表达式<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;=</span><span class="hljs-operator">&lt;</span>表达式<span class="hljs-operator">&gt;</span>] ··· <span class="hljs-comment">-- 修改属性列为什么值</span><br>[<span class="hljs-keyword">WHERE</span> <span class="hljs-operator">&lt;</span>条件<span class="hljs-operator">&gt;</span>];  <span class="hljs-comment">-- 不加条件就全部修改</span><br><br><span class="hljs-keyword">UPDATE</span> student<br><span class="hljs-keyword">SET</span> sage<span class="hljs-operator">=</span><span class="hljs-number">22</span>    <span class="hljs-comment">-- SET sage = sage + 1  年龄全部自增1</span><br><span class="hljs-keyword">WHERE</span> sno<span class="hljs-operator">=</span><span class="hljs-number">2012158</span>;<br><br><span class="hljs-comment">-- 带子查询的修改 ------</span><br><span class="hljs-keyword">UPDATE</span> student<br><span class="hljs-keyword">SET</span> sage<span class="hljs-operator">=</span><span class="hljs-number">22</span><br><span class="hljs-keyword">WHERE</span> sno <span class="hljs-keyword">IN</span><br>(<span class="hljs-keyword">SELECT</span> sno <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sage<span class="hljs-operator">&gt;</span><span class="hljs-number">18</span>);<br></code></pre></td></tr></table></figure><h3 id="3-4-3-删除"><a href="#3-4-3-删除" class="headerlink" title="3.4.3 删除"></a>3.4.3 删除</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">DELETE</span> <span class="hljs-keyword">FROM</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span> [<span class="hljs-keyword">WHERE</span> <span class="hljs-operator">&lt;</span>条件<span class="hljs-operator">&gt;</span>]; <span class="hljs-comment">-- 不加WHERE就全删，一条一条删</span><br><br><span class="hljs-keyword">DELETE</span> <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sno<span class="hljs-operator">=</span><span class="hljs-number">2012145</span>;<br><span class="hljs-comment">-- 带子查询删除 -------------</span><br><span class="hljs-keyword">DELETE</span> <span class="hljs-keyword">FROM</span> student<br><span class="hljs-keyword">WHERE</span> sno <span class="hljs-keyword">IN</span>(<span class="hljs-keyword">SELECT</span> sno <span class="hljs-keyword">FROM</span> student <span class="hljs-keyword">WHERE</span> sage<span class="hljs-operator">&gt;</span><span class="hljs-number">18</span>);<br></code></pre></td></tr></table></figure><h2 id="3-5-空值的处理"><a href="#3-5-空值的处理" class="headerlink" title="3.5 空值的处理"></a>3.5 空值的处理</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 1. 产生，使用NULL</span><br><span class="hljs-comment">-- 2. 判断，IS NULL  ,  IS NOT NULL</span><br><span class="hljs-comment">-- 3. 约束条件，创建时加上</span><br><span class="hljs-comment">-- 4. 运算</span><br>空值与另一个（空）值的算术结果为空值，比较结果为 <span class="hljs-literal">UNKNOWN</span><br><span class="hljs-literal">TRUE</span>, <span class="hljs-literal">FALSE</span>, <span class="hljs-literal">UNKNOWN</span><br></code></pre></td></tr></table></figure><table><thead><tr><th align="center">x</th><th align="center">y</th><th align="center">x AND y</th><th align="center">x OR y</th></tr></thead><tbody><tr><td align="center">T</td><td align="center">T</td><td align="center">T</td><td align="center">T</td></tr><tr><td align="center">T</td><td align="center">U</td><td align="center">U</td><td align="center">T</td></tr><tr><td align="center">T</td><td align="center">F</td><td align="center">F</td><td align="center">T</td></tr><tr><td align="center">U</td><td align="center">T</td><td align="center">U</td><td align="center">T</td></tr><tr><td align="center">U</td><td align="center">U</td><td align="center">U</td><td align="center">U</td></tr><tr><td align="center">U</td><td align="center">F</td><td align="center">F</td><td align="center">U</td></tr><tr><td align="center">F</td><td align="center">T</td><td align="center">F</td><td align="center">T</td></tr><tr><td align="center">F</td><td align="center">U</td><td align="center">F</td><td align="center">U</td></tr><tr><td align="center">F</td><td align="center">F</td><td align="center">F</td><td align="center">F</td></tr></tbody></table><h2 id="3-6-视图"><a href="#3-6-视图" class="headerlink" title="3.6 视图"></a>3.6 视图</h2><ul><li><strong>数据库中只存放视图的定义，不存放数据</strong>，视图是从其它<strong>1个或几个基本表导出的表，是虚表。</strong></li><li>基本表中的数据发生变化，视图中的数据也随之变化</li><li>对视图的更新操作有限制</li><li>作用：<ul><li>①视图能够简化用户从操作</li><li>②视图能够使用户以多种角度看同一数据</li><li>③视图对重构数据库提供了一定程度的逻辑独立性</li><li>④视图能够对机密文件提供安全保护</li></ul></li></ul><h3 id="3-6-1-定义和删除"><a href="#3-6-1-定义和删除" class="headerlink" title="3.6.1 定义和删除"></a>3.6.1 定义和删除</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 定义</span><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">VIEW</span> <span class="hljs-operator">&lt;</span>视图名<span class="hljs-operator">&gt;</span>[(<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>列名<span class="hljs-operator">&gt;</span>]···)]<br><span class="hljs-keyword">AS</span> 子查询<br>[<span class="hljs-keyword">WITH</span> <span class="hljs-keyword">CHECK</span> OPTION];<br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">VIEW</span> is_student<br><span class="hljs-keyword">AS</span> <span class="hljs-keyword">select</span> sno,sname,sage <span class="hljs-keyword">from</span> student <span class="hljs-keyword">where</span> sdept <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;IS&#x27;</span>;<br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">VIEW</span> is_student <span class="hljs-comment">-- 不写属性名就是查询的属性名</span><br><span class="hljs-keyword">AS</span> <span class="hljs-keyword">select</span> sno,sname,sage <span class="hljs-keyword">from</span> student <span class="hljs-keyword">where</span> sdept <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;IS&#x27;</span><br><span class="hljs-keyword">WITH</span> <span class="hljs-keyword">CHECK</span> OPTION; <span class="hljs-comment">-- 保证后续对视图进行操作仍需满足子查询中的条件</span><br><br><span class="hljs-comment">-- 分组视图：带有聚集函数和 GROUP BY 子句定义的视图</span><br><br><span class="hljs-comment">-- 删除</span><br><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">VIEW</span> <span class="hljs-operator">&lt;</span>视图名<span class="hljs-operator">&gt;</span> [CASCADE];<br><span class="hljs-comment">-- CASCADE 如果该视图有基于其导出的视图，也会强行删除。</span><br></code></pre></td></tr></table></figure><h3 id="3-6-1-查询"><a href="#3-6-1-查询" class="headerlink" title="3.6.1 查询"></a>3.6.1 查询</h3><ul><li>视图消解：从数据字典中取出视图的定义，把定义中的子查询和用户的查询结合起来，转换为等价的对基本表的查询，然后再执行修正了的查询。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">和之前的一样<br></code></pre></td></tr></table></figure><h3 id="3-6-1-更新"><a href="#3-6-1-更新" class="headerlink" title="3.6.1 更新"></a>3.6.1 更新</h3><p>更新视图—-&gt;更新基本表</p><ul><li>不可更新的视图：例如更改平均值</li><li>不允许更新的视图<ul><li>由两个以上基本表导出的（包含嵌套查询里的表）视图</li><li>视图的字段来自字段表达式或常数，只允许DELETE</li><li>视图的字段来自聚集函数</li><li>视图定义中含有GROUP BY子句</li><li>视图定义中含有DISTINCT短语</li><li>不允许更新的视图上定义的视图</li></ul></li></ul><h3 id="3-6-1-作用"><a href="#3-6-1-作用" class="headerlink" title="3.6.1 作用"></a>3.6.1 作用</h3><ul><li>简化用户的操作</li><li>使用户能以多种角度看待同一数据</li><li>对重构数据库提供了一定程度的逻辑独立性</li><li>能够对机密数据提供安全保护</li><li>可以更清晰的表达查询</li></ul><h2 id="3-7-存储过程（类似函数FUNCTION，但是函数固定返回一个值）"><a href="#3-7-存储过程（类似函数FUNCTION，但是函数固定返回一个值）" class="headerlink" title="3.7 存储过程（类似函数FUNCTION，但是函数固定返回一个值）"></a>3.7 存储过程（类似函数FUNCTION，但是函数固定返回一个值）</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">Procedure</span> GetUserAccount<br>(a <span class="hljs-type">INT</span>,b <span class="hljs-type">char</span>(<span class="hljs-number">8</span>)) <span class="hljs-comment">-- 参数</span><br><span class="hljs-keyword">as</span><br>BIGIN<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> UserAccount<br><span class="hljs-keyword">END</span>;<br></code></pre></td></tr></table></figure><h1 id="第四章-数据库安全性"><a href="#第四章-数据库安全性" class="headerlink" title="第四章 数据库安全性"></a>第四章 数据库安全性</h1><ul><li>定义：数据库的安全性是指<strong>保护数据库以防止不合法使用所造成的数据泄露、更改或破坏</strong>。</li><li>一般保护方法：<strong>设置用户标识、存取权限控制</strong>。</li><li>五级安全措施：用户标识鉴定、存取控制、视图机制、审计、数据加密。</li></ul><h2 id="4-1-用户标识鉴别"><a href="#4-1-用户标识鉴别" class="headerlink" title="4.1 用户标识鉴别"></a>4.1 用户标识鉴别</h2><ul><li>唯一用户标识：用户名，用户标识号<ul><li>静态口令鉴别</li><li>动态口令鉴别</li><li>生物特征鉴别</li><li>智能卡鉴别</li></ul></li></ul><h2 id="4-2-存取控制（授权）"><a href="#4-2-存取控制（授权）" class="headerlink" title="4.2 存取控制（授权）"></a>4.2 存取控制（授权）</h2><ul><li>定义用户权限，并将用户权限登记到数据字典中。</li><li>合法权限检查：用户发出请求，DBMS查询数据字典确认。</li><li><strong>内容</strong>：</li><li>1.要存取的数据对象</li><li>2.对此数据对象进行操作的类型</li></ul><h3 id="4-2-1-自主存取控制方法（MAC）"><a href="#4-2-1-自主存取控制方法（MAC）" class="headerlink" title="4.2.1 自主存取控制方法（MAC）"></a>4.2.1 自主存取控制方法（MAC）</h3><ul><li><p>用户对不同的数据对象有不同的存取权限</p></li><li><p>不同的用户对同一对象也有不同的权限</p></li><li><p>用户还可将其拥有的存取权限转授给其他用户</p></li><li><p>通过 GRANT 和 REVOKE 语句实现（授权）</p></li></ul><h3 id="4-2-2-授权（访问数据的权限）"><a href="#4-2-2-授权（访问数据的权限）" class="headerlink" title="4.2.2 授权（访问数据的权限）"></a>4.2.2 授权（访问数据的权限）</h3><p>1.权限授予</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">GRANT</span> <span class="hljs-operator">&lt;</span>权限<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>权限<span class="hljs-operator">&gt;</span>]...<br><span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>对象类型<span class="hljs-operator">&gt;</span><span class="hljs-operator">&lt;</span>对象名<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>对象类型<span class="hljs-operator">&gt;</span><span class="hljs-operator">&lt;</span>对象名<span class="hljs-operator">&gt;</span>]...<br><span class="hljs-keyword">TO</span> <span class="hljs-operator">&lt;</span>用户<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>用户<span class="hljs-operator">&gt;</span>]...<br>[<span class="hljs-keyword">WITH</span> <span class="hljs-keyword">GRANT</span> OPTION]; <span class="hljs-comment">-- 指定该子句可以再转授权限，不允许循环授权即授权给祖先</span><br><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span><br><span class="hljs-keyword">ON</span> <span class="hljs-keyword">TABLE</span> student<br><span class="hljs-keyword">TO</span> U1;<br><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">UPDATE</span>(sno),<span class="hljs-keyword">SELECT</span>  <span class="hljs-comment">-- 对属性列的授权必须指明列名</span><br><span class="hljs-keyword">ON</span> <span class="hljs-keyword">TABLE</span> student<br><span class="hljs-keyword">TO</span> U1;<br></code></pre></td></tr></table></figure><p>2.权限回收</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">REVOKE</span> <span class="hljs-operator">&lt;</span>权限<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>权限<span class="hljs-operator">&gt;</span>]...<br><span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>对象类型<span class="hljs-operator">&gt;</span><span class="hljs-operator">&lt;</span>对象名<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>对象类型<span class="hljs-operator">&gt;</span><span class="hljs-operator">&lt;</span>对象名<span class="hljs-operator">&gt;</span>]...<br><span class="hljs-keyword">FROM</span> <span class="hljs-operator">&lt;</span>用户<span class="hljs-operator">&gt;</span>[,<span class="hljs-operator">&lt;</span>用户<span class="hljs-operator">&gt;</span>]...<br>[RESTRICT<span class="hljs-operator">|</span>CASCADE];<br><span class="hljs-comment">-- CASCADE 级联：该用户传播出去的权限也回收。</span><br><span class="hljs-comment">-- RESTRICT 限制：如果该用户传播过权限，就拒绝这个语句的执行。</span><br><span class="hljs-comment">-- 不指明就按照缺省值，不同系统缺省值不同。</span><br><br><span class="hljs-keyword">REVOKE</span> <span class="hljs-keyword">SELECT</span><br><span class="hljs-keyword">ON</span> <span class="hljs-keyword">TABLE</span> student<br><span class="hljs-keyword">FROM</span> PUBLIC; <span class="hljs-comment">-- 所有用户权限</span><br></code></pre></td></tr></table></figure><h3 id="4-2-3-数据库角色"><a href="#4-2-3-数据库角色" class="headerlink" title="4.2.3 数据库角色"></a>4.2.3 数据库角色</h3><ul><li>角色是指一类人，比如说 CEO、总监、普通职员，可以给一类人授权</li></ul><p>1.角色创建</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> ROLE <span class="hljs-operator">&lt;</span>角色名<span class="hljs-operator">&gt;</span>;<br><br><span class="hljs-keyword">CREATE</span> ROLE CEO;<br></code></pre></td></tr></table></figure><p>2.角色授权</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">GRANT</span> <span class="hljs-operator">&lt;</span>权限<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>对象类型<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span>对象名<span class="hljs-operator">&gt;</span>[列名]  [<span class="hljs-keyword">WHEN</span> 条件]  <span class="hljs-keyword">TO</span> <span class="hljs-operator">&lt;</span>角色<span class="hljs-operator">&gt;</span> [<span class="hljs-keyword">WITH</span> <span class="hljs-keyword">GRANT</span> OPTION];<br><span class="hljs-comment">-- 如果加上 WITH ADMIN OPTION，意味着，这个用户还可以吧这权限授予给其他角色或者用户。</span><br><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">ON</span> <span class="hljs-keyword">TABLE</span> Employee <span class="hljs-keyword">TO</span> CEO ; <span class="hljs-comment">-- 查询</span><br>      <span class="hljs-keyword">UPDATE</span>   <span class="hljs-comment">-- 更新</span><br>      <span class="hljs-keyword">UPDATE</span>(属性名)   <span class="hljs-comment">-- 更新某一属性</span><br>  <span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span>   <span class="hljs-comment">-- 修改表结构</span><br>      <span class="hljs-keyword">ALL</span> PRIVILIGES  <span class="hljs-comment">-- 所有权限</span><br>                                  PUBLIC <span class="hljs-comment">-- 所有人</span><br><br><span class="hljs-comment">-- 对于很复杂的，先建立视图在给予权限</span><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">VIEW</span> DS(Sname,Smax,Smin,Savg)<br><span class="hljs-keyword">AS</span><br><span class="hljs-keyword">SELECT</span> DepartmentId,<span class="hljs-built_in">max</span>(Employee.Salary),<span class="hljs-built_in">min</span>(Employee.Salary),<span class="hljs-built_in">avg</span>(Employee.Salary)<br><span class="hljs-keyword">FROM</span> Employee,Department<br><span class="hljs-keyword">WHERE</span> DepartmentId<span class="hljs-operator">=</span>Department.ID<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> DepartmentId;<br><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span><br><span class="hljs-keyword">ON</span> <span class="hljs-keyword">VIEW</span> DS<br><span class="hljs-keyword">TO</span> 杨兰<br></code></pre></td></tr></table></figure><p>3.把角色授权给其他用户或角色</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">GRANT</span> <span class="hljs-operator">&lt;</span>角色<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">TO</span> <span class="hljs-operator">&lt;</span>其他角色或用户<span class="hljs-operator">&gt;</span> [<span class="hljs-keyword">WITH</span> ADMIN OPTION];<br><br><span class="hljs-keyword">GRANT</span> CEO <span class="hljs-keyword">TO</span> Panzhicheng <span class="hljs-keyword">WITH</span> ADMIN OPTION;<br></code></pre></td></tr></table></figure><p>4.角色权限收回</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">REVOKE</span> <span class="hljs-operator">&lt;</span>权限<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">FROM</span> <span class="hljs-operator">&lt;</span>角色<span class="hljs-operator">&gt;</span>;<br><br><span class="hljs-keyword">REVOKE</span> <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">ON</span> Employee <span class="hljs-keyword">FROM</span> CEO;<br></code></pre></td></tr></table></figure><ul><li>可能无意泄露数据</li></ul><h3 id="4-2-4-强制存取控制方法（MAC）"><a href="#4-2-4-强制存取控制方法（MAC）" class="headerlink" title="4.2.4 强制存取控制方法（MAC）"></a>4.2.4 强制存取控制方法（MAC）</h3><ul><li><strong>主体</strong>：活动实体，如用户</li><li><strong>客体</strong>：被动实体，如基本表</li><li><strong>敏感度标记</strong>：绝密TS &gt;&#x3D; 机密S &gt;&#x3D; 可信C &gt;&#x3D; 公开P<ul><li>为每个主体与客体指派一个敏感度标记</li></ul></li><li><strong>规则</strong>：<ul><li>仅当主体的许可证级别<strong>大于或等于</strong>客体的密级时，该主体才能<strong>读取</strong>相应的客体。</li><li>仅当主体的许可证级别<strong>小于或等于</strong>客体的密级时，该主体才能<strong>写</strong>相应的客体。</li></ul></li><li>标记与数据是不可分的整体，复制仍然在。</li></ul><h3 id="4-2-3-总结"><a href="#4-2-3-总结" class="headerlink" title="4.2.3 总结"></a>4.2.3 总结</h3><ul><li>先DAC检查再MAC检查，</li><li>自主存取控制方法（DAC）与强制存取控制方法（MAC）共同构成数据库管理系统的安全机制。</li></ul><h2 id="4-3-视图机制"><a href="#4-3-视图机制" class="headerlink" title="4.3 视图机制"></a>4.3 视图机制</h2><ul><li>为不同的用户定义不同的视图，把不需要的数据给隐藏起来，这样用户就不会误操作。<ul><li>服务器事件</li><li>系统权限</li><li>语句事件</li><li>模式对象事件</li></ul></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 1. 创建视图</span><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">VIEW</span> CS_Student<br><span class="hljs-keyword">AS</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span><br><span class="hljs-keyword">FROM</span> Student<br><span class="hljs-keyword">WHERE</span> Sdept <span class="hljs-operator">=</span> ‘<span class="hljs-keyword">IS</span>’;<br><br><span class="hljs-comment">-- 2. 授权角色</span><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">ON</span> CS_Student <span class="hljs-keyword">TO</span> Panzhicheng;<br><span class="hljs-keyword">GRANT</span> ALL_PRIVILEGES <span class="hljs-keyword">ON</span> CS_Student <span class="hljs-keyword">TO</span> Panzhicheng;<br></code></pre></td></tr></table></figure><h2 id="4-4-审计（事后监控措施）"><a href="#4-4-审计（事后监控措施）" class="headerlink" title="4.4 审计（事后监控措施）"></a>4.4 审计（事后监控措施）</h2><ul><li>任何操作都记录到审计日志，然后看日志，里面是否有非法行为。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 对修改 SC 数据的操作进行审计（AUDIT）</span><br>AUDIT <span class="hljs-keyword">UPDATE</span> <span class="hljs-keyword">ON</span> SC;<br><br><span class="hljs-comment">-- 取消对 SC 表的一切审计（NOAUDIT）</span><br>NOAUDIT <span class="hljs-keyword">UPDATE</span> <span class="hljs-keyword">ON</span> SC;<br></code></pre></td></tr></table></figure><h2 id="4-5-数据加密"><a href="#4-5-数据加密" class="headerlink" title="4.5 数据加密"></a>4.5 数据加密</h2><ul><li>通过一些加密算法，把明文变成密文，这样别人就无法查看。<ul><li>存储加密</li><li>传输加密<ul><li>链路加密</li><li>端到端加密</li></ul></li></ul></li></ul><h2 id="4-5-其它安全性保护"><a href="#4-5-其它安全性保护" class="headerlink" title="4.5 其它安全性保护"></a>4.5 其它安全性保护</h2><ul><li>推理控制：避免用户利用其能够访问的数据推知更高密级的数据</li><li>隐蔽信道</li><li>数据隐私保护：控制个人数据</li></ul><h1 id="第五章-数据库完整性"><a href="#第五章-数据库完整性" class="headerlink" title="第五章 数据库完整性"></a>第五章 数据库完整性</h1><ul><li><strong>主要任务</strong>：保障数据的正确性、有效性、协调性，提高数据对用户的可用性。</li><li><strong>值</strong>的约束和<strong>结构</strong>的约束</li><li><strong>措施</strong>：<ul><li>适时检查完整性约束条件，保证语义完整。</li><li>控制并发操作，使其不破坏完整性。</li><li>在系统发生故障后，即时恢复系统。</li></ul></li></ul><h2 id="5-1-完整性定义"><a href="#5-1-完整性定义" class="headerlink" title="5.1 完整性定义"></a>5.1 完整性定义</h2><ul><li><p><strong>正确性</strong>：符合现实世界的描述（<strong>正确性、相容性</strong>）</p></li><li><p><strong>相容性</strong>：同一个对象在不同表里面是符合逻辑，比如我的地址、年龄，在不同的表里应该一致</p></li><li><p>维护数据库完整性（措施）：</p><ul><li>提供完整性约束条件的机制</li><li>提供完整性检查的方法</li><li>进行违约处理</li></ul></li></ul><h2 id="5-2-实体完整性"><a href="#5-2-实体完整性" class="headerlink" title="5.2 实体完整性"></a>5.2 实体完整性</h2><ul><li><strong>主码值唯一，且非空</strong>。<ul><li>主键一般自带索引，查找速度极快。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> Course (id <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span> <span class="hljs-keyword">PRIMARY</span> KEY,<br>                    name <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">255</span>));<br></code></pre></td></tr></table></figure></li></ul></li></ul><h2 id="5-3-参照完整性"><a href="#5-3-参照完整性" class="headerlink" title="5.3 参照完整性"></a>5.3 参照完整性</h2><ul><li><strong>外码可以是空值或另一个关系主码的有效值</strong>。</li><li>对参照表和被参照表增删改操作时有可能破坏参照完整性，必须进行检查。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> Course (id <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>                    name <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">255</span>),<br>                    teacher_id <span class="hljs-type">INT</span>,<br>                    <span class="hljs-keyword">PRIMARY</span> KEY(id),<br>                    <span class="hljs-keyword">FOREIGN</span> KEY(ID) <span class="hljs-keyword">REFERENCES</span> Course_description(Course_id));<br><span class="hljs-comment">-- FOREIGN 定义外码</span><br><span class="hljs-comment">-- REFERENCES 指明外码参照哪些表的主码</span><br></code></pre></td></tr></table></figure><h2 id="5-4-用户定义的完整性"><a href="#5-4-用户定义的完整性" class="headerlink" title="5.4 用户定义的完整性"></a>5.4 用户定义的完整性</h2><ul><li><p>非空 NOT NULL</p></li><li><p>列值唯一 UNIQUE</p></li><li><p>属性满足某一个条件表达式 CHECK</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> SC (Sno <span class="hljs-type">CHAR</span>(<span class="hljs-number">9</span>) <span class="hljs-keyword">PRIMARY</span> KEY,<br>                   Sname <span class="hljs-type">CHAR</span>(<span class="hljs-number">8</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>                   Ssex <span class="hljs-type">CHAR</span>(<span class="hljs-number">2</span>) <span class="hljs-keyword">CHECK</span> (Ssex <span class="hljs-keyword">IN</span> (<span class="hljs-string">&#x27;男&#x27;</span>, <span class="hljs-string">&#x27;女&#x27;</span>))<br>                   Grade <span class="hljs-type">SMALLINT</span> <span class="hljs-keyword">CHECK</span> (Grade<span class="hljs-operator">&gt;</span><span class="hljs-number">60</span>);<br></code></pre></td></tr></table></figure></li><li><p>元组满足某一个条件表达式 CHECK</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> SC (Sno <span class="hljs-type">CHAR</span>(<span class="hljs-number">9</span>) <span class="hljs-keyword">PRIMARY</span> KEY,<br>                   Sname <span class="hljs-type">CHAR</span>(<span class="hljs-number">8</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">NULL</span>,<br>                   Ssex <span class="hljs-type">CHAR</span>(<span class="hljs-number">2</span>)<br>                   Grade <span class="hljs-type">SMALLINT</span><br>                   <span class="hljs-keyword">CHECK</span> (Ssex<span class="hljs-operator">=</span><span class="hljs-string">&#x27;女&#x27;</span> <span class="hljs-keyword">OR</span> Sname <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">LIKE</span> <span class="hljs-string">&#x27;Ms.%&#x27;</span>);<br></code></pre></td></tr></table></figure></li><li><p>属性上的约束条件检查和违约处理</p></li><li><p>元组上的约束条件检查和违约处理</p></li></ul><h2 id="5-5-断言"><a href="#5-5-断言" class="headerlink" title="5.5 断言"></a>5.5 断言</h2><ul><li>通过声明性断言来指定更具一般性的约束。</li><li>可以定义涉及多个表或聚集操作的比较复杂的完整性约束。</li><li>断言创建以后，任何对断言中所涉及关系的操作都会触发关系数据库管理系统对断言的检查，任何使断言不为真值的操作都会被拒绝执行。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 创建断言</span><br><span class="hljs-keyword">CREATE</span> ASSERTION <span class="hljs-operator">&lt;</span>断言名<span class="hljs-operator">&gt;</span> <span class="hljs-operator">&lt;</span><span class="hljs-keyword">CHECK</span>子句<span class="hljs-operator">&gt;</span>;<br><br><span class="hljs-keyword">CREATE</span> ASSERTION ASSE_SC_CNUM1<br><span class="hljs-keyword">CHECK</span>(<span class="hljs-number">60</span><span class="hljs-operator">&gt;=</span><span class="hljs-keyword">ALL</span>(<span class="hljs-keyword">SELECT</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>)<br>      <span class="hljs-keyword">FROM</span> SC<br>                  <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> cno)<br>    );<br><br><span class="hljs-comment">-- 删除断言</span><br><span class="hljs-keyword">DROP</span> ASSERTION <span class="hljs-operator">&lt;</span>断言名<span class="hljs-operator">&gt;</span>;<br></code></pre></td></tr></table></figure><h2 id="5-6-触发器"><a href="#5-6-触发器" class="headerlink" title="5.6 触发器"></a>5.6 触发器</h2><ul><li>触发器也叫做 事件 -&gt; 条件 -&gt; 动作 规则。</li><li>当对一个表增删改的时候，对触发器里面的条件进行检查，如果成立就会执行触发器里的动作，否则不执行里面的动作。</li></ul><h3 id="5-6-1-定义触发器"><a href="#5-6-1-定义触发器" class="headerlink" title="5.6.1 定义触发器"></a>5.6.1 定义触发器</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TRIGGER</span> <span class="hljs-operator">&lt;</span>触发器名<span class="hljs-operator">&gt;</span>  <span class="hljs-comment">-- 同一模式下唯一</span><br>&#123;BEFORE<span class="hljs-operator">|</span>AFTER&#125; <span class="hljs-operator">&lt;</span>触发事件<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span>  <span class="hljs-comment">-- 只能定义在基本表上，触发器名和表名必须在同一模式下</span><br><br><span class="hljs-keyword">REFERENCING</span> <span class="hljs-keyword">NEW</span><span class="hljs-operator">|</span><span class="hljs-keyword">OLD</span> <span class="hljs-type">ROW</span> <span class="hljs-keyword">AS</span> <span class="hljs-operator">&lt;</span>变量<span class="hljs-operator">&gt;</span>  <span class="hljs-comment">-- 只在行级触发器中有用</span><br><span class="hljs-keyword">REFERENCING</span> <span class="hljs-keyword">NEW</span><span class="hljs-operator">|</span><span class="hljs-keyword">OLD</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-keyword">AS</span> <span class="hljs-operator">&lt;</span>变量<span class="hljs-operator">&gt;</span>  <span class="hljs-comment">-- 只在语句级触发器中有用</span><br><br><span class="hljs-keyword">FOR</span> <span class="hljs-keyword">EACH</span> &#123;<span class="hljs-type">ROW</span><span class="hljs-operator">|</span>STATEMENT&#125;  <span class="hljs-comment">-- 行级触发器/语句级触发器</span><br><br>[<span class="hljs-keyword">WHEN</span>（触发条件）]<br>或<br><span class="hljs-keyword">BEGIN</span><br>    <span class="hljs-operator">&lt;</span>触发动作体<span class="hljs-operator">&gt;</span> <span class="hljs-comment">-- 注意缩进</span><br><span class="hljs-keyword">END</span>；<br></code></pre></td></tr></table></figure><h3 id="5-6-2-激活触发器"><a href="#5-6-2-激活触发器" class="headerlink" title="5.6.2 激活触发器"></a>5.6.2 激活触发器</h3><ul><li><strong>数据操纵会自动执行触发器所定义的SQL语句</strong>。</li><li>由触发事件激活，并由数据库服务器自动执行</li><li>执行顺序：<ul><li>1.执行BEFORE触发器</li><li>2.执行触发器的SQL语句</li><li>3.执行AFTER触发器</li></ul></li></ul><h3 id="5-6-3-删除触发器"><a href="#5-6-3-删除触发器" class="headerlink" title="5.6.3 删除触发器"></a>5.6.3 删除触发器</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TRIGGER</span> <span class="hljs-operator">&lt;</span>触发器名<span class="hljs-operator">&gt;</span> <span class="hljs-keyword">ON</span> <span class="hljs-operator">&lt;</span>表名<span class="hljs-operator">&gt;</span>;<br></code></pre></td></tr></table></figure><h1 id="第六章-关系数据理论"><a href="#第六章-关系数据理论" class="headerlink" title="第六章 关系数据理论"></a>第六章 关系数据理论</h1><h2 id="6-1-问题的提出"><a href="#6-1-问题的提出" class="headerlink" title="6.1 问题的提出"></a>6.1 问题的提出</h2><ul><li>第一范式（1NF）：每个分量是不可分的数据项。</li><li>数据依赖（难）：<ul><li>是一个关系内部属性与属性之间的约束关系</li><li>是现实世界属性间相互联系的抽象</li><li>是数据内在的性质</li><li>是语义的体现<ul><li>函数依赖：一 一对应</li><li>多值依赖</li></ul></li></ul></li></ul><p>举个例子：（学号，所在系，系主任，课程号，成绩）</p><ul><li>学号 –&gt;  所在系</li><li>所在系 –&gt; 系主任</li><li>学号+课程号 –&gt; 成绩<br>存在多个依赖，数据有很大的冗余<br>  （学号，所在系）<br>  （学号，课程号，成绩）<br>  （所在系，系主任）</li></ul><h2 id="6-2-规范化"><a href="#6-2-规范化" class="headerlink" title="6.2 规范化"></a>6.2 规范化</h2><ul><li><p><strong>函数依赖</strong>：（多对一映射）所有元组中都满足的，例如，学号 –&gt; 所在系。</p><ul><li>Y函数依赖于X</li><li>平凡函数依赖：X –&gt; Y,  Y属于X（废话，自己决定自己）</li><li>不平凡函数依赖：X –&gt; Y,  Y不属于X（这才是我们讨论的）</li></ul></li><li><p>若 X –&gt; Y，则称X为这个函数依赖的决定因素</p></li><li><p>若 X –&gt; Y，Y –&gt; X，则记作 X &lt;–&gt; Y</p></li><li><p><strong>完全函数依赖</strong>：X —-F—-&gt; Y，当 X –&gt; Y，且对任意的X真子集XX（多个主属性中的几个），都没有 XX –&gt; Y。</p></li><li><p><strong>部分函数依赖</strong>：X —-P—-&gt; Y，    完全依赖+其它属性&#x3D;部分依赖（只依赖主码中的部分属性）</p></li><li><p><strong>传递函数依赖</strong>：X –&gt; Y，Y –&gt; Z，则 Z 传递依赖于 X 。（默认非平凡，不能主属性之间互推）</p></li><li><p>超码（见2.1.1）：候选码+其它属性</p></li><li><p><strong>闭包</strong>就是通过这些属性能够直接推出或间接推出的属性集的集合。</p></li><li><p><strong>无损连接性</strong>：如果R1∩R2是R1或R2的超码，则R上的分解（R1，R2）是无损分解。</p></li><li><p><strong>保持函数依赖性</strong>：F上的每一个函数依赖都在其分解后的某一个关系上成立（充分条件），则原关系必满足3NF。</p></li></ul><h2 id="6-3-范式"><a href="#6-3-范式" class="headerlink" title="6.3 范式"></a>6.3 范式</h2><ul><li>符合某一种级别的关系模式的集合。</li><li>1NF 包含于 2NF 包含于 3NF 包含于 BCNF 包含于 4NF 包含于 5NF</li><li><strong>规范化</strong>：一个低一级范式的关系模式，通过<strong>模式分解</strong>，转化为若干个高一级范式的关系模式的集合。</li></ul><h3 id="6-3-1-第一范式（1NF）"><a href="#6-3-1-第一范式（1NF）" class="headerlink" title="6.3.1 第一范式（1NF）"></a>6.3.1 第一范式（1NF）</h3><ul><li>每个分量是不可分的数据项。</li><li>问题：数据冗余度大，插入异常，删除异常，修改异常</li></ul><h3 id="6-3-2-第二范式（2NF）"><a href="#6-3-2-第二范式（2NF）" class="headerlink" title="6.3.2 第二范式（2NF）"></a>6.3.2 第二范式（2NF）</h3><ul><li>在满足1NF的基础上，且非主属性<strong>完全依赖于</strong>主码。</li></ul><h3 id="6-3-3-第三范式（3NF）"><a href="#6-3-3-第三范式（3NF）" class="headerlink" title="6.3.3 第三范式（3NF）"></a>6.3.3 第三范式（3NF）</h3><ul><li>在满足2NF的基础上，且每个非主属性都<strong>不传递函数依赖于</strong>主码。</li></ul><h3 id="6-3-4-BCNF（修正的-3NF）"><a href="#6-3-4-BCNF（修正的-3NF）" class="headerlink" title="6.3.4 BCNF（修正的 3NF）"></a>6.3.4 BCNF（修正的 3NF）</h3><ul><li>消除每一个<strong>主属性</strong>对<strong>候选码</strong>的<strong>部分或传递</strong>依赖（主属性很多，候选码内部传递依赖）。</li><li>满足BCNF，则实现了模式的彻底分解，<strong>消除了插入异常（该插没插）和删除异常（不该删被删）</strong>。</li></ul><h3 id="6-3-5-多值依赖（一对几个多，多中的相互独立，可独立变化）"><a href="#6-3-5-多值依赖（一对几个多，多中的相互独立，可独立变化）" class="headerlink" title="6.3.5 多值依赖（一对几个多，多中的相互独立，可独立变化）"></a>6.3.5 多值依赖（一对几个多，多中的相互独立，可独立变化）</h3><ul><li>对于R(U),X,Y,Z是U的子集，并且X+Y+Z&#x3D;U。<strong>U的任何子集及其组合都不重复</strong>。X，Y，Z互相多值依赖。</li><li>X –&gt;–&gt; Y</li><li>对称性</li><li>传递性</li></ul><h3 id="6-3-6-第四范式（4NF）"><a href="#6-3-6-第四范式（4NF）" class="headerlink" title="6.3.6 第四范式（4NF）"></a>6.3.6 第四范式（4NF）</h3><ul><li>在满足BCNF的基础上，属性之间不允许有非平凡且非函数依赖的多值依赖，只允许函数依赖。</li><li><strong>二目关系都属于4NF</strong></li></ul><h2 id="6-4-数据依赖的公理系统"><a href="#6-4-数据依赖的公理系统" class="headerlink" title="6.4 数据依赖的公理系统"></a>6.4 数据依赖的公理系统</h2><ul><li>模式分解算法的理论基础。</li><li>Armstrong公理系统：函数依赖的一个有效而完备的公理系统。</li></ul><p><img src="/2025/01/11/%E6%95%B0%E6%8D%AE%E5%BA%93/armstrong.png"></p><h2 id="6-5-模式分解（规范化）"><a href="#6-5-模式分解（规范化）" class="headerlink" title="6.5 模式分解（规范化）"></a>6.5 模式分解（规范化）</h2><p>找主码，（检查完全依赖、检查传递依赖）–找所有函数依赖</p><ol><li>1NF到2NF：拆主码，其中一个主码不变。</li><li>2NF到3NF：传递拆开，X-&gt;Y-&gt;Z，拆成X,Y ; Y,Z。</li><li>3NF到BCNF：拆主属性</li></ol><h2 id="6-6-解题"><a href="#6-6-解题" class="headerlink" title="6.6 解题"></a>6.6 解题</h2><ul><li>求<strong>闭包</strong>：必包含自身。</li><li>求<strong>候选码</strong>：<ul><li>①只在F右部出现的属性，不属于候选码</li><li>②只在F左部出现的属性，一定存在于某候选码当中</li><li>③两边都没有出现的属性，一定存在于候选码中</li><li>④其他属性逐个与②③的属性结合，求属性闭包 ，直至X的闭包等于U。若等于U，则X为候选码</li></ul></li><li>求<strong>极小函数依赖集</strong>：<ul><li>①单一化，右边只有一个属性</li><li>②去掉左边多余属性</li><li>③去掉多余依赖</li></ul></li></ul><h1 id="第七章-数据库设计"><a href="#第七章-数据库设计" class="headerlink" title="第七章 数据库设计"></a>第七章 数据库设计</h1><h2 id="7-1-数据库设计概念"><a href="#7-1-数据库设计概念" class="headerlink" title="7.1 数据库设计概念"></a>7.1 数据库设计概念</h2><ul><li>基本步骤：<br>  1.需求分析<br>  2.概念结构设计：E-R图或者设计数据字典<br>  3.逻辑结构设计：E-R图 -&gt; 逻辑模型<br>  4.物理结构设计：逻辑模型 -&gt; 物理模型<br>  5.数据库实施：写SQL代码<br>  6.数据库运维：性能检测</li></ul><h2 id="7-2-需求分析"><a href="#7-2-需求分析" class="headerlink" title="7.2 需求分析"></a>7.2 需求分析</h2><ul><li>产生数据字典，是全系统中数据项、数据结构、数据流、数据存储的描述。</li><li>工具：数据流程图、数据字典</li></ul><h2 id="7-3-概念结构设计"><a href="#7-3-概念结构设计" class="headerlink" title="7.3 概念结构设计"></a>7.3 概念结构设计</h2><h3 id="7-3-1-E-R图"><a href="#7-3-1-E-R图" class="headerlink" title="7.3.1 E-R图"></a>7.3.1 E-R图</h3><ul><li><p>实体间的联系</p><ul><li>一对一联系（1:1）</li><li>一对多联系（1:n）</li><li>多对多联系（m:n）</li></ul></li><li><p>二元联系：两个实体型之间的联系，度为2。</p></li><li><p>三元联系：三个实体型之间的联系，度为3。</p></li><li><p>N元联系：N个实体型之间的联系，度为N。</p></li><li><p>实体：矩形</p></li><li><p>属性：椭圆形</p></li><li><p>联系：菱形</p></li></ul><h3 id="7-3-2-合并E-R图"><a href="#7-3-2-合并E-R图" class="headerlink" title="7.3.2 合并E-R图"></a>7.3.2 合并E-R图</h3><p>1.<strong>属性冲突</strong></p><ul><li>属性域</li><li>属性单位</li></ul><p>2.<strong>命名冲突</strong></p><ul><li>同名异义</li><li>异名同义</li></ul><p>3.<strong>结构冲突</strong></p><ul><li>又当实体又当属性</li><li>同一实体的属性个数与属性排列次序不完全相同</li><li>实体间的联系在不同E-R图中为不同类型</li></ul><h2 id="7-4-逻辑结构设计"><a href="#7-4-逻辑结构设计" class="headerlink" title="7.4 逻辑结构设计"></a>7.4 逻辑结构设计</h2><p>1.一个<strong>实体型</strong>转换为一个关系模式</p><ul><li>关系的属性：实体的属性</li><li>关系的码：实体的码</li></ul><p>2.一个<strong>1:m</strong>联系，在 M 端添加另一端的主键。<br>3.一个<strong>m:n</strong>联系，将联系转换为实体，然后在该实体上加上另外两个实体的主键。<br>4.一个多元联系转换，和二元类似。<br>5.具有相同码的关系模式可合并。</p><h2 id="7-5-物理结构设计"><a href="#7-5-物理结构设计" class="headerlink" title="7.5 物理结构设计"></a>7.5 物理结构设计</h2><ul><li>B+树索引</li><li>hash索引</li><li>聚簇方法（在物理上连续，同一页）</li></ul><h2 id="7-6-数据库的实施与维护"><a href="#7-6-数据库的实施与维护" class="headerlink" title="7.6 数据库的实施与维护"></a>7.6 数据库的实施与维护</h2><h3 id="7-6-1-数据的载入和应用程序的调试"><a href="#7-6-1-数据的载入和应用程序的调试" class="headerlink" title="7.6.1 数据的载入和应用程序的调试"></a>7.6.1 数据的载入和应用程序的调试</h3><ul><li>数据库应用程序的设计应该与数据库设计同时进行。</li></ul><h3 id="7-6-2-数据库的试运行"><a href="#7-6-2-数据库的试运行" class="headerlink" title="7.6.2 数据库的试运行"></a>7.6.2 数据库的试运行</h3><ul><li>先输入小批量数据做调式用，运行合格再逐步增加数据量。</li><li>要做好数据库的转储和恢复工作。</li></ul><h3 id="7-6-3-数据库的运行和维护"><a href="#7-6-3-数据库的运行和维护" class="headerlink" title="7.6.3 数据库的运行和维护"></a>7.6.3 数据库的运行和维护</h3><h1 id="第八章-事务"><a href="#第八章-事务" class="headerlink" title="第八章 事务"></a>第八章 事务</h1><h2 id="8-1-事务的概念"><a href="#8-1-事务的概念" class="headerlink" title="8.1 事务的概念"></a>8.1 事务的概念</h2><ul><li>用户定义的一个数据库操作序列，具有原子性。类比原语。</li><li>是恢复和并发控制的基本单位。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">BEGIN</span> TRANSACTION<br><span class="hljs-keyword">SQL</span> 语句<span class="hljs-number">1</span><br>        <span class="hljs-keyword">SQL</span> 语句<span class="hljs-number">2</span><br>        ......<br>[<span class="hljs-keyword">COMMIT</span><span class="hljs-operator">|</span><span class="hljs-keyword">ROLLBACK</span>]；<br><span class="hljs-comment">-- COMMIT：提交，提交事务的所有操作。（默认）</span><br><span class="hljs-comment">-- ROLLBACK：回滚，系统将事务中对数据库的所有已完成操作撤销，回滚到事务开始时的状态。</span><br></code></pre></td></tr></table></figure><h2 id="8-2-事务的特性（ACID）"><a href="#8-2-事务的特性（ACID）" class="headerlink" title="8.2 事务的特性（ACID）"></a>8.2 事务的特性（ACID）</h2><ul><li><strong>原子性Atomicity</strong>：所有操作要么都做要么都不做。</li><li><strong>一致性Consistency</strong>：事务执行结果必须使数据库从一个一致状态变到另一个一致性状态。</li><li><strong>隔离性Isolation</strong>：并发执行的各个事务之间不能互相干扰。</li><li><strong>持续性Durability</strong>：一个事务一旦提交，它对数据库的改变是永久的。</li></ul><h2 id="8-3-事务的故障"><a href="#8-3-事务的故障" class="headerlink" title="8.3 事务的故障"></a>8.3 事务的故障</h2><ol><li><p><strong>事务（内部）故障</strong>：事务未完成，强行回滚。rollback；</p></li><li><p><strong>系统故障</strong>：造成系统停转的任何事件。</p></li><li><p><strong>介质故障</strong>：硬件损坏</p></li><li><p><strong>计算机病毒</strong></p></li></ol><h2 id="8-4-数据库恢复—利用冗余数据"><a href="#8-4-数据库恢复—利用冗余数据" class="headerlink" title="8.4 数据库恢复—利用冗余数据"></a>8.4 数据库恢复—利用冗余数据</h2><ul><li><p>将数据库从错误状态恢复到某一已知的正确状态</p></li><li><p>技术：</p><ul><li>数据转储（静态与动态）</li><li>登记日志文件<ul><li>登记的次序严格按并发事务执行的顺序</li><li>必须先写日志文件，后写数据库</li></ul></li></ul></li><li><p>策略：</p><ul><li><strong>事务故障</strong>：反向扫描日志文件，查找该事务的更新操作，依次进行逆操作。</li><li><strong>系统故障</strong>：正向扫描日志文件，故障前发生的事务加入重做队列，故障时未发生的事务加入撤销队列，对重做队列中的事务进行重做处理，对撤销队列中的事务进行撤销（UNDO）处理。</li><li><strong>介质故障</strong>：重装数据库，然后重做已完成的事务。</li></ul></li></ul><h3 id="8-4-1-后援副本"><a href="#8-4-1-后援副本" class="headerlink" title="8.4.1 后援副本"></a>8.4.1 后援副本</h3><h3 id="8-4-2-日志文件"><a href="#8-4-2-日志文件" class="headerlink" title="8.4.2 日志文件"></a>8.4.2 日志文件</h3><p>日志文件是用来记录事务对数据库更新操作的文件。日志文件主要有以下两种格式：</p><ul><li>以<strong>记录</strong>为单位的日志文件包括：<ul><li>各个事务开始的标记；</li><li>各个事务的结束标记；</li><li>各个事务的所有更新操作。</li><li>每个事务的开始标记、结束标记和每个更新操作构成一个日志记录。</li></ul></li><li>以<strong>数据块</strong>为单位的日志文件包括：<ul><li>事务标识（标明是哪个事务）</li><li>操作的类型（插入、删除或修改）</li><li>操作对象（记录内部标识）</li><li>更新前数据的旧值（对插入操作而言此项为空值）</li><li>更新后数据的新值（对删除操作而言此项为空值）</li></ul></li></ul><p>作用：<br>（1）事务故障恢复和系统故障恢复必须用日志文件；<br>（2）在动态转储方式中必须建立日志文件，后备副本和日志文件结合起来才能有效地恢复数据库；<br>（3）在静态转储方式中也可以建立日志文件。</p><p>登记原则：<br>（1）登记的次序严格按照并发事务执行的时间次序。<br>（2）必须先写日志文件，后写数据库。</p><h1 id="第九章-并发控制"><a href="#第九章-并发控制" class="headerlink" title="第九章 并发控制"></a>第九章 并发控制</h1><ul><li><strong>事务是并发控制的基本单位</strong>，保证事务ACID特性是事务处理的重要任务。</li><li>事务的ACID可能遭到破坏的原因是多个事务对数据库的并发操作造成的。</li><li>为了保证事务的<strong>隔离性和一致性</strong>，DBMS需要读并发操作进行正确调度。</li></ul><h2 id="9-1-并发带来的问题（数据不一致）"><a href="#9-1-并发带来的问题（数据不一致）" class="headerlink" title="9.1 并发带来的问题（数据不一致）"></a>9.1 并发带来的问题（数据不一致）</h2><ul><li><p><strong>丢失修改</strong></p></li><li><p><strong>脏读</strong></p></li><li><p><strong>不可重复读</strong>：读后被修改，无法再次重现读</p></li><li><p>原因：并发操作破坏了事务的隔离性。</p></li></ul><h2 id="9-2-方法：封锁以及封锁协议"><a href="#9-2-方法：封锁以及封锁协议" class="headerlink" title="9.2 方法：封锁以及封锁协议"></a>9.2 方法：封锁以及封锁协议</h2><h3 id="9-2-1-封锁（实现并发控制）"><a href="#9-2-1-封锁（实现并发控制）" class="headerlink" title="9.2.1 封锁（实现并发控制）"></a>9.2.1 封锁（实现并发控制）</h3><p>基本的锁有两类：</p><ul><li><strong>排他锁（X锁）</strong>，写锁：只允许加锁事务进行读写。</li><li><strong>共享锁（S锁）</strong>，读锁：只允许加锁事务进行读，其它事务加读锁。</li></ul><h3 id="9-2-2-封锁协议"><a href="#9-2-2-封锁协议" class="headerlink" title="9.2.2 封锁协议"></a>9.2.2 封锁协议</h3><ul><li>一级封锁协议：<strong>修改前</strong>必须加X锁，直到<strong>事务结束才释放</strong>。<ul><li>防止丢失修改</li></ul></li><li>二级封锁协议：在一级封锁协议上，<strong>读取前</strong>必须加S锁，<strong>读完后</strong>即可释放。<ul><li>防止丢失修改，防止脏读</li></ul></li><li>三级封锁协议：在一级封锁协议上，<strong>读取前</strong>必须加S锁，<strong>直到事务结束</strong>才释放。<ul><li>防止丢失修改，防止脏读，防止不可重复读</li></ul></li><li>两段封锁协议：加锁统一加，然后统一解锁。</li></ul><h2 id="9-3-活锁与死锁"><a href="#9-3-活锁与死锁" class="headerlink" title="9.3 活锁与死锁"></a>9.3 活锁与死锁</h2><h3 id="9-3-1-活锁"><a href="#9-3-1-活锁" class="headerlink" title="9.3.1 活锁"></a>9.3.1 活锁</h3><p>事务串行等待，有可能永远等待。</p><ul><li>避免活锁：采用<strong>FCFS先来先服务</strong>。</li></ul><h3 id="9-3-2-死锁"><a href="#9-3-2-死锁" class="headerlink" title="9.3.2 死锁"></a>9.3.2 死锁</h3><p>多个事务互相等待，永远不能结束。</p><ul><li>预防死锁<ul><li>一次封锁法</li><li>顺序封锁法</li></ul></li><li>诊断与解除死锁<ul><li>超时法</li><li>等待图法</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>考研</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>23年数学建模国赛B题省二奖</title>
    <link href="/2024/10/01/PDF_math/"/>
    <url>/2024/10/01/PDF_math/</url>
    
    <content type="html"><![CDATA[<!--<div class="row">    <embed src="./math_struct.pdf" width="100%" height="550" type="application/pdf"></div>--><p>手机端无法查看，可尝试浏览器爬虫功能，建议电脑端查看。<br><embed src="./math_struct.pdf" width="100%" height="750" type="application/pdf"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>从AR到SARIMA时间序列预测代码</title>
    <link href="/2024/09/12/%E4%BB%8EAR%E5%88%B0SARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/"/>
    <url>/2024/09/12/%E4%BB%8EAR%E5%88%B0SARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="一，AR预测"><a href="#一，AR预测" class="headerlink" title="一，AR预测"></a>一，AR预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br><span class="hljs-keyword">from</span> statsmodels.stats.diagnostic <span class="hljs-keyword">import</span> acorr_ljungbox<br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf,plot_acf<br><span class="hljs-keyword">import</span> statsmodels.api <span class="hljs-keyword">as</span> sm<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br>data = pd.read_csv(<span class="hljs-string">&#x27;时间序列预测数据集.csv&#x27;</span>,parse_dates=[<span class="hljs-string">&#x27;Date&#x27;</span>])<br>data.set_index(<span class="hljs-string">&#x27;Date&#x27;</span>,inplace=<span class="hljs-literal">True</span>)     <span class="hljs-comment">#将时间设置为行索引</span><br><span class="hljs-comment">#data = data[&quot;1981-01-01&quot;:&quot;1982-01-01&quot;]</span><br><span class="hljs-comment">####################################   绘制时序图   ############################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">picture</span>(<span class="hljs-params">data</span>):<br>    plt.figure(figsize=(<span class="hljs-number">16</span>,<span class="hljs-number">16</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>):<br>        plt.subplot(<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,i)<br>        df = data[<span class="hljs-string">f&quot;198<span class="hljs-subst">&#123;<span class="hljs-number">1</span>+<span class="hljs-number">2</span>*(i-<span class="hljs-number">1</span>)&#125;</span>-01-01&quot;</span>:<span class="hljs-string">f&quot;198<span class="hljs-subst">&#123;<span class="hljs-number">3</span>+<span class="hljs-number">2</span>*(i-<span class="hljs-number">1</span>)&#125;</span>-01-01&quot;</span>]<br>        plt.plot(df.index,df[<span class="hljs-string">&#x27;Temp&#x27;</span>])<br>        plt.xticks(rotation=<span class="hljs-number">45</span>,size=<span class="hljs-number">6</span>)<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:<br>            plt.title(<span class="hljs-string">&quot;时序图&quot;</span>)<br>    plt.show()<br>    plt.close()<br><span class="hljs-comment">######################################   时间序列检验      #######################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">inspect</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-comment"># 单位根检验-ADF检验</span><br>    ADF = sm.tsa.stattools.adfuller(data[<span class="hljs-string">&#x27;Temp&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;ADF值:&#x27;</span>, <span class="hljs-built_in">format</span>(ADF[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;.4f&#x27;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;拒绝程度值:&#x27;</span>, ADF[<span class="hljs-number">4</span>])      <span class="hljs-comment">#ADF值需要小于三个拒绝程度值</span><br><br>    <span class="hljs-comment"># 白噪声检验</span><br>    white_noise = acorr_ljungbox(data[<span class="hljs-string">&#x27;Temp&#x27;</span>], lags = [<span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>],boxpierce=<span class="hljs-literal">True</span>) <span class="hljs-comment">#lag是需要检验的阶数</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;白噪声检验:\n&#x27;</span>,white_noise)   <span class="hljs-comment">#LB和BP统计量的P值都小于显著水平（α = 0.05）,所以拒绝序列为纯随机序列的原假设，认为该序列为非白噪声序列</span><br><br>    fig = plt.figure(figsize=(<span class="hljs-number">16</span>,<span class="hljs-number">6</span>))<br><br>    ax1 = fig.add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>    plot_acf(data[<span class="hljs-string">&#x27;Temp&#x27;</span>],ax=ax1)<br>    plt.title(<span class="hljs-string">&quot;自相关图&quot;</span>)        <span class="hljs-comment">#需要拖尾,确定q</span><br><br>    ax2 = fig.add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>    plot_pacf(data[<span class="hljs-string">&#x27;Temp&#x27;</span>],ax=ax2)<br>    plt.title(<span class="hljs-string">&quot;偏自相关图&quot;</span>)      <span class="hljs-comment">#需要截尾,确定p</span><br><br>    plt.show()<br>    plt.close()<br><span class="hljs-comment">#####################################    信息准则    ###########################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">information</span>(<span class="hljs-params">df,df0,p</span>):<br>    n = <span class="hljs-built_in">len</span>(df)<br>    mse = mean_squared_error(df,df0)<br>    <span class="hljs-comment">#aic = n * log(mse) + 2 * p</span><br>    aicc = log(mse) + (n+p)/(n-p-<span class="hljs-number">2</span>)<br>    bic = n * log(mse) + p * log(n)<br>    <span class="hljs-keyword">return</span> aicc,bic<br><br><span class="hljs-comment">####################################     模型预测     ##########################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):<br>    df = np.array(x).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>    Y = df[p:].copy()<br>    h = <span class="hljs-built_in">len</span>(df0)-p<br>    X = np.zeros((h,p+<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>        X[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>            X[i][-v] = df[i+v-<span class="hljs-number">1</span>]<br>    sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>    <span class="hljs-built_in">print</span>(sigma)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        df0[p+i] = <span class="hljs-built_in">sum</span>(sigma * X[i])        <span class="hljs-comment">#得到所有预测的估计值</span><br>    df00 = df.copy()<br>    df1 = np.zeros(predict_x_n)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>        df00 = np.append(df00,df1[i])<br>    <span class="hljs-keyword">return</span> df0,df1<br><br><span class="hljs-comment">#########################################   阶数确定   ##############################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">p_finally</span>(<span class="hljs-params">n</span>):<br>    jieguo = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,n):<br>        df0,df1 = AR_prediction(data,i)<br>        aicc,bic = information(data,df0,i)<br>        jieguo.append([i,aicc,bic])<br>    jieguo_aicc = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])  <span class="hljs-comment">#以aicc排序</span><br>    jieguo_bic = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">2</span>])  <span class="hljs-comment">#以bic排序</span><br><br>    <span class="hljs-keyword">return</span> jieguo_aicc[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>],jieguo_bic[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">#################################   得到最终结果   ###################################</span><br><span class="hljs-comment">#images(data)</span><br><span class="hljs-comment">#inspect(data)</span><br><br><span class="hljs-comment">#p_aicc,p_bic = p_finally(30)</span><br><span class="hljs-comment">#print(p_aicc)</span><br>df0,df1 = AR_prediction(data,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>)<br><br>plt.figure()<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">50</span>),data[-<span class="hljs-number">50</span>:],c = <span class="hljs-string">&#x27;black&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">50</span>),df0[-<span class="hljs-number">50</span>:],c=<span class="hljs-string">&#x27;red&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h1 id="二，MA预测"><a href="#二，MA预测" class="headerlink" title="二，MA预测"></a>二，MA预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br>data = pd.read_csv(<span class="hljs-string">&#x27;时间序列预测数据集.csv&#x27;</span>,parse_dates=[<span class="hljs-string">&#x27;Date&#x27;</span>])<br>data.set_index(<span class="hljs-string">&#x27;Date&#x27;</span>,inplace=<span class="hljs-literal">True</span>)     <span class="hljs-comment">#将时间设置为行索引</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sma</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.mean(x)        <span class="hljs-comment">#简单移动平均</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">wma</span>(<span class="hljs-params">x</span>):<br>    x = np.array(x).ravel()<br>    w = np.arange(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)      <span class="hljs-comment">#生成等差数列</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/(<span class="hljs-built_in">len</span>(x)*(<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>)       <span class="hljs-comment">#加权移动平均（等距）</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ema</span>(<span class="hljs-params">x,i</span>):<br>    x = np.array(x).ravel()<br>    <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i &gt; <span class="hljs-number">0</span>:<br>        l = <span class="hljs-built_in">len</span>(x)<br>        w = np.logspace(l, <span class="hljs-number">0</span>, num=l, base=(<span class="hljs-number">1</span>-i))      <span class="hljs-comment">#生成等比数列</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平滑因子范围错误&#x27;</span>)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/np.<span class="hljs-built_in">sum</span>(w)         <span class="hljs-comment">#指数移动平均</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ma_prediction</span>(<span class="hljs-params">data, q, predict_x_n=<span class="hljs-number">0</span></span>):<br><span class="hljs-comment">##########################   移动平均预测    ################################</span><br>    df = np.array(data).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，存储真实值以及预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)-q+<span class="hljs-number">1</span>):<br>        df[q+i-<span class="hljs-number">1</span>] = ema(data[i:i+q],<span class="hljs-number">0.5</span>)         <span class="hljs-comment">#获得简单移动平均获得的预测数列</span><br><br>    df_wu = df0 - df        <span class="hljs-comment">#获得误差项</span><br><br>    df1 = np.zeros(predict_x_n)      <span class="hljs-comment">#存储预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = ema(df0[-q:],<span class="hljs-number">0.5</span>)        <span class="hljs-comment">#得到所有预测值</span><br>        df0 = np.append(df0,df1[i])<br><span class="hljs-comment">##############################   误差项预测   ###############################</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):           <span class="hljs-comment">#误差项预测实际就为AR预测，这也是为什么MA模型阶数为0时就转化成AR模型的原因</span><br>        df = np.array(x[p:]).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>        df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>        Y = df[p:].copy()<br>        h = <span class="hljs-built_in">len</span>(df0)-p<br>        X = np.zeros((h,p+<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>            X[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>                X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>        sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>            df0[p+i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , X[i]))        <span class="hljs-comment">#得到所有预测的估计值</span><br>        df00 = df.copy()<br>        df1 = np.zeros(predict_x_n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>            df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>            df00 = np.append(df00,df1[i])<br>        <span class="hljs-keyword">return</span> df0,df1<br>    wucha,wucha_predict = AR_prediction(df_wu,q,predict_x_n)<br>    result = df[-<span class="hljs-built_in">len</span>(wucha):] - wucha<br>    predict = df1 - wucha_predict<br>    <span class="hljs-keyword">return</span> result,predict<br><br>result,predict = ma_prediction(data, <span class="hljs-number">6</span>, <span class="hljs-number">0</span>)<br><br>plt.figure()<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>),data[-<span class="hljs-number">60</span>:],c = <span class="hljs-string">&#x27;black&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>),result[-<span class="hljs-number">60</span>:],c=<span class="hljs-string">&#x27;red&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h1 id="三，ARMA预测"><a href="#三，ARMA预测" class="headerlink" title="三，ARMA预测"></a>三，ARMA预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br>data = pd.read_csv(<span class="hljs-string">&#x27;时间序列预测数据集.csv&#x27;</span>,parse_dates=[<span class="hljs-string">&#x27;Date&#x27;</span>])<br>data.set_index(<span class="hljs-string">&#x27;Date&#x27;</span>,inplace=<span class="hljs-literal">True</span>)     <span class="hljs-comment">#将时间设置为行索引</span><br><br><span class="hljs-comment">#####################################    信息准则    ###########################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">information</span>(<span class="hljs-params">df,df0,p</span>):<br>    n = <span class="hljs-built_in">len</span>(df)<br>    mse = mean_squared_error(df,df0)<br>    <span class="hljs-comment">#aic = n * log(mse) + 2 * p</span><br>    aicc = log(mse) + (n+p)/(n-p-<span class="hljs-number">2</span>)<br>    bic = n * log(mse) + p * log(n)<br>    <span class="hljs-keyword">return</span> aicc,bic<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):<br>    df = np.array(x).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>    Y = df[p:].copy()<br>    h = <span class="hljs-built_in">len</span>(df0)-p<br>    X = np.zeros((h,p+<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>        X[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>            X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>    sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        df0[p+i] = <span class="hljs-built_in">sum</span>(sigma * X[i])      <span class="hljs-comment">#得到所有预测的估计值</span><br>    df00 = df.copy()<br>    df1 = np.zeros(predict_x_n)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>        df00 = np.append(df00,df1[i])<br>    <span class="hljs-keyword">return</span> df0,df1<br><br><span class="hljs-comment">#########################################   阶数确定   ##############################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">p_finally</span>(<span class="hljs-params">n</span>):<br>    jieguo = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,n):<br>        df0,df1 = AR_prediction(data,i)<br>        aicc,bic = information(data,df0,i)<br>        jieguo.append([i,aicc,bic])<br>    jieguo_aicc = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])  <span class="hljs-comment">#以aicc排序</span><br>    jieguo_bic = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">2</span>])  <span class="hljs-comment">#以bic排序</span><br>    <span class="hljs-keyword">return</span> jieguo_aicc[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>],jieguo_bic[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sma</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.mean(x)        <span class="hljs-comment">#简单移动平均</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">wma</span>(<span class="hljs-params">x</span>):<br>    x = np.array(x).ravel()<br>    w = np.arange(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)      <span class="hljs-comment">#生成等差数列</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/(<span class="hljs-built_in">len</span>(x)*(<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>)       <span class="hljs-comment">#加权移动平均（等距）</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ema</span>(<span class="hljs-params">x,i</span>):<br>    x = np.array(x).ravel()<br>    <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i &gt; <span class="hljs-number">0</span>:<br>        l = <span class="hljs-built_in">len</span>(x)<br>        w = np.logspace(l, <span class="hljs-number">0</span>, num=l, base=(<span class="hljs-number">1</span>-i))      <span class="hljs-comment">#生成等比数列</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平滑因子范围错误&#x27;</span>)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/np.<span class="hljs-built_in">sum</span>(w)         <span class="hljs-comment">#指数移动平均</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MA_prediction</span>(<span class="hljs-params">data, q, predict_x_n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-comment">##########################   移动平均预测    ################################</span><br>    df = np.array(data).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，存储真实值以及预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)-q+<span class="hljs-number">1</span>):<br>        df[q+i-<span class="hljs-number">1</span>] = ema(data[i:i+q],<span class="hljs-number">0.5</span>)         <span class="hljs-comment">#获得简单移动平均获得的预测数列</span><br><br>    df_wu = df0 - df        <span class="hljs-comment">#获得误差项</span><br><br>    df1 = np.zeros(predict_x_n)      <span class="hljs-comment">#存储预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = ema(df0[-q:],<span class="hljs-number">0.5</span>)        <span class="hljs-comment">#得到所有预测值</span><br>        df0 = np.append(df0,df1[i])<br>    <span class="hljs-comment">##############################   误差项预测   ###############################</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">MA_AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):           <span class="hljs-comment">#误差项预测实际就为AR预测，这也是为什么MA模型阶数为0时就转化成AR模型的原因</span><br>        df = np.array(x[p:]).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>        df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>        Y = df[p:].copy()<br>        h = <span class="hljs-built_in">len</span>(df0)-p<br>        X = np.zeros((h,p+<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>            X[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>                X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>        sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>            df0[p+i] = <span class="hljs-built_in">sum</span>(sigma * X[i])        <span class="hljs-comment">#得到所有预测的估计值</span><br>        df00 = df.copy()<br>        df1 = np.zeros(predict_x_n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>            df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>            df00 = np.append(df00,df1[i])<br>        <span class="hljs-keyword">return</span> df0,df1<br>    wucha,wucha_predict = MA_AR_prediction(df_wu,q,predict_x_n)<br>    <span class="hljs-keyword">return</span> wucha,wucha_predict<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ARMA</span>(<span class="hljs-params">p,q</span>):<br>    wucha,wucha_predict = MA_prediction(data, q, <span class="hljs-number">0</span>)<br>    <span class="hljs-comment">#p_aicc,p_bic = p_finally(10)</span><br>    df0,df1 = AR_prediction(data,p,<span class="hljs-number">0</span>)<br>    result = df0[-<span class="hljs-built_in">len</span>(wucha):] - wucha<br>    <span class="hljs-keyword">return</span> result<br><br>result = ARMA(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>)<br>plt.figure()<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>),data[-<span class="hljs-number">60</span>:],c = <span class="hljs-string">&#x27;black&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>),result[-<span class="hljs-number">60</span>:],c=<span class="hljs-string">&#x27;red&#x27;</span>)<br>plt.show()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mse:&#x27;</span>,mean_squared_error(result,data[-<span class="hljs-built_in">len</span>(result):]))<br></code></pre></td></tr></table></figure><h1 id="四，ARIMA预测"><a href="#四，ARIMA预测" class="headerlink" title="四，ARIMA预测"></a>四，ARIMA预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> copy<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> statsmodels.api <span class="hljs-keyword">as</span> sm<br><span class="hljs-keyword">from</span> statsmodels.stats.diagnostic <span class="hljs-keyword">import</span> acorr_ljungbox<br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf,plot_acf<br><span class="hljs-keyword">import</span> warnings<br><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br>data = pd.read_csv(<span class="hljs-string">&#x27;时间序列预测数据集.csv&#x27;</span>,parse_dates=[<span class="hljs-string">&#x27;Date&#x27;</span>])<br>data.set_index(<span class="hljs-string">&#x27;Date&#x27;</span>,inplace=<span class="hljs-literal">True</span>)     <span class="hljs-comment">#将时间设置为行索引</span><br><br><span class="hljs-comment">####################################   绘制时序图   ############################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">picture</span>(<span class="hljs-params">data</span>):<br>    plt.figure(figsize=(<span class="hljs-number">16</span>,<span class="hljs-number">16</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>):<br>        plt.subplot(<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,i)<br>        df = data[<span class="hljs-string">f&quot;198<span class="hljs-subst">&#123;<span class="hljs-number">1</span>+<span class="hljs-number">2</span>*(i-<span class="hljs-number">1</span>)&#125;</span>-01-01&quot;</span>:<span class="hljs-string">f&quot;198<span class="hljs-subst">&#123;<span class="hljs-number">3</span>+<span class="hljs-number">2</span>*(i-<span class="hljs-number">1</span>)&#125;</span>-01-01&quot;</span>]<br>        plt.plot(df.index,df[<span class="hljs-string">&#x27;Temp&#x27;</span>].values)<br>        plt.xticks(rotation=<span class="hljs-number">45</span>,size=<span class="hljs-number">6</span>)<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">1</span>:<br>            plt.title(<span class="hljs-string">&quot;时序图&quot;</span>)<br>    plt.show()<br>    plt.close()<br><span class="hljs-comment">######################################   时间序列检验      #######################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">inspect</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-comment"># 单位根检验-ADF检验</span><br>    ADF = sm.tsa.stattools.adfuller(data[<span class="hljs-string">&#x27;Temp&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;ADF值:&#x27;</span>, <span class="hljs-built_in">format</span>(ADF[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;.4f&#x27;</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;拒绝程度值:&#x27;</span>, ADF[<span class="hljs-number">4</span>])      <span class="hljs-comment">#ADF值需要小于三个拒绝程度值</span><br><br>    <span class="hljs-comment"># 白噪声检验</span><br>    white_noise = acorr_ljungbox(data[<span class="hljs-string">&#x27;Temp&#x27;</span>], lags = [<span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>],boxpierce=<span class="hljs-literal">True</span>) <span class="hljs-comment">#lag是需要检验的阶数</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;白噪声检验:\n&#x27;</span>,white_noise)   <span class="hljs-comment">#LB和BP统计量的P值都小于显著水平（α = 0.05）,所以拒绝序列为纯随机序列的原假设，认为该序列为非白噪声序列</span><br><br>    fig = plt.figure(figsize=(<span class="hljs-number">16</span>,<span class="hljs-number">6</span>))<br><br>    ax1 = fig.add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>    plot_acf(data[<span class="hljs-string">&#x27;Temp&#x27;</span>],ax=ax1)<br>    plt.title(<span class="hljs-string">&quot;自相关图&quot;</span>)        <span class="hljs-comment">#需要拖尾</span><br><br>    ax2 = fig.add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>    plot_pacf(data[<span class="hljs-string">&#x27;Temp&#x27;</span>],ax=ax2)<br>    plt.title(<span class="hljs-string">&quot;偏自相关图&quot;</span>)      <span class="hljs-comment">#需要截尾,确定p</span><br><br>    plt.show()<br>    plt.close()<br><span class="hljs-comment">#####################################    信息准则    ###########################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">information</span>(<span class="hljs-params">df,df0,p</span>):<br>    n = <span class="hljs-built_in">len</span>(df)<br>    mse = mean_squared_error(df,df0)<br>    <span class="hljs-comment">#aic = n * log(mse) + 2 * p</span><br>    aicc = log(mse) + (n+p)/(n-p-<span class="hljs-number">2</span>)<br>    bic = n * log(mse) + p * log(n)<br>    <span class="hljs-keyword">return</span> aicc,bic<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):<br>    df = np.array(x).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>    Y = df[p:].copy()<br>    h = <span class="hljs-built_in">len</span>(df0)-p<br>    X = np.zeros((h,p+<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>        X[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>            X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>    sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        df0[p+i] = <span class="hljs-built_in">sum</span>(sigma * X[i])      <span class="hljs-comment">#得到所有预测的估计值</span><br>    df00 = df.copy()<br>    df1 = np.zeros(predict_x_n)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = <span class="hljs-built_in">sum</span>(sigma[<span class="hljs-number">1</span>:] * df00[-p:][::-<span class="hljs-number">1</span>])+sigma[<span class="hljs-number">0</span>]        <span class="hljs-comment">#得到所有预测值</span><br>        df00 = np.append(df00,df1[i])<br>    <span class="hljs-keyword">return</span> df0,df1<br><br><span class="hljs-comment">#########################################   阶数确定   ##############################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">p_finally</span>(<span class="hljs-params">n</span>):<br>    jieguo = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,n):<br>        df0,df1 = AR_prediction(data,i)<br>        aicc,bic = information(data,df0,i)<br>        jieguo.append([i,aicc,bic])<br>    jieguo_aicc = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])  <span class="hljs-comment">#以aicc排序</span><br>    jieguo_bic = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">2</span>])  <span class="hljs-comment">#以bic排序</span><br>    <span class="hljs-keyword">return</span> jieguo_aicc[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>],jieguo_bic[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sma</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.mean(x)        <span class="hljs-comment">#简单移动平均</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">wma</span>(<span class="hljs-params">x</span>):<br>    x = np.array(x).ravel()<br>    w = np.arange(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)      <span class="hljs-comment">#生成等差数列</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/(<span class="hljs-built_in">len</span>(x)*(<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>)       <span class="hljs-comment">#加权移动平均（等距）</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ema</span>(<span class="hljs-params">x,i</span>):<br>    x = np.array(x).ravel()<br>    <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i &gt; <span class="hljs-number">0</span>:<br>        l = <span class="hljs-built_in">len</span>(x)<br>        w = np.logspace(l, <span class="hljs-number">0</span>, num=l, base=(<span class="hljs-number">1</span>-i))      <span class="hljs-comment">#生成等比数列</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平滑因子范围错误&#x27;</span>)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/np.<span class="hljs-built_in">sum</span>(w)         <span class="hljs-comment">#指数移动平均</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MA_prediction</span>(<span class="hljs-params">data, q, predict_x_n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-comment">##########################   移动平均预测    ################################</span><br>    df = np.array(data).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，存储真实值以及预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)-q+<span class="hljs-number">1</span>):<br>        df[q+i-<span class="hljs-number">1</span>] = ema(data[i:i+q],<span class="hljs-number">0.5</span>)         <span class="hljs-comment">#获得简单移动平均获得的预测数列</span><br><br>    df_wu = df0 - df        <span class="hljs-comment">#获得误差项</span><br><br>    df1 = np.zeros(predict_x_n)      <span class="hljs-comment">#存储预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = ema(df0[-q:],<span class="hljs-number">0.5</span>)        <span class="hljs-comment">#得到所有预测值</span><br>        df0 = np.append(df0,df1[i])<br>    <span class="hljs-comment">##############################   误差项预测   ###############################</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">MA_AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):           <span class="hljs-comment">#误差项预测实际就为AR预测，这也是为什么MA模型阶数为0时就转化成AR模型的原因</span><br>        df = np.array(x[p:]).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>        df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>        Y = df[p:].copy()<br>        h = <span class="hljs-built_in">len</span>(df0)-p<br>        X = np.zeros((h,p+<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>            X[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>                X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>        sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>            df0[p+i] = <span class="hljs-built_in">sum</span>(sigma * X[i])        <span class="hljs-comment">#得到所有预测的估计值</span><br>        df00 = df.copy()<br>        df1 = np.zeros(predict_x_n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>            df1[i] = <span class="hljs-built_in">sum</span>(sigma[<span class="hljs-number">1</span>:] * df00[-p:][::-<span class="hljs-number">1</span>])+sigma[<span class="hljs-number">0</span>]       <span class="hljs-comment">#得到所有预测值</span><br>            df00 = np.append(df00,df1[i])<br>        <span class="hljs-keyword">return</span> df0,df1<br>    wucha,wucha_predict = MA_AR_prediction(df_wu,q,predict_x_n)<br>    <span class="hljs-keyword">return</span> wucha,wucha_predict<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sum_s</span>(<span class="hljs-params">data,df,q,result_predict</span>):<br>    data = np.array(data).ravel()<br>    df = np.array(df).ravel()<br>    result_predict = np.array(result_predict).ravel()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data)-<span class="hljs-built_in">len</span>(df)==<span class="hljs-number">1</span>+q:<br>        data0 = np.zeros(<span class="hljs-built_in">len</span>(data))<br>        data0[<span class="hljs-number">0</span>] = data[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)-<span class="hljs-number">1</span>):<br>            data0[i+<span class="hljs-number">1</span>] = data[i]<br>        df0 = np.zeros(<span class="hljs-built_in">len</span>(df)+<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(df)):<br>            df0[i+<span class="hljs-number">1</span>] = df[i]<br>        asd = data0[-<span class="hljs-built_in">len</span>(df0):]+df0<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result_predict)):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>                result_predict[<span class="hljs-number">0</span>]=result_predict[<span class="hljs-number">0</span>]+asd[-<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">else</span>:<br>                result_predict[i]=result_predict[i]+result_predict[i-<span class="hljs-number">1</span>]<br>                <span class="hljs-built_in">print</span>(result_predict)<br>        <span class="hljs-keyword">return</span> asd,result_predict<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(data)-<span class="hljs-built_in">len</span>(df)==<span class="hljs-number">2</span>+q:<br>        cha1 = np.diff(data)<br>        cha1_1,result_predict = sum_s(cha1,df,q,result_predict)<br>        <span class="hljs-keyword">return</span> sum_s(data,cha1_1,q,result_predict)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(data)-<span class="hljs-built_in">len</span>(df)==<span class="hljs-number">3</span>+q:<br>        cha1 = np.diff(data)<br>        cha11 = np.diff(cha1)<br>        cha1_1,result_predict = sum_s(cha11,df,q,result_predict)<br>        cha1_1_1,result_predict = sum_s(cha1,cha1_1,q,result_predict)<br>        <span class="hljs-keyword">return</span> sum_s(data,cha1_1_1,q,result_predict)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ARIMA</span>(<span class="hljs-params">p,q,d,data,predict_n=<span class="hljs-number">0</span></span>):<br>    df_0 = np.array(data).ravel()<br>    df = np.diff(df_0,d)<br>    wucha,wucha_predict = MA_prediction(df, q, predict_n)<br>    <span class="hljs-comment">#p_aicc,p_bic = p_finally(10)</span><br>    df0,df1 = AR_prediction(df,p,predict_n)<br>    result = df0[-<span class="hljs-built_in">len</span>(wucha):] - wucha<br>    result_predict = df1-wucha_predict<br>    <span class="hljs-keyword">if</span> d != <span class="hljs-number">0</span>:<br>        result,result_predict = sum_s(df_0,result,q,result_predict)<br>    <span class="hljs-keyword">return</span> result,result_predict<br><br>result,result_predict = ARIMA(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>,data,<span class="hljs-number">4</span>)<br><br>asd = np.append(result,result_predict)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data[-<span class="hljs-number">60</span>:])),data[-<span class="hljs-number">60</span>:],c=<span class="hljs-string">&#x27;b&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result[-<span class="hljs-number">63</span>:])),asd[-<span class="hljs-number">63</span>:],c=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h1 id="五，SARIMA预测"><a href="#五，SARIMA预测" class="headerlink" title="五，SARIMA预测"></a>五，SARIMA预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> copy<br><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br><br><span class="hljs-comment">#####################################    信息准则    ###########################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">information</span>(<span class="hljs-params">df,df0,p</span>):<br>    n = <span class="hljs-built_in">len</span>(df)<br>    mse = mean_squared_error(df,df0)<br>    <span class="hljs-comment">#aic = n * log(mse) + 2 * p</span><br>    aicc = log(mse) + (n+p)/(n-p-<span class="hljs-number">2</span>)<br>    bic = n * log(mse) + p * log(n)<br>    <span class="hljs-keyword">return</span> aicc,bic<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):<br>    df = np.array(x).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>    Y = df[p:].copy()<br>    h = <span class="hljs-built_in">len</span>(df0)-p<br>    X = np.zeros((h,p))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>            X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>    sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        df0[p+i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , X[i]))        <span class="hljs-comment">#得到所有预测的估计值</span><br>    df00 = df.copy()<br>    df1 = np.zeros(predict_x_n)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>        df00 = np.append(df00,df1[i])<br>    <span class="hljs-keyword">return</span> df0,df1,sigma<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">SAR</span>(<span class="hljs-params">x,p,s,predict_x_n=<span class="hljs-number">0</span></span>):<br>    x = np.array(x).ravel()<br>    df0 = x.copy()<br>    Y = x[s*p:].copy()<br>    h = <span class="hljs-built_in">len</span>(x) - p*s<br>    X = np.zeros((h,p))<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>            X[t][-i] = x[p*s+t-i*s]<br>    sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        df0[p*s+i] = <span class="hljs-built_in">sum</span>(sigma * X[i])        <span class="hljs-comment">#得到所有预测的估计值</span><br>    df00 = x.copy()<br>    df1 = np.zeros(predict_x_n)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>        df00 = np.append(df00,df1[i])<br>    <span class="hljs-keyword">return</span> df0,df1,sigma<br><br><span class="hljs-comment">#########################################   阶数确定   ##############################################</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">p_finally</span>(<span class="hljs-params">n</span>):<br>    jieguo = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,n):<br>        df0,df1 = AR_prediction(data,i)<br>        aicc,bic = information(data,df0,i)<br>        jieguo.append([i,aicc,bic])<br>    jieguo_aicc = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])  <span class="hljs-comment">#以aicc排序</span><br>    jieguo_bic = <span class="hljs-built_in">sorted</span>(jieguo,reverse=<span class="hljs-literal">False</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">2</span>])  <span class="hljs-comment">#以bic排序</span><br>    <span class="hljs-keyword">return</span> jieguo_aicc[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>],jieguo_bic[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MA_prediction</span>(<span class="hljs-params">data, q, predict_x_n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sma</span>(<span class="hljs-params">x</span>):<br>        <span class="hljs-keyword">return</span> np.mean(x)        <span class="hljs-comment">#简单移动平均</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wma</span>(<span class="hljs-params">x</span>):<br>        x = np.array(x).ravel()<br>        w = np.arange(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)      <span class="hljs-comment">#生成等差数列</span><br>        <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/(<span class="hljs-built_in">len</span>(x)*(<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>)       <span class="hljs-comment">#加权移动平均（等距）</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">ema</span>(<span class="hljs-params">x,i</span>):<br>        x = np.array(x).ravel()<br>        <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i &gt; <span class="hljs-number">0</span>:<br>            l = <span class="hljs-built_in">len</span>(x)<br>            w = np.logspace(l, <span class="hljs-number">0</span>, num=l, base=(<span class="hljs-number">1</span>-i))      <span class="hljs-comment">#生成等比数列</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平滑因子范围错误&#x27;</span>)<br>        <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/np.<span class="hljs-built_in">sum</span>(w)         <span class="hljs-comment">#指数移动平均</span><br>    <span class="hljs-comment">##########################   移动平均预测    ################################</span><br>    df = np.array(data).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，存储真实值以及预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(df0)-q+<span class="hljs-number">1</span>):<br>        df[q+i-<span class="hljs-number">1</span>] = ema(df0[i:i+q],<span class="hljs-number">0.5</span>)         <span class="hljs-comment">#获得简单移动平均获得的预测数列</span><br><br>    df_wu = df0 - df        <span class="hljs-comment">#获得误差项</span><br><br>    df1 = np.zeros(predict_x_n)      <span class="hljs-comment">#存储预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = ema(df0[-q:],<span class="hljs-number">0.5</span>)        <span class="hljs-comment">#得到所有预测值</span><br>        df0 = np.append(df0,df1[i])<br>    <span class="hljs-comment">##############################   误差项预测   ###############################</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">MA_AR_prediction</span>(<span class="hljs-params">x, p, predict_x_n = <span class="hljs-number">0</span></span>):           <span class="hljs-comment">#误差项预测实际就为AR预测，这也是为什么MA模型阶数为0时就转化成AR模型的原因</span><br>        df = np.array(x[p:]).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>        df0 = df.copy()         <span class="hljs-comment">#准备一个副本，为了存储预测的数据</span><br>        Y = df[p:].copy()<br>        h = <span class="hljs-built_in">len</span>(df0)-p<br>        X = np.zeros((h,p))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):            <span class="hljs-comment">#得到X矩阵</span><br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>                X[i,-v] = df[i+v-<span class="hljs-number">1</span>]<br>        sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>            df0[p+i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , X[i]))        <span class="hljs-comment">#得到所有预测的估计值</span><br>        df00 = df.copy()<br>        df1 = np.zeros(predict_x_n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>            df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>            df00 = np.append(df00,df1[i])<br>        <span class="hljs-keyword">return</span> df0,df1,sigma<br>    wucha,wucha_predict,sigma = MA_AR_prediction(df_wu,q,predict_x_n)<br>    <span class="hljs-keyword">return</span> wucha,wucha_predict,sigma,df_wu<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">SMA</span>(<span class="hljs-params">data,q,s,predict_x_n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sma</span>(<span class="hljs-params">x</span>):<br>        <span class="hljs-keyword">return</span> np.mean(x)        <span class="hljs-comment">#简单移动平均</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wma</span>(<span class="hljs-params">x</span>):<br>        x = np.array(x).ravel()<br>        w = np.arange(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)      <span class="hljs-comment">#生成等差数列</span><br>        <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/(<span class="hljs-built_in">len</span>(x)*(<span class="hljs-built_in">len</span>(x)+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>)       <span class="hljs-comment">#加权移动平均（等距）</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">ema</span>(<span class="hljs-params">x,i</span>):<br>        x = np.array(x).ravel()<br>        <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i &gt; <span class="hljs-number">0</span>:<br>            l = <span class="hljs-built_in">len</span>(x)<br>            w = np.logspace(l, <span class="hljs-number">0</span>, num=l, base=(<span class="hljs-number">1</span>-i))      <span class="hljs-comment">#生成等比数列</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;平滑因子范围错误&#x27;</span>)<br>        <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(x*w)/np.<span class="hljs-built_in">sum</span>(w)         <span class="hljs-comment">#指数移动平均</span><br>    <span class="hljs-comment">##########################   移动平均预测    ################################</span><br>    df = np.array(data).ravel()     <span class="hljs-comment">#将数据转化为numpy格式，并将其转化为一维列表</span><br>    df0 = df.copy()         <span class="hljs-comment">#准备一个副本，存储真实值以及预测值</span><br>    h = <span class="hljs-built_in">len</span>(data) - q*s<br>    X = np.zeros((h,q))<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,q+<span class="hljs-number">1</span>):<br>            X[t][-i] = df[q*s+t-i*s]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>        df[q*s+i] = ema(X[i],<span class="hljs-number">0.5</span>)         <span class="hljs-comment">#获得简单移动平均获得的预测数列</span><br><br>    df_wu = df0 - df        <span class="hljs-comment">#获得误差项</span><br><br>    df1 = np.zeros(predict_x_n)      <span class="hljs-comment">#存储预测值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>        df1[i] = ema(df0[-q:],<span class="hljs-number">0.5</span>)        <span class="hljs-comment">#得到所有预测值</span><br>        df0 = np.append(df0,df1[i])<br>    <span class="hljs-comment">##############################   误差项预测   ###############################</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">SAR</span>(<span class="hljs-params">x,p,s,predict_x_n=<span class="hljs-number">0</span></span>):<br>        x = np.array(x[p*s:]).ravel()<br>        df0 = x.copy()<br>        Y = x[s*p:].copy()<br>        h = <span class="hljs-built_in">len</span>(x) - p*s<br>        X = np.zeros((h,p))<br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,p+<span class="hljs-number">1</span>):<br>                X[t][-i] = x[p*s+t-i*s]<br>        sigma = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y.T)          <span class="hljs-comment">#最小二乘法估计参数值</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(h):<br>            df0[p*s+i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , X[i]))        <span class="hljs-comment">#得到所有预测的估计值</span><br>        df00 = x.copy()<br>        df1 = np.zeros(predict_x_n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(predict_x_n):<br>            df1[i] = <span class="hljs-built_in">sum</span>(np.multiply(sigma , df00[-p:][::-<span class="hljs-number">1</span>]))        <span class="hljs-comment">#得到所有预测值</span><br>            df00 = np.append(df00,df1[i])<br>        <span class="hljs-keyword">return</span> df0,df1,sigma<br>    wucha,wucha_predict,sigma = SAR(df_wu,q,s,predict_x_n)<br>    <span class="hljs-keyword">return</span> wucha,wucha_predict,sigma<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">SARIMA</span>(<span class="hljs-params">p,q,P,Q,data,m</span>):<br>    <span class="hljs-comment">#p_aicc,p_bic = p_finally(10)</span><br>    df0,df1,sigma = AR_prediction(data,p,<span class="hljs-number">0</span>)<br>    wucha,wucha_predict,sigma1,df_wu = MA_prediction(data, q, <span class="hljs-number">0</span>)<br>    a,b,sigma2 = SAR(data,P,m,<span class="hljs-number">0</span>)<br>    c,d,sigma3 = SMA(data,Q,m,<span class="hljs-number">0</span>)<br>    sigma = sigma[::-<span class="hljs-number">1</span>]<br>    sigma1 = sigma1[::-<span class="hljs-number">1</span>]<br>    sigma2 = sigma2[::-<span class="hljs-number">1</span>]<br>    sigma3 = sigma3[::-<span class="hljs-number">1</span>]<br>    sigma22 = np.append(np.array([<span class="hljs-number">1</span>]),sigma2)<br>    sigma33 = np.append(np.array([<span class="hljs-number">1</span>]),sigma3)<br>    result = []<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">30</span>,<span class="hljs-built_in">len</span>(data)+<span class="hljs-number">1</span>):<br>        sar = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(p):<br>            <span class="hljs-keyword">for</span> P <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(P+<span class="hljs-number">1</span>):<br>                sar += sigma[p] * data[t-p-<span class="hljs-number">1</span>-P*m] * sigma22[P]<br>        sar += <span class="hljs-built_in">sum</span>(sigma2 * np.array([data[t-i*m] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,P+<span class="hljs-number">1</span>)]))<br>        sma = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(q):<br>            <span class="hljs-keyword">for</span> Q <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Q+<span class="hljs-number">1</span>):<br>                sma += sigma1[q] * df_wu[t-q-<span class="hljs-number">1</span>-Q*m] * sigma33[Q]<br>        sma += <span class="hljs-built_in">sum</span>(sigma3 * np.array([df_wu[t-i*m] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,Q+<span class="hljs-number">1</span>)]))<br>        result.append(sar + sma)<br>    <span class="hljs-keyword">return</span> result<br><br><br>data0 = pd.read_csv(<span class="hljs-string">&#x27;时间序列预测数据集.csv&#x27;</span>,parse_dates=[<span class="hljs-string">&#x27;Date&#x27;</span>])<br>data0.set_index(<span class="hljs-string">&#x27;Date&#x27;</span>,inplace=<span class="hljs-literal">True</span>)     <span class="hljs-comment">#将时间设置为行索引</span><br>data=np.array(copy.deepcopy(data0)).ravel()<br><span class="hljs-comment">#data = data.reshape((10,365))    #季节性差分</span><br><span class="hljs-comment">#data=np.diff(data,1)</span><br><span class="hljs-comment">#data = data.ravel()</span><br>result = SARIMA(<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,data,<span class="hljs-number">365</span>)<br>plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">7.5</span>))<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">500</span>),data[-<span class="hljs-number">500</span>:],c = <span class="hljs-string">&#x27;black&#x27;</span>,label=<span class="hljs-string">&#x27;actual&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">500</span>),result[-<span class="hljs-number">500</span>:],c=<span class="hljs-string">&#x27;red&#x27;</span>,label=<span class="hljs-string">&#x27;model&#x27;</span>)<br>plt.show()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mse:&#x27;</span>,mean_squared_error(result,data[-<span class="hljs-built_in">len</span>(result):]))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>灰色预测代码</title>
    <link href="/2024/09/11/%E7%81%B0%E8%89%B2%E9%A2%84%E6%B5%8B/"/>
    <url>/2024/09/11/%E7%81%B0%E8%89%B2%E9%A2%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> matplotlib.pyplot  <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy<br><span class="hljs-keyword">import</span> plotly.graph_objects <span class="hljs-keyword">as</span> go<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span><br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br><br><br>X = np.array([-<span class="hljs-number">18</span>, <span class="hljs-number">0.34</span>, <span class="hljs-number">4.68</span>, <span class="hljs-number">8.49</span>, <span class="hljs-number">29.84</span>, <span class="hljs-number">50.21</span>, <span class="hljs-number">77.65</span>, <span class="hljs-number">109.36</span>])<br>x = np.array([[<span class="hljs-number">83.0</span>, <span class="hljs-number">79.8</span>, <span class="hljs-number">78.1</span>, <span class="hljs-number">85.1</span>, <span class="hljs-number">86.6</span>, <span class="hljs-number">88.2</span>, <span class="hljs-number">90.3</span>, <span class="hljs-number">86.7</span>, <span class="hljs-number">93.3</span>, <span class="hljs-number">92.5</span>, <span class="hljs-number">90.9</span>, <span class="hljs-number">96.9</span>],<br>              [<span class="hljs-number">101.7</span>, <span class="hljs-number">85.1</span>, <span class="hljs-number">87.8</span>, <span class="hljs-number">91.6</span>, <span class="hljs-number">93.4</span>, <span class="hljs-number">94.5</span>, <span class="hljs-number">97.4</span>, <span class="hljs-number">99.5</span>, <span class="hljs-number">104.2</span>, <span class="hljs-number">102.3</span>, <span class="hljs-number">101.0</span>, <span class="hljs-number">123.5</span>],<br>              [<span class="hljs-number">92.2</span>, <span class="hljs-number">114.0</span>, <span class="hljs-number">93.3</span>, <span class="hljs-number">101.0</span>, <span class="hljs-number">103.5</span>, <span class="hljs-number">105.2</span>, <span class="hljs-number">109.5</span>, <span class="hljs-number">109.2</span>, <span class="hljs-number">109.6</span>, <span class="hljs-number">111.2</span>, <span class="hljs-number">121.7</span>, <span class="hljs-number">131.3</span>],<br>              [<span class="hljs-number">105.0</span>, <span class="hljs-number">125.7</span>, <span class="hljs-number">106.6</span>, <span class="hljs-number">116.0</span>, <span class="hljs-number">117.6</span>, <span class="hljs-number">118.0</span>, <span class="hljs-number">121.7</span>, <span class="hljs-number">118.7</span>, <span class="hljs-number">120.2</span>, <span class="hljs-number">127.8</span>, <span class="hljs-number">121.8</span>, <span class="hljs-number">121.9</span>],<br>              [<span class="hljs-number">139.3</span>, <span class="hljs-number">129.5</span>, <span class="hljs-number">122.5</span>, <span class="hljs-number">124.5</span>, <span class="hljs-number">135.7</span>, <span class="hljs-number">130.8</span>, <span class="hljs-number">138.7</span>, <span class="hljs-number">133.7</span>, <span class="hljs-number">136.8</span>, <span class="hljs-number">138.9</span>, <span class="hljs-number">129.6</span>, <span class="hljs-number">133.7</span>],<br>              [<span class="hljs-number">137.5</span>, <span class="hljs-number">135.3</span>, <span class="hljs-number">133.0</span>, <span class="hljs-number">133.4</span>, <span class="hljs-number">142.8</span>, <span class="hljs-number">141.6</span>, <span class="hljs-number">142.9</span>, <span class="hljs-number">147.3</span>, <span class="hljs-number">159.6</span>, <span class="hljs-number">162.1</span>, <span class="hljs-number">153.5</span>, <span class="hljs-number">155.9</span>]])<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grey_model</span>(<span class="hljs-params">X,form,y</span>):      <span class="hljs-comment">#X为代预测的数列，form为预测的数量,y为是否绘图，0不画，1画</span><br>    x_0 = deepcopy(X)<br>    <span class="hljs-comment">##########################################          级比检验         ###########################################</span><br>    x_n = [X[i] / X[i + <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X) - <span class="hljs-number">1</span>)]       <span class="hljs-comment">#计算原数列的级比</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(n &lt;= math.exp(-<span class="hljs-number">2</span> / (<span class="hljs-built_in">len</span>(X) + <span class="hljs-number">1</span>)) <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> x_n)==<span class="hljs-literal">True</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">any</span>(n &gt;= math.exp(-<span class="hljs-number">2</span> / (<span class="hljs-built_in">len</span>(X) + <span class="hljs-number">2</span>)) <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> x_n)==<span class="hljs-literal">True</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;______未通过级比检验______&#x27;</span>)<br>        <span class="hljs-comment">####################     级比检验不通过处理      ####################</span><br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            X += <span class="hljs-number">10</span>      <span class="hljs-comment">#以10为步长慢慢给原数列加数值</span><br>            x_n_new = [X[i] / X[i + <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X) - <span class="hljs-number">1</span>)]     <span class="hljs-comment">#计算每一个新的数列的级比</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(n &lt;= np.exp(-<span class="hljs-number">2</span> / (<span class="hljs-built_in">len</span>(X) + <span class="hljs-number">1</span>)) <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> x_n_new)==<span class="hljs-literal">True</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">any</span>(n &gt;= np.exp(<span class="hljs-number">2</span> / (<span class="hljs-built_in">len</span>(X) + <span class="hljs-number">1</span>)) <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> x_n_new)==<span class="hljs-literal">True</span>:<br>                i += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;修正数列为：\n&#x27;</span>,X)<br>                sc = <span class="hljs-number">10</span>*(i+<span class="hljs-number">1</span>)<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;修正值为：\n&#x27;</span>,sc)<br>                <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;_______通过级比检验______&quot;</span>)<br><br>    <span class="hljs-comment">######################################     模型构建与求解     #######################################</span><br>    X_sum = X.cumsum()   <span class="hljs-comment"># 重新求得累加数列</span><br><br>    z_n = [(X_sum[i] + X_sum[i + <span class="hljs-number">1</span>]) / <span class="hljs-number">2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X_sum)-<span class="hljs-number">1</span>)]   <span class="hljs-comment"># 紧邻均值序列</span><br><br>    <span class="hljs-comment">############# 最小二乘法计算 ###############</span><br>    Y = [X[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(X))]  <span class="hljs-comment">#生成数组Y</span><br>    Y = np.array(Y)   <span class="hljs-comment">#将数组转化为numpy数组</span><br>    Y = Y.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)   <span class="hljs-comment">#转换格式</span><br><br>    B = [-z_n[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(z_n))]  <span class="hljs-comment">#生成数组B</span><br>    B = np.array(B)   <span class="hljs-comment">#将数组转化为numpy数组</span><br>    B = B.reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)   <span class="hljs-comment">#转换格式</span><br>    c = np.ones((<span class="hljs-built_in">len</span>(B),<span class="hljs-number">1</span>))    <span class="hljs-comment">#生成数值全为1的一列数组</span><br>    B = np.hstack((B,c))     <span class="hljs-comment">#将两者相连</span><br><br>    parameters = np.linalg.inv(B.T.dot(B)).dot(B.T).dot(Y)  <span class="hljs-comment"># 通过numpy求出参数（最小二乘法）</span><br>    a = parameters[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]   <span class="hljs-comment">#索引到a参数</span><br>    b = parameters[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]   <span class="hljs-comment">#索引到b参数</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;a=&quot;</span>,a)   <span class="hljs-comment"># 打印结果</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;b=&quot;</span>,b)<br><br>    <span class="hljs-comment">#生成预测模型#####################################################        要改在这改     ################################</span><br>    b_a = b/a  <span class="hljs-comment">#提前计算好常数项，减少后续程序的计算</span><br>    model_predict = [(X[<span class="hljs-number">0</span>] - b_a) * np.exp(-a * k) + b_a <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X)+form)]  <span class="hljs-comment">#生成预测数列</span><br><br>    list_predict = np.concatenate(([model_predict[<span class="hljs-number">0</span>]], np.diff(model_predict))) - sc <span class="hljs-comment"># 先累减获得预测数列，再做差得到真的预测序列</span><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;预测数列为:\n&quot;</span>,list_predict)<br>    list_predict = [<span class="hljs-built_in">float</span>(<span class="hljs-built_in">format</span>(i,<span class="hljs-string">&#x27;.4f&#x27;</span>)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> list_predict]<br>    <span class="hljs-keyword">if</span> y == <span class="hljs-number">1</span>:<br>        <span class="hljs-comment">#####################################     绘图     ####################################</span><br>        fig = go.Figure()<br>        fig.add_trace(go.Scatter(x=<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X))),y=x_0,         <span class="hljs-comment">#添加x,y</span><br>                                 mode=<span class="hljs-string">&quot;markers+lines+text&quot;</span>,text=x_0,textposition=<span class="hljs-string">&quot;top center&quot;</span>,  <span class="hljs-comment">#设置坐标点显示</span><br>                                 name=<span class="hljs-string">&#x27;原数列&#x27;</span>))  <span class="hljs-comment">#设置标签名</span><br>        fig.add_trace(go.Scatter(x=<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(X)+form)),y=list_predict,        <span class="hljs-comment">#添加x,y</span><br>                                 mode=<span class="hljs-string">&quot;markers+lines+text&quot;</span>,text=list_predict,textposition=<span class="hljs-string">&quot;top center&quot;</span>,  <span class="hljs-comment">#设置坐标点显示</span><br>                                 name=<span class="hljs-string">&#x27;预测数列&#x27;</span>))   <span class="hljs-comment">#设置标签名</span><br>        fig.update_layout(title=<span class="hljs-string">&quot;灰色预测&quot;</span>,     <span class="hljs-comment">#设置图表名</span><br>                          xaxis=<span class="hljs-built_in">dict</span>(title=<span class="hljs-string">&quot;时间序号&quot;</span>),    <span class="hljs-comment">#设置x轴参数</span><br>                          yaxis=<span class="hljs-built_in">dict</span>(title=<span class="hljs-string">&quot;值&quot;</span>),      <span class="hljs-comment">#设置y轴参数</span><br>                          title_x=<span class="hljs-number">0.5</span>,  <span class="hljs-comment"># 将标题居中</span><br>                          title_y=<span class="hljs-number">0.94</span>,  <span class="hljs-comment"># 将标题置于上方</span><br>                          template=<span class="hljs-string">&quot;plotly&quot;</span>)<br>        fig.show()<br><br>    <span class="hljs-comment">########################################      模型检验      #######################################</span><br>    G = np.array(list_predict[:<span class="hljs-built_in">len</span>(list_predict)-form])  <span class="hljs-comment">#生成与真实数列对应的预测数列</span><br>    e = x_0 - G  <span class="hljs-comment">#获得每一个预测值的残差</span><br>    q = <span class="hljs-built_in">abs</span>(e / x_0)  <span class="hljs-comment"># 获得每一个预测值的相对误差</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;相对误差数列为:\n&quot;</span>,q)<br>    q_q = q.<span class="hljs-built_in">sum</span>()/(<span class="hljs-built_in">len</span>(q)-<span class="hljs-number">1</span>)   <span class="hljs-comment">#求得平均相对误差</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;平均相对误差为:\n<span class="hljs-subst">&#123;q_q:<span class="hljs-number">.4</span>f&#125;</span>&quot;</span>)<br><br>    S0 = np.sqrt(np.var(x_0))   <span class="hljs-comment">#原数列的标准差</span><br>    S1 = np.sqrt(np.var(e))    <span class="hljs-comment">#残差数列的标准差</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;后验差比值C为:\n&#x27;</span>,S1 / S0)<br><br>    E = e.<span class="hljs-built_in">sum</span>()/(<span class="hljs-built_in">len</span>(e)-<span class="hljs-number">1</span>)    <span class="hljs-comment">#计算残差的均值</span><br>    yu_zhi = <span class="hljs-number">0.6745</span>*S0<br>    g = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(e)):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(e[i]-E) &lt; yu_zhi:<br>            g += <span class="hljs-number">1</span><br>    p = g/<span class="hljs-built_in">len</span>(e)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;小概率误差为:\n&#x27;</span>,p)<br><br>    list_p = list_predict[-form:]       <span class="hljs-comment">#获得我们预测的值</span><br>    <span class="hljs-keyword">return</span> list_p<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">grey_models</span>(<span class="hljs-params">x</span>):<br>    av = np.array([np.mean(x[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x))])    <span class="hljs-comment">#求得每一个过程的平均值</span><br>    av_predict = grey_model(av,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)          <span class="hljs-comment">#求得预测过程的平均值</span><br>    sum_predict = <span class="hljs-built_in">len</span>(x[<span class="hljs-number">0</span>]) * av_predict[<span class="hljs-number">0</span>]       <span class="hljs-comment">#计算获得预测过程的总和</span><br>    x_x = x.T   <span class="hljs-comment">#将数组转置</span><br><br>    pre = np.array([grey_model(x_x[i],<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x_x))])       <span class="hljs-comment">#获得每个过程同一时间在预测过程中的预测值</span><br>    pre = pre.ravel()<br><br>    c_predict = np.array(pre/<span class="hljs-built_in">sum</span>(pre))     <span class="hljs-comment">#获得预测过程每一个的预测占比</span><br>    c_predict = c_predict.ravel()<br>    predict = c_predict * sum_predict<br>    <span class="hljs-keyword">return</span> predict<br><br>list_p = grey_model(X,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(list_p)<br><span class="hljs-comment">#predict = grey_models(x)</span><br><span class="hljs-comment">#print(predict)</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>结合熵权法的topsis客观评价代码</title>
    <link href="/2024/09/11/%E7%BB%93%E5%90%88%E7%86%B5%E6%9D%83%E6%B3%95%E7%9A%84topsis%E5%AE%A2%E8%A7%82%E8%AF%84%E4%BB%B7/"/>
    <url>/2024/09/11/%E7%BB%93%E5%90%88%E7%86%B5%E6%9D%83%E6%B3%95%E7%9A%84topsis%E5%AE%A2%E8%A7%82%E8%AF%84%E4%BB%B7/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br><br><span class="hljs-comment">#导入数据</span><br>data = pd.read_excel(<span class="hljs-string">&#x27;收发货表格.xlsx&#x27;</span>,usecols=[<span class="hljs-string">&#x27;发货&#x27;</span>,<span class="hljs-string">&#x27;收货&#x27;</span>,<span class="hljs-string">&#x27;总运输&#x27;</span>,<span class="hljs-string">&#x27;发斜&#x27;</span>,<span class="hljs-string">&#x27;收斜&#x27;</span>,<span class="hljs-string">&#x27;平均相关性&#x27;</span>,<span class="hljs-string">&#x27;发货城市&#x27;</span>,<span class="hljs-string">&#x27;收货城市&#x27;</span>,<span class="hljs-string">&#x27;连接数&#x27;</span>])<br>x_data = np.array(data)<br><br><span class="hljs-comment">#正向化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">positive</span>(<span class="hljs-params">x, <span class="hljs-built_in">type</span>, best_value=<span class="hljs-literal">None</span>, a=<span class="hljs-literal">None</span>, b=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    :param x: 原始数据</span><br><span class="hljs-string">    :param type: 1表示极小型，2表示中间型，3表示区间型,4表示正数话，[[,1],[,2],[,3]]前面是需要正向化的列的序号</span><br><span class="hljs-string">    :param best_value: 中间型的最优值</span><br><span class="hljs-string">    :param a: 区间型的区间下限</span><br><span class="hljs-string">    :param b: 区间型的区间上限</span><br><span class="hljs-string">    :return: 正向化后的数据（列）</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span> == <span class="hljs-literal">None</span>:     <span class="hljs-comment">#先判断是否需要正向化</span><br>        <span class="hljs-keyword">pass</span><br>    <span class="hljs-keyword">else</span>:<br>        x = x.T  <span class="hljs-comment">#转置</span><br>        m = np.array(<span class="hljs-built_in">type</span>).shape[<span class="hljs-number">0</span>]  <span class="hljs-comment">#获得需要正向化的列数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(m)):  <span class="hljs-comment">#迭代需要正向化的列</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>[i][<span class="hljs-number">1</span>] == <span class="hljs-number">1</span>:   <span class="hljs-comment">#成本型数据的转化，采用max-x</span><br>                x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]] = x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]].<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>)-x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]]<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>[i][<span class="hljs-number">1</span>] == <span class="hljs-number">2</span>:  <span class="hljs-comment">#中间型数据的转化</span><br>                max_value = (<span class="hljs-built_in">abs</span>(x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]] - best_value)).<span class="hljs-built_in">max</span>()<br>                x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]] = <span class="hljs-number">1</span> - <span class="hljs-built_in">abs</span>(x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]] - best_value) / max_value<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>[i][<span class="hljs-number">1</span>] == <span class="hljs-number">3</span>:  <span class="hljs-comment">#区间型数据的转化</span><br>                max_value = (np.append(a-x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]].<span class="hljs-built_in">min</span>(),x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]].<span class="hljs-built_in">max</span>()-b)).<span class="hljs-built_in">max</span>()  <span class="hljs-comment">#即M，后面转换时的分母</span><br>                x_rows = x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]].shape[<span class="hljs-number">0</span>]<br>                <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x_rows):<br>                    <span class="hljs-keyword">if</span> x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] &gt; b:  <span class="hljs-comment">#当数据大于区间最大值的转换</span><br>                        x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] = <span class="hljs-number">1</span>-(x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v]-b)/max_value<br>                    <span class="hljs-keyword">elif</span> x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] &lt; a:   <span class="hljs-comment">#当数据小于区间最小值的转换</span><br>                        x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] = <span class="hljs-number">1</span>-(a-x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v])/max_value<br>                    <span class="hljs-keyword">elif</span> a &lt;= x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] &lt;= b:  <span class="hljs-comment">#当数据在区间内则给予最优值1</span><br>                        x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] = <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">else</span>:                      <span class="hljs-comment">#其它情况则给予最劣值0</span><br>                        x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]][v] = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>[i][<span class="hljs-number">1</span>] == <span class="hljs-number">4</span>:   <span class="hljs-comment">#极大型负数的转换</span><br>                x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]] = <span class="hljs-number">1</span>-(x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]].<span class="hljs-built_in">min</span>(<span class="hljs-number">0</span>)) + x[<span class="hljs-built_in">type</span>[i][<span class="hljs-number">0</span>]]<br>        <span class="hljs-keyword">return</span> x.T<br><br><span class="hljs-comment">#标准化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize</span>(<span class="hljs-params">x</span>):<br>    sqrt_sum = (x * x).<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)  <span class="hljs-comment">#每一列元素的平方和</span><br>    sqt_sum_z = np.tile(sqrt_sum, (x.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>)) <span class="hljs-comment">#转换格式,每一列的值均为当列的元素平方和</span><br>    Z = x / np.sqrt(sqt_sum_z) <span class="hljs-comment">#标准化</span><br>    <span class="hljs-keyword">return</span> Z<br><br><span class="hljs-comment">#熵权法计算权值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">importance</span>(<span class="hljs-params">data</span>):<br>    l = <span class="hljs-built_in">len</span>(data[<span class="hljs-number">0</span>])<br>    h = [<span class="hljs-number">0</span>]*l<br>    w = [<span class="hljs-number">0</span>]*l<br>    data = data.T<br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data[<span class="hljs-number">0</span>])):<br>            <span class="hljs-keyword">if</span> data[v][i] == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">pass</span><br>            <span class="hljs-keyword">else</span>:<br>                h[v] += -data[v][i] * np.log(data[v][i])/np.log(<span class="hljs-built_in">len</span>(data[<span class="hljs-number">0</span>]))       <span class="hljs-comment">#计算每个指标的信息熵值</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l):<br>        w[i] = (<span class="hljs-number">1</span>-h[i])/(<span class="hljs-built_in">len</span>(data)-<span class="hljs-built_in">sum</span>(h))           <span class="hljs-comment">#计算每个指标的权重</span><br>    <span class="hljs-keyword">return</span> w<br><span class="hljs-comment">#topsis算法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">topsis</span>(<span class="hljs-params">z,h</span>):<br>    z_max = z.<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>)  <span class="hljs-comment">#每一列的最大值与最小值</span><br>    z_min = z.<span class="hljs-built_in">min</span>(<span class="hljs-number">0</span>)<br><br>    d_m = z - np.tile(z_max, (z.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))  <span class="hljs-comment">#每个方案与最优解及最劣解的差值数列</span><br>    d_i = z - np.tile(z_min, (z.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))<br><br>    d_i_max = np.sqrt(((h * d_m) ** <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>))  <span class="hljs-comment">#每个方案的综合距离</span><br>    d_i_min = np.sqrt(((h * d_i) ** <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>))<br><br>    score = d_i_min/(d_i_max + d_i_min) <span class="hljs-comment">#每个方案的评分</span><br>    std_score = score / score.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)  <span class="hljs-comment">#归一化，方便查看</span><br>    <span class="hljs-keyword">return</span> std_score<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment">#正向化，如果不需要则为空列表即可,要求都为正向化且数据都大于0</span><br>    <span class="hljs-built_in">type</span> = [[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">4</span>]]<br>    a = positive(x_data,<span class="hljs-built_in">type</span>,best_value=<span class="hljs-literal">None</span>, a=<span class="hljs-literal">None</span>, b=<span class="hljs-literal">None</span>)<br>    <span class="hljs-comment">#标准化</span><br>    b = normalize(a)<br>    <span class="hljs-comment">#信息熵计算</span><br>    h = importance(b)<br>    <span class="hljs-comment">#topsis评价</span><br>    s = topsis(b,h)<br>    <span class="hljs-comment">#将评价与方案连接，方便对比与观察</span><br>    clo = np.array([<span class="hljs-string">&#x27;A&#x27;</span>,<span class="hljs-string">&#x27;B&#x27;</span>,<span class="hljs-string">&#x27;C&#x27;</span>,<span class="hljs-string">&#x27;D&#x27;</span>,<span class="hljs-string">&#x27;E&#x27;</span>,<span class="hljs-string">&#x27;G&#x27;</span>,<span class="hljs-string">&#x27;H&#x27;</span>,<span class="hljs-string">&#x27;I&#x27;</span>,<span class="hljs-string">&#x27;J&#x27;</span>,<span class="hljs-string">&#x27;K&#x27;</span>,<span class="hljs-string">&#x27;L&#x27;</span>,<span class="hljs-string">&#x27;M&#x27;</span>,<span class="hljs-string">&#x27;N&#x27;</span>,<span class="hljs-string">&#x27;O&#x27;</span>,<span class="hljs-string">&#x27;P&#x27;</span>,<span class="hljs-string">&#x27;Q&#x27;</span>,<span class="hljs-string">&#x27;R&#x27;</span>,<span class="hljs-string">&#x27;S&#x27;</span>,<span class="hljs-string">&#x27;T&#x27;</span>,<span class="hljs-string">&#x27;U&#x27;</span>,<span class="hljs-string">&#x27;V&#x27;</span>,<span class="hljs-string">&#x27;W&#x27;</span>,<span class="hljs-string">&#x27;X&#x27;</span>,<span class="hljs-string">&#x27;Y&#x27;</span>])<br>    lianjie_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>        lianjie_list.append([clo[i], s[i]])<br>    jieguo = <span class="hljs-built_in">sorted</span>(lianjie_list,reverse=<span class="hljs-literal">True</span>, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])  <span class="hljs-comment">#根据评分值进行排序</span><br>    <span class="hljs-built_in">print</span>(jieguo)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>各种经典排队论模型代码</title>
    <link href="/2024/09/11/%E6%8E%92%E9%98%9F%E8%AE%BA%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81/"/>
    <url>/2024/09/11/%E6%8E%92%E9%98%9F%E8%AE%BA%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mm1_model</span>(<span class="hljs-params">lamb_da, miu, n=<span class="hljs-number">0</span></span>):<br>    rou = lamb_da / miu<br>    W_s = <span class="hljs-number">1</span> / (miu - lamb_da)<br>    W_q = rou / (miu - lamb_da)<br>    L_s = lamb_da * W_s<br>    L_q = lamb_da * W_q<br>    P_n = (<span class="hljs-number">1</span>-rou)*(rou**n)<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;服务强度&#x27;</span>: rou,<br>        <span class="hljs-string">&#x27;平均队长&#x27;</span>: L_s,<br>        <span class="hljs-string">&#x27;平均队列长&#x27;</span>: L_q,<br>        <span class="hljs-string">&#x27;平均逗留时间&#x27;</span>: W_s,<br>        <span class="hljs-string">&#x27;平均等待时间&#x27;</span>: W_q,<br>        <span class="hljs-string">f&#x27;系统稳定有<span class="hljs-subst">&#123;n&#125;</span>个顾客的概率&#x27;</span>:P_n<br>    &#125;<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mm1N_model</span>(<span class="hljs-params">lamb_da, miu, N, n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    损失制:当顾客到达时，队列达到N，顾客随即离去。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    rou = lamb_da / miu<br>    P_N = (<span class="hljs-number">1</span>-rou)*(rou**N)/(<span class="hljs-number">1</span>-rou**(N+<span class="hljs-number">1</span>))<br>    lamb_da_e = lamb_da*(<span class="hljs-number">1</span>-P_N)<br>    rou_e = lamb_da_e / miu<br>    L_s = <span class="hljs-number">1</span>/(<span class="hljs-number">1</span>-rou) - ((N+<span class="hljs-number">1</span>)*rou**(N+<span class="hljs-number">1</span>))/(<span class="hljs-number">1</span>-rou**(N+<span class="hljs-number">1</span>))<br>    L_q = L_s - rou_e<br>    W_s = L_s/lamb_da_e<br>    W_q = L_q/lamb_da_e<br>    P_n = (<span class="hljs-number">1</span>-rou)*(rou**n)/(<span class="hljs-number">1</span>-rou**(N+<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;有效服务强度&#x27;</span>: rou_e,<br>        <span class="hljs-string">&#x27;平均队长&#x27;</span>: L_s,<br>        <span class="hljs-string">&#x27;平均队列长&#x27;</span>: L_q,<br>        <span class="hljs-string">&#x27;平均逗留时间&#x27;</span>: W_s,<br>        <span class="hljs-string">&#x27;平均等待时间&#x27;</span>: W_q,<br>        <span class="hljs-string">f&#x27;系统稳定有<span class="hljs-subst">&#123;n&#125;</span>个顾客的概率&#x27;</span>:P_n<br>    &#125;<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mm1_m_model</span>(<span class="hljs-params">lamb_da, miu, m, n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    这里的lamb_da定义为每个顾客的到达率</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    rou = lamb_da / miu<br>    P_0 = <span class="hljs-number">1</span>/<span class="hljs-built_in">sum</span>(math.factorial(m)/math.factorial(m-i)*rou**i<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,m+<span class="hljs-number">1</span>))<br>    W_s = m/(miu*(<span class="hljs-number">1</span>-P_0)) - <span class="hljs-number">1</span>/lamb_da<br>    W_q = W_s - <span class="hljs-number">1</span>/miu<br>    L_s = m - (miu/lamb_da)*(<span class="hljs-number">1</span>-P_0)<br>    L_q = L_s - (<span class="hljs-number">1</span>-P_0)<br>    <span class="hljs-keyword">if</span> n == <span class="hljs-number">0</span>:<br>        P_n = P_0<br>    <span class="hljs-keyword">else</span>:<br>        P_n = math.factorial(m)/math.factorial(m-n)*rou**n * P_0<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;服务强度&#x27;</span>: rou,<br>        <span class="hljs-string">&#x27;平均队长&#x27;</span>: L_s,<br>        <span class="hljs-string">&#x27;平均队列长&#x27;</span>: L_q,<br>        <span class="hljs-string">&#x27;平均逗留时间&#x27;</span>: W_s,<br>        <span class="hljs-string">&#x27;平均等待时间&#x27;</span>: W_q,<br>        <span class="hljs-string">f&#x27;系统稳定有<span class="hljs-subst">&#123;n&#125;</span>个顾客的概率&#x27;</span>:P_n<br>    &#125;<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mmc_model</span>(<span class="hljs-params">lamb_da, miu, c, n=<span class="hljs-number">0</span></span>):<br>    rou = lamb_da / (miu*c)<br>    P_0 = <span class="hljs-number">1</span>/(<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>/math.factorial(i)*(rou*c)**i<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,c-<span class="hljs-number">1</span>))<br>             +<span class="hljs-number">1</span>/(math.factorial(c)*(<span class="hljs-number">1</span>-rou))*(rou*c)**c)<br>    L_q = P_0*(rou*c)**c*rou/(math.factorial(c)*(<span class="hljs-number">1</span>+rou)**<span class="hljs-number">2</span>)<br>    L_s = L_q + rou*c<br>    W_s = L_s / lamb_da<br>    W_q = L_q / lamb_da<br>    <span class="hljs-keyword">if</span> n == <span class="hljs-number">0</span>:<br>        P_n = P_0<br>    <span class="hljs-keyword">elif</span> n&lt;=c:<br>        P_n = P_0*(rou*c)**n / math.factorial(n)<br>    <span class="hljs-keyword">else</span>:<br>        P_n = P_0*(rou*c)**n / (math.factorial(c)*c**(n-c))<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;服务强度&#x27;</span>: rou,<br>        <span class="hljs-string">&#x27;平均队长&#x27;</span>: L_s,<br>        <span class="hljs-string">&#x27;平均队列长&#x27;</span>: L_q,<br>        <span class="hljs-string">&#x27;平均逗留时间&#x27;</span>: W_s,<br>        <span class="hljs-string">&#x27;平均等待时间&#x27;</span>: W_q,<br>        <span class="hljs-string">f&#x27;系统稳定有<span class="hljs-subst">&#123;n&#125;</span>个顾客的概率&#x27;</span>:P_n<br>    &#125;<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mmcN_model</span>(<span class="hljs-params">lamb_da, miu, c, N, n=<span class="hljs-number">0</span></span>):<br>    rou = lamb_da / (miu*c)<br>    <span class="hljs-keyword">if</span> rou == <span class="hljs-number">1</span>:<br>        P_0 = <span class="hljs-built_in">sum</span>(c**i/math.factorial(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,c))\<br>             +(N-c+<span class="hljs-number">1</span>)*c**c/math.factorial(c)<br>    <span class="hljs-keyword">else</span>:<br>        P_0 =<span class="hljs-number">1</span>/(<span class="hljs-built_in">sum</span>(c*rou**i/math.factorial(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,c))\<br>                +(rou*(rou**c-rou**N)/(<span class="hljs-number">1</span>-rou))*c**c/math.factorial(c))<br>    <span class="hljs-keyword">if</span> n&lt;=c:<br>        P_n = P_0*(rou*c)**n / math.factorial(n)<br>    <span class="hljs-keyword">elif</span> n&gt;c <span class="hljs-keyword">and</span> n&lt;=N:<br>        P_n = P_0 * c**c * rou**n / math.factorial(c)<br>    L_q = <span class="hljs-number">0</span><br>    P_N = P_0 * c**c * rou**N / math.factorial(c)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,N-c+<span class="hljs-number">1</span>):<br>        L_q += i*P_N<br>    L_s = L_q + rou*c*(<span class="hljs-number">1</span>-P_N)<br>    W_q = L_q / (lamb_da*(<span class="hljs-number">1</span>-P_N))<br>    W_s = W_q + <span class="hljs-number">1</span>/miu<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;服务强度&#x27;</span>: rou,<br>        <span class="hljs-string">&#x27;平均队长&#x27;</span>: L_s,<br>        <span class="hljs-string">&#x27;平均队列长&#x27;</span>: L_q,<br>        <span class="hljs-string">&#x27;平均逗留时间&#x27;</span>: W_s,<br>        <span class="hljs-string">&#x27;平均等待时间&#x27;</span>: W_q,<br>        <span class="hljs-string">f&#x27;系统稳定有<span class="hljs-subst">&#123;n&#125;</span>个顾客的概率&#x27;</span>: P_n<br>    &#125;<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mmc_m_model</span>(<span class="hljs-params">lamb_da, miu, c, m, n=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    n应该要大于c，不然概率可能大于1.</span><br><span class="hljs-string">    因为有时每个服务台都会有人。</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    rou = m*lamb_da / (miu*c)<br>    P_0 =<span class="hljs-number">1</span>/((<span class="hljs-built_in">sum</span>((c*rou/m)**i/(math.factorial(i)*math.factorial(m-i)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,c+<span class="hljs-number">1</span>))\<br>            +<span class="hljs-built_in">sum</span>(c**c*(rou/m)**i/(math.factorial(m-i)*math.factorial(c)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,c+<span class="hljs-number">1</span>)))\<br>            *math.factorial(m))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">P</span>(<span class="hljs-params">P_0, lamb_da, miu, c, m, n=<span class="hljs-number">0</span></span>):<br>        <span class="hljs-keyword">if</span> n&lt;=c:<br>            P_n = (P_0*((lamb_da/miu)**n)*math.factorial(m) /<br>                   (math.factorial(n)*math.factorial(m-n)))<br>        <span class="hljs-keyword">elif</span> n&gt;c <span class="hljs-keyword">and</span> n&lt;=m:<br>            P_n = (P_0*(lamb_da/miu)**n*math.factorial(m) /<br>                   (math.factorial(c)*math.factorial(m-n)*c**(n-c)))<br>        <span class="hljs-keyword">return</span> P_n<br>    P_n = P(P_0, lamb_da, miu, c, m, n)<br>    L_q = <span class="hljs-built_in">sum</span>(i*P(P_0, lamb_da, miu, c, m, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,m-c+<span class="hljs-number">1</span>))<br>    L_s = <span class="hljs-built_in">sum</span>(i*P(P_0, lamb_da, miu, c, m, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,m+<span class="hljs-number">1</span>))<br>    lamb_da_e = lamb_da * (m-L_s)<br>    W_s = L_s/lamb_da_e<br>    W_q = L_q/lamb_da_e<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;服务强度&#x27;</span>: rou,<br>        <span class="hljs-string">&#x27;平均队长&#x27;</span>: L_s,<br>        <span class="hljs-string">&#x27;平均队列长&#x27;</span>: L_q,<br>        <span class="hljs-string">&#x27;平均逗留时间&#x27;</span>: W_s,<br>        <span class="hljs-string">&#x27;平均等待时间&#x27;</span>: W_q,<br>        <span class="hljs-string">f&#x27;系统稳定有<span class="hljs-subst">&#123;n&#125;</span>个顾客的概率&#x27;</span>: P_n<br>    &#125;<br><span class="hljs-comment"># 输入模拟参数</span><br>lamb_da = <span class="hljs-number">0.8</span>  <span class="hljs-comment"># 平均到达速率</span><br>miu = <span class="hljs-number">0.6</span>  <span class="hljs-comment"># 平均服务速率</span><br>c = <span class="hljs-number">10</span>  <span class="hljs-comment"># 服务台数量 ,需要小于m</span><br>N = <span class="hljs-number">5</span>  <span class="hljs-comment"># 队列（排队）容量</span><br>m = <span class="hljs-number">10</span>  <span class="hljs-comment"># 顾客源总数</span><br><br>results = mmc_m_model(lamb_da, miu, c, m, <span class="hljs-number">5</span>)<br><span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> results.items():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;key&#125;</span>: <span class="hljs-subst">&#123;value:<span class="hljs-number">.6</span>f&#125;</span>&quot;</span>)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>交通运输工程学课程设计代码</title>
    <link href="/2024/09/11/%E4%BA%A4%E9%80%9A%E8%BF%90%E8%BE%93%E5%B7%A5%E7%A8%8B%E5%AD%A6%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E4%BB%A3%E7%A0%81/"/>
    <url>/2024/09/11/%E4%BA%A4%E9%80%9A%E8%BF%90%E8%BE%93%E5%B7%A5%E7%A8%8B%E5%AD%A6%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">haversine_distance</span>(<span class="hljs-params">coord1, coord2</span>):<br>    <span class="hljs-comment"># 将经纬度从度数转换为弧度</span><br>    lat1, lon1 = np.radians(coord1[<span class="hljs-number">1</span>]), np.radians(coord1[<span class="hljs-number">0</span>])<br>    lat2, lon2 = np.radians(coord2[<span class="hljs-number">1</span>]), np.radians(coord2[<span class="hljs-number">0</span>])<br>    <span class="hljs-comment"># Haversine 公式</span><br>    dlon = lon2 - lon1<br>    dlat = lat2 - lat1<br>    a = np.sin(dlat / <span class="hljs-number">2</span>) ** <span class="hljs-number">2</span> + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / <span class="hljs-number">2</span>) ** <span class="hljs-number">2</span><br>    c = <span class="hljs-number">2</span> * np.arctan2(np.sqrt(a), np.sqrt(<span class="hljs-number">1</span> - a))<br>    <span class="hljs-comment"># 地球半径（单位：公里）</span><br>    radius = <span class="hljs-number">6371.0</span><br>    <span class="hljs-comment"># 计算距离</span><br>    distance = radius * c<br>    <span class="hljs-keyword">return</span> distance<br>coordinates = np.array([<br>    [<span class="hljs-number">104.107895</span>, <span class="hljs-number">30.457623</span>],<br>    [<span class="hljs-number">104.642054</span>, <span class="hljs-number">30.702534</span>],<br>    [<span class="hljs-number">104.055628</span>, <span class="hljs-number">30.527435</span>],<br>    [<span class="hljs-number">103.721549</span>, <span class="hljs-number">30.931824</span>],<br>    [<span class="hljs-number">104.112324</span>, <span class="hljs-number">30.668907</span>],<br>    [<span class="hljs-number">104.077094</span>, <span class="hljs-number">30.674277</span>],<br>    [<span class="hljs-number">104.214562</span>, <span class="hljs-number">30.531782</span>],<br>    [<span class="hljs-number">103.943217</span>, <span class="hljs-number">30.782159</span>],<br>    [<span class="hljs-number">104.145552</span>, <span class="hljs-number">30.605267</span>],<br>    [<span class="hljs-number">104.028378</span>, <span class="hljs-number">30.676363</span>],<br>    [<span class="hljs-number">103.974325</span>, <span class="hljs-number">30.735671</span>],<br>    [<span class="hljs-number">104.076092</span>, <span class="hljs-number">30.624577</span>],<br>    [<span class="hljs-number">104.060045</span>, <span class="hljs-number">30.633286</span>],<br>    [<span class="hljs-number">104.042753</span>, <span class="hljs-number">30.637203</span>],<br>    [<span class="hljs-number">104.034653</span>, <span class="hljs-number">30.525472</span>],<br>    [<span class="hljs-number">103.922376</span>, <span class="hljs-number">30.570071</span>],<br>    [<span class="hljs-number">103.693276</span>, <span class="hljs-number">30.632171</span>],<br>    [<span class="hljs-number">104.101776</span>, <span class="hljs-number">30.632171</span>],<br>    [<span class="hljs-number">104.234756</span>, <span class="hljs-number">30.568442</span>],<br>    [<span class="hljs-number">104.074576</span>, <span class="hljs-number">30.624871</span>],<br>    [<span class="hljs-number">104.204776</span>, <span class="hljs-number">30.518071</span>]<br>])<br><span class="hljs-comment"># 初始化距离矩阵</span><br>num_points = <span class="hljs-built_in">len</span>(coordinates)<br>dist_matrix = np.zeros((num_points, num_points))<br><span class="hljs-comment"># 计算距离矩阵</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_points):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_points):<br>        dist_matrix[i, j] = haversine_distance(coordinates[i], coordinates[j])<br>values = [<span class="hljs-number">0</span>, <span class="hljs-number">1.151</span>, <span class="hljs-number">1.273</span>, <span class="hljs-number">1.512</span>, <span class="hljs-number">2.311</span>, <span class="hljs-number">0.827</span>, <span class="hljs-number">4.185</span>, <span class="hljs-number">2.342</span>, <span class="hljs-number">1.124</span>, <span class="hljs-number">1.367</span>, <span class="hljs-number">4.227</span>,<br>          <span class="hljs-number">0.622</span>, <span class="hljs-number">0.937</span>, <span class="hljs-number">1.722</span>, <span class="hljs-number">3.075</span>, <span class="hljs-number">1.252</span>, <span class="hljs-number">5.221</span>, <span class="hljs-number">2.879</span>, <span class="hljs-number">2.357</span>, <span class="hljs-number">4.212</span>, <span class="hljs-number">3.661</span>]<br><span class="hljs-comment"># 46t</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">xuhao</span>(<span class="hljs-params">x,v</span>):  <span class="hljs-comment"># 获取x中第v个1的纵坐标</span><br>    vv = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x)):<br>        <span class="hljs-keyword">if</span> x[i] == <span class="hljs-number">1</span>:<br>            vv += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> vv == v:<br>                <span class="hljs-keyword">return</span> i<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dfs</span>(<span class="hljs-params">graph, start, end, k, matrix</span>):<br>    xx = []<br>    dd = [<span class="hljs-number">0</span>]*k<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>        xxx = [start]<br>        down = xuhao(graph[start],i+<span class="hljs-number">1</span>)<br>        dd[i] += <span class="hljs-built_in">float</span>(matrix[start,down])<br>        start = down<br>        xxx.append(start)<br>        <span class="hljs-keyword">while</span> start != end:<br>            down = xuhao(graph[start],<span class="hljs-number">1</span>)<br>            dd[i] += matrix[start][down]<br>            xxx.append(down)<br>            start = down<br>        xx.append(xxx)<br>    vv = [<span class="hljs-number">0</span>]*k<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(xx)):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(xx[i])-<span class="hljs-number">1</span>):<br>            vv[i] += values[xx[i][j]]<br>    <span class="hljs-keyword">return</span> xx,dd,vv<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">xijdef</span>(<span class="hljs-params">x</span>):<br>    xij = np.zeros((<span class="hljs-number">21</span>,<span class="hljs-number">21</span>), dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-comment"># 将主对角线上面的一条线设为1</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">21</span>-x):<br>        xij[i, i+x] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,x+<span class="hljs-number">1</span>):<br>        xij[-i,<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,x+<span class="hljs-number">1</span>):<br>        xij[<span class="hljs-number">0</span>,i] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> xij<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fun</span>(<span class="hljs-params">X</span>):  <span class="hljs-comment"># 目标函数和约束条件</span><br>    x = X.flatten() <span class="hljs-comment">#将X变为一维数组</span><br>    xij = xijdef(<span class="hljs-built_in">int</span>(x[-<span class="hljs-number">1</span>]))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">15</span>):<br>        xij[:,<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i])] , xij[:,<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>])] = xij[:,<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>])].copy() , xij[:,<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i])].copy()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">15</span>,<span class="hljs-number">30</span>):<br>        xij[<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i]),:] , xij[<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>]),:] = xij[<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>]),:].copy() , xij[<span class="hljs-built_in">int</span>(x[<span class="hljs-number">2</span>*i]),:].copy()<br>    result,dd,vv = dfs(xij,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-built_in">int</span>(x[-<span class="hljs-number">1</span>]),dist_matrix)  <span class="hljs-comment"># 获得路径与路程</span><br><br>    st = <span class="hljs-number">0</span><br>    lis = [element <span class="hljs-keyword">for</span> sublist <span class="hljs-keyword">in</span> result <span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> sublist <span class="hljs-keyword">if</span> element != <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(lis) != <span class="hljs-number">20</span>:<br>        st += <span class="hljs-number">1000000000000</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">max</span>(dd) &gt; <span class="hljs-number">150</span>: <span class="hljs-comment"># 最大距离限制</span><br>        st += <span class="hljs-number">1000000000</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">max</span>(vv) &gt; <span class="hljs-number">10</span>: <span class="hljs-comment"># 最大容量限制</span><br>        st += <span class="hljs-number">1000000000</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">21</span>): <span class="hljs-comment"># 每个点都要走</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span>(xij[:,i]) != <span class="hljs-number">1</span>:<br>            st += <span class="hljs-number">1000000000</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span>(xij[i,:]) != <span class="hljs-number">1</span>:<br>            st += <span class="hljs-number">1000000000</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">21</span>):  <span class="hljs-comment"># 避免车辆来回跑</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> xij[i,j] == xij[j,i] <span class="hljs-keyword">and</span> xij[i,j] == <span class="hljs-number">1</span>:<br>                st += <span class="hljs-number">1000000000</span><br><br>    fx1 = x[-<span class="hljs-number">1</span>]*<span class="hljs-number">150</span>  <span class="hljs-comment"># 车辆固定成本</span><br>    fx2 = <span class="hljs-number">0</span><br>    fx3 = <span class="hljs-number">0</span><br>    e = np.e<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result)):<br>        ddd = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(result[i])):<br>            ddd += dist_matrix[result[i][j-<span class="hljs-number">1</span>],result[i][j]]<br>            <span class="hljs-keyword">if</span> j == <span class="hljs-built_in">len</span>(result[i])-<span class="hljs-number">1</span>:<br>                fx3 += <span class="hljs-number">6</span>*dist_matrix[result[i][j-<span class="hljs-number">1</span>],result[i][j]]<br>            <span class="hljs-keyword">else</span>:<br>                fx2 += (<span class="hljs-number">1</span>-<span class="hljs-number">1</span>/e**(<span class="hljs-number">0.05</span>*(ddd/<span class="hljs-number">23</span>)))*<span class="hljs-number">500</span>*values[result[i][j]] <span class="hljs-comment"># 货损成本</span><br>                fx3 += ddd*<span class="hljs-number">7</span>*values[result[i][j]] <span class="hljs-comment"># 运输费用</span><br>    <span class="hljs-keyword">return</span> fx1+fx2+fx3+st<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dd2</span>(<span class="hljs-params">best_x, x</span>):  <span class="hljs-comment">#欧氏距离</span><br>    best_x = np.array(best_x)   <span class="hljs-comment">#转化成numpy数组</span><br>    x = np.array(x)          <span class="hljs-comment">#转化成numpy数组</span><br>    c = np.<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">pow</span>(x - best_x, <span class="hljs-number">2</span>), axis=<span class="hljs-number">1</span>)    <span class="hljs-comment">#求方差，在行上的标准差</span><br>    d = <span class="hljs-built_in">pow</span>(c, <span class="hljs-number">0.5</span>)   <span class="hljs-comment">#标准差</span><br>    <span class="hljs-keyword">return</span> d<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">new_min</span>(<span class="hljs-params">arr</span>):  <span class="hljs-comment">#求最小</span><br>    min_data = <span class="hljs-built_in">min</span>(arr)   <span class="hljs-comment">#找到最小值</span><br>    key = np.argmin(arr)  <span class="hljs-comment">#找到最小值的索引</span><br>    <span class="hljs-keyword">return</span> min_data, key<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">type_x</span>(<span class="hljs-params">xx,<span class="hljs-built_in">type</span>,n</span>):  <span class="hljs-comment">#变量范围约束</span><br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>[v] == -<span class="hljs-number">1</span>:<br>            xx[v] = np.maximum(sub[v], xx[v])<br>            xx[v] = np.minimum(up[v], xx[v])<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>[v] == <span class="hljs-number">0</span>:<br>            xx[v] = np.maximum(sub[v], <span class="hljs-built_in">int</span>(xx[v]))<br>            xx[v] = np.minimum(up[v], <span class="hljs-built_in">int</span>(xx[v]))<br>        <span class="hljs-keyword">else</span>:<br>            xx[v] = np.maximum(sub[v], random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>))<br>            xx[v] = np.minimum(up[v], random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> xx<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">woa</span>(<span class="hljs-params">sub,up,<span class="hljs-built_in">type</span>,nums,det</span>):<br>    n = <span class="hljs-built_in">len</span>(sub)  <span class="hljs-comment"># 自变量个数</span><br>    num = nums * n  <span class="hljs-comment"># 种群大小</span><br>    x = np.zeros([num, n])  <span class="hljs-comment">#生成保存解的矩阵</span><br><br>    f = np.zeros(num)   <span class="hljs-comment">#生成保存值的矩阵</span><br>    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):      <span class="hljs-comment">#随机生成初始解</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            rand_data = np.random.uniform(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>            x[s, v] = sub[v] + (up[v] - sub[v]) * rand_data<br>        x[s, :] = type_x(x[s, :],<span class="hljs-built_in">type</span>,n)<br>        f[s] = fun(x[s, :])<br>    best_f, a = new_min(f)  <span class="hljs-comment"># 记录历史最优值</span><br>    best_x = x[a, :]  <span class="hljs-comment"># 记录历史最优解</span><br>    trace = np.array([deepcopy(best_f)]) <span class="hljs-comment">#记录初始最优值,以便后期添加最优值画图</span><br>    <span class="hljs-comment">############################ 改进的鲸鱼算法 ################################</span><br>    xx = np.zeros([num, n])<br>    ff = np.zeros(num)<br>    Mc = (up - sub) * <span class="hljs-number">0.1</span>  <span class="hljs-comment"># 猎物行动最大范围</span><br>    <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(det)):      <span class="hljs-comment">#设置迭代次数，进入迭代过程</span><br>        <span class="hljs-comment"># 猎物躲避,蒙特卡洛模拟，并选择最佳的点作为下一逃跑点 #########！！！创新点</span><br>        d = dd2(best_x, x)  <span class="hljs-comment">#记录当前解与最优解的距离</span><br>        d.sort()  <span class="hljs-comment">#从小到大排序,d[0]恒为0</span><br>        z = np.exp(-d[<span class="hljs-number">1</span>] / np.mean(Mc))  <span class="hljs-comment"># 猎物急躁系数</span><br>        z = <span class="hljs-built_in">max</span>(z, <span class="hljs-number">0.1</span>)     <span class="hljs-comment">#决定最终系数</span><br>        yx = []  <span class="hljs-comment">#初始化存储函数值</span><br>        dx = []  <span class="hljs-comment">#初始化存储解</span><br>        random_rand = random.random() <span class="hljs-comment">#0-1的随机数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">30</span>):    <span class="hljs-comment">#蒙特卡洛模拟的次数</span><br>            m = [random.choice([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)] <span class="hljs-comment">#随机的-1和1</span><br>            asd = best_x + Mc * z * ((det-ii )/det) * random_rand * m   <span class="hljs-comment">#最优解更新公式</span><br>            xd = type_x(asd,<span class="hljs-built_in">type</span>,n)  <span class="hljs-comment">#对自变量进行限制</span><br>            <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span>:<br>                dx = deepcopy(xd)<br>            <span class="hljs-keyword">else</span>:<br>                dx = np.vstack((dx,xd))   <span class="hljs-comment">#存储每一次的解</span><br>            yx=np.hstack((yx,fun(xd)))    <span class="hljs-comment">#存储每一次的值</span><br>        best_t, a = new_min(yx)  <span class="hljs-comment"># 选择最佳逃跑点</span><br>        best_c = dx[a, :]   <span class="hljs-comment">#最佳逃跑点</span><br>        <span class="hljs-keyword">if</span> best_t &lt; best_f:   <span class="hljs-comment">#与鲸鱼算法得到的最优值对比</span><br>            best_f = best_t   <span class="hljs-comment">#更新最优值</span><br>            best_x = best_c   <span class="hljs-comment">#更新最优解</span><br>        <span class="hljs-comment">############################# 鲸鱼追捕 #################################</span><br>        w = (ii / det)**<span class="hljs-number">3</span>   <span class="hljs-comment">#自适应惯性权重!!!创新点</span><br>        a = (<span class="hljs-number">2</span> - <span class="hljs-number">2</span>*ii/det)*(<span class="hljs-number">1</span>- w)  <span class="hljs-comment">#a随迭代次数从2非线性下降至0！！！创新点</span><br>        pp=<span class="hljs-number">0.7</span> <span class="hljs-keyword">if</span> ii &lt;= <span class="hljs-number">0.5</span>*det <span class="hljs-keyword">else</span> <span class="hljs-number">0.4</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):<br>            r1 = np.random.rand()  <span class="hljs-comment"># r1为[0,1]之间的随机数</span><br>            r2 = np.random.rand()  <span class="hljs-comment"># r2为[0,1]之间的随机数</span><br>            A = <span class="hljs-number">2</span> * a * r1 - a<br>            C = <span class="hljs-number">2</span> * r2<br>            b = <span class="hljs-number">1</span>     <span class="hljs-comment">#螺旋形状系数</span><br>            l = np.random.uniform(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)  <span class="hljs-comment">#参数l</span><br>            p = np.random.rand()<br>            <span class="hljs-keyword">if</span> p &lt; pp:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(A) &gt;= <span class="hljs-number">1</span>:<br>                    rand_leader = np.random.randint(<span class="hljs-number">0</span>, num)<br>                    X_rand = x[rand_leader, :]<br>                    D_X_rand = <span class="hljs-built_in">abs</span>(C * X_rand - x[i, :])<br>                    xx[i, :] = w*X_rand - A * D_X_rand<br>                    xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>                <span class="hljs-keyword">elif</span> <span class="hljs-built_in">abs</span>(A) &lt; <span class="hljs-number">1</span>:<br>                    D_Leader = <span class="hljs-built_in">abs</span>(C * best_x - x[i, :])<br>                    xx[i, :] = w*best_x - A * D_Leader<br>                    xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>            <span class="hljs-keyword">elif</span> p &gt;= pp:<br>                D = <span class="hljs-built_in">abs</span>(best_x - x[i, :])<br>                xx[i, :] = D*np.exp(b*l)*np.cos(<span class="hljs-number">2</span>*np.pi*l) + (<span class="hljs-number">1</span>-w)*best_x   <span class="hljs-comment">#完整的气泡网捕食公式</span><br>                xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>            ff[i] = fun(xx[i, :])<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(np.unique(ff[:i]))/(i+<span class="hljs-number">1</span>) &lt;= <span class="hljs-number">0.1</span>:     <span class="hljs-comment">#limit阈值 + 随机差分变异！！！创新点</span><br>                xx[i,:] = (r1*(best_x-xx[i,:]) +<br>                           r2*(x[np.random.randint(<span class="hljs-number">0</span>,num),:] - xx[i,:]))<br>                xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>                ff[i] = fun(xx[i, :])<br>        <span class="hljs-comment">#将上一代种群与这一代种群以及最优种群结合，选取排名靠前的个体组成新的种群</span><br>        F = np.hstack((np.array([best_f]), f, ff))<br>        F, b = np.sort(F,axis=-<span class="hljs-number">1</span>,kind=<span class="hljs-string">&#x27;stable&#x27;</span>), np.argsort(F)<span class="hljs-comment">#按小到大排序,获得靠前的位置</span><br>        X = np.vstack(([best_x], x, xx))[b, :]<br>        f = F[:num]  <span class="hljs-comment">#新种群的位置</span><br>        x = X[:num, :]  <span class="hljs-comment">#新种群的位置</span><br>        best_f, a = new_min(f)  <span class="hljs-comment"># 记录历史最优值</span><br>        best_x = x[a , :]  <span class="hljs-comment"># 记录历史最优解</span><br>        trace = np.hstack((trace, [best_f]))<br>    <span class="hljs-keyword">return</span> best_x,best_f,trace<br><br><br>s = np.zeros((<span class="hljs-number">1</span>,<span class="hljs-number">60</span>))<br>sub = np.concatenate((s+<span class="hljs-number">1</span>,np.array([[<span class="hljs-number">5</span>]])), axis=<span class="hljs-number">1</span>).ravel()  <span class="hljs-comment"># 自变量下限</span><br>up = np.concatenate((s+<span class="hljs-number">20</span>,np.array([[<span class="hljs-number">7</span>]])), axis=<span class="hljs-number">1</span>).ravel()  <span class="hljs-comment"># 自变量上限</span><br><span class="hljs-built_in">type</span> = np.concatenate((s,np.array([[<span class="hljs-number">0</span>]])), axis=<span class="hljs-number">1</span>).ravel()    <span class="hljs-comment">#-1是有理数，0是整数，1是0-1变量</span><br>best_x,best_f,trace = woa(sub,up,<span class="hljs-built_in">type</span>,<span class="hljs-number">40</span>,<span class="hljs-number">10</span>)     <span class="hljs-comment">#种群大小，迭代次数</span><br><span class="hljs-comment">#种群大小可以为自变量个数，迭代次数看情况</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;最优解为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(best_x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;最优值为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">float</span>(best_f))<br><br>xij = xijdef(<span class="hljs-built_in">int</span>(best_x[-<span class="hljs-number">1</span>]))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">15</span>):<br>    xij[:,<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i])] , xij[:,<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>])] = xij[:,<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>])].copy() , xij[:,<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i])].copy()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">15</span>,<span class="hljs-number">30</span>):<br>    xij[<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i])] , xij[<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>])] = xij[<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i+<span class="hljs-number">1</span>])].copy() , xij[<span class="hljs-built_in">int</span>(best_x[<span class="hljs-number">2</span>*i])].copy()<br>result,dd,vv = dfs(xij,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-built_in">int</span>(best_x[-<span class="hljs-number">1</span>]),dist_matrix)<br><span class="hljs-built_in">print</span>(result)<br><span class="hljs-built_in">print</span>(dd)<br><span class="hljs-built_in">print</span>(vv)<br>fx1 = best_x[-<span class="hljs-number">1</span>]*<span class="hljs-number">150</span>  <span class="hljs-comment"># 车辆固定成本</span><br>fx2 = <span class="hljs-number">0</span><br>fx3 = <span class="hljs-number">0</span><br>e = np.e<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result)):<br>    ddd = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(result[i])):<br>        ddd += dist_matrix[result[i][j-<span class="hljs-number">1</span>],result[i][j]]<br>        <span class="hljs-keyword">if</span> j == <span class="hljs-built_in">len</span>(result[i])-<span class="hljs-number">1</span>:<br>            fx3 += <span class="hljs-number">4</span>*dist_matrix[result[i][j-<span class="hljs-number">1</span>],result[i][j]]<br>        <span class="hljs-keyword">else</span>:<br>            fx2 += (<span class="hljs-number">1</span>-<span class="hljs-number">1</span>/e**(<span class="hljs-number">0.05</span>*(ddd/<span class="hljs-number">23</span>)))*<span class="hljs-number">500</span>*values[result[i][j]] <span class="hljs-comment"># 货损成本</span><br>            fx3 += ddd*<span class="hljs-number">7</span>*values[result[i][j]] <span class="hljs-comment"># 运输费用</span><br><span class="hljs-built_in">print</span>(fx1,fx2,fx3)<br><br>plt.title(<span class="hljs-string">&#x27;鲸鱼算法&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(trace)+<span class="hljs-number">1</span>),trace, color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>启发式算法代码</title>
    <link href="/2024/09/11/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81/"/>
    <url>/2024/09/11/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="一，模拟退火算法"><a href="#一，模拟退火算法" class="headerlink" title="一，模拟退火算法"></a>一，模拟退火算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><code class="hljs python">参考文献：<br>（<span class="hljs-number">1</span>）胡山鹰，陈丙珍，非线性规划问题全局优化的模拟退火法，清华大学学报，<span class="hljs-number">1997</span>,<span class="hljs-number">37</span>(<span class="hljs-number">6</span>):<span class="hljs-number">5</span>-<span class="hljs-number">9</span><br>（<span class="hljs-number">2</span>）李歧强，具有约束指导的模拟退火算法，系统工程，<span class="hljs-number">2001</span>,<span class="hljs-number">19</span>(<span class="hljs-number">3</span>):<span class="hljs-number">49</span>-<span class="hljs-number">55</span><br><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br><span class="hljs-comment"># 定义优化问题的目标函数，最小化问题</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Objective_function</span>(<span class="hljs-params">X</span>):  <span class="hljs-comment"># 目标函数和约束条件    最小化</span><br>    X = X.flatten() <span class="hljs-comment">#将X变为一维数组</span><br>    x1 = X[<span class="hljs-number">0</span>]<br>    x2 = X[<span class="hljs-number">1</span>]<br>    x3 = X[<span class="hljs-number">2</span>]<br>    p1 = (<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-number">6</span> * x1 + <span class="hljs-number">5</span> * x2 - <span class="hljs-number">60</span>)) ** <span class="hljs-number">2</span>     <span class="hljs-comment">#表达的含义是函数表达式小于0</span><br>    p2 = (<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-number">10</span> * x1 + <span class="hljs-number">20</span> * x2 - <span class="hljs-number">150</span>)) ** <span class="hljs-number">2</span><br>    <span class="hljs-comment">#如果是等式约束，可以转化成表达式=0，然后目标函数-10000*表达式</span><br>    fx = <span class="hljs-number">100.0</span> * (x2 - x1) ** <span class="hljs-number">2.0</span> + (<span class="hljs-number">1</span> - x1) ** <span class="hljs-number">2.0</span> * x3<br>    <span class="hljs-keyword">return</span> fx + <span class="hljs-number">10000</span> * (p1 + p2)     <span class="hljs-comment">#施加惩罚项</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main_work</span>():       <span class="hljs-comment">#有理数，整数，0-1变量</span><br>    sa = SA(x_min=[[-<span class="hljs-number">30</span>,-<span class="hljs-number">30</span>],[-<span class="hljs-number">1</span>],[]],x_max=[[<span class="hljs-number">30</span>,<span class="hljs-number">30</span>],[<span class="hljs-number">1</span>],[]],t1=<span class="hljs-number">1000</span>,t0=<span class="hljs-number">1e-4</span>,k=<span class="hljs-number">0.98</span>,Markov=<span class="hljs-number">500</span>,step=<span class="hljs-number">0.1</span>)<br>    fv = sa.optimize()<br>    plt.title(<span class="hljs-string">&#x27;模拟退火&#x27;</span>)<br>    plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(fv)+<span class="hljs-number">1</span>), fv, color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>    plt.show()<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SA</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x_min,x_max,t1,t0,k,Markov,step</span>):<br>        <span class="hljs-comment"># ====== 初始化随机数发生器 ======</span><br>        randseed = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br>        random.seed(randseed)  <span class="hljs-comment"># 随机数发生器设置种子，也可以设为指定整数</span><br><br>        self.n = <span class="hljs-built_in">len</span>(np.array(x_min).ravel())  <span class="hljs-comment"># 自变量数量</span><br>        self.x_min = x_min  <span class="hljs-comment"># 给定搜索空间的下限</span><br>        self.x_max = x_max  <span class="hljs-comment"># 给定搜索空间的上限</span><br>        self.t1 = t1  <span class="hljs-comment"># 初始退火温度</span><br>        self.t0 = t0  <span class="hljs-comment"># 终止退火温度，不能是0，因为只会无限趋近于0</span><br>        self.k = k  <span class="hljs-comment"># 降温参数，T(i)=k*T(i-1)</span><br>        self.Markov = Markov  <span class="hljs-comment"># Markov链长度，内循环运行次数</span><br>        self.step = step  <span class="hljs-comment"># 搜索步长</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">optimize</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># ====== 随机产生优化问题的初始解 ======</span><br>        xInitial = np.zeros((self.n))  <span class="hljs-comment"># 初始化，创建数组</span><br>        l1 = <span class="hljs-built_in">len</span>(self.x_min[<span class="hljs-number">0</span>])<br>        l2 = <span class="hljs-built_in">len</span>(self.x_min[<span class="hljs-number">0</span>]+self.x_min[<span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n):<br>            <span class="hljs-keyword">if</span> v &lt; l1:<br>                xInitial[v] = np.random.uniform(self.x_min[<span class="hljs-number">0</span>][v], self.x_max[<span class="hljs-number">0</span>][v])     <span class="hljs-comment">#有理数</span><br>            <span class="hljs-keyword">elif</span> v &gt;= l1 <span class="hljs-keyword">and</span> v &lt; l2:<br>                xInitial[v] = np.random.randint(self.x_min[<span class="hljs-number">1</span>][v-l1], self.x_max[<span class="hljs-number">1</span>][v-l1]+<span class="hljs-number">1</span>)   <span class="hljs-comment">#整数</span><br>            <span class="hljs-keyword">else</span>:<br>                xInitial[v] = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>)    <span class="hljs-comment">#0-1变量</span><br>        fxInitial = Objective_function(xInitial)<br><br>        <span class="hljs-comment">##################################      模拟退火算法初始化      ##############################</span><br>        xNew = np.zeros((self.n))  <span class="hljs-comment"># 初始化，创建数组</span><br>        xNow = np.zeros((self.n))  <span class="hljs-comment"># 初始化，创建数组</span><br>        xBest = np.zeros((self.n))  <span class="hljs-comment"># 初始化，创建数组</span><br>        xNow[:] = xInitial[:]  <span class="hljs-comment"># 初始化当前解，将初始解置为当前解</span><br>        xBest[:] = xInitial[:]  <span class="hljs-comment"># 初始化最优解，将当前解置为最优解</span><br>        fxNow = fxInitial  <span class="hljs-comment"># 将初始解的目标函数置为当前值</span><br>        fxBest = fxInitial  <span class="hljs-comment"># 将当前解的目标函数置为最优值</span><br>        <span class="hljs-comment">#print(&#x27;初始解:&#123;:.6f&#125;,&#123;:.6f&#125;,\t初始值:&#123;:.6f&#125;&#x27;.format(xInitial[0], xInitial[1], fxInitial))</span><br><br>        recordIter = []  <span class="hljs-comment"># 初始化，外循环次数</span><br>        recordFxNow = []  <span class="hljs-comment"># 初始化，当前解的目标函数值</span><br>        recordFxBest = []  <span class="hljs-comment"># 初始化，最佳解的目标函数值</span><br>        recordPBad = []  <span class="hljs-comment"># 初始化，劣质解的接受概率</span><br>        n_Iter = <span class="hljs-number">0</span>  <span class="hljs-comment"># 外循环迭代次数</span><br>        totalMar = <span class="hljs-number">0</span>  <span class="hljs-comment"># 总计 Markov 链长度</span><br>        totalImprove = <span class="hljs-number">0</span>  <span class="hljs-comment"># fxBest 改善次数</span><br>        nMarkov = self.Markov  <span class="hljs-comment"># 固定长度 Markov链</span><br><br>        <span class="hljs-comment">###################################       开始模拟退火优化     ####################################</span><br>        <span class="hljs-comment"># 外循环</span><br>        fv = []<br>        tNow = self.t1  <span class="hljs-comment"># 当前温度</span><br>        <span class="hljs-keyword">while</span> tNow &gt; self.t0:  <span class="hljs-comment"># 外循环，直到当前温度达到终止温度时结束</span><br>            kBetter = <span class="hljs-number">0</span>  <span class="hljs-comment"># 获得优质解的次数</span><br>            kBadAccept = <span class="hljs-number">0</span>  <span class="hljs-comment"># 接受劣质解的次数</span><br>            kBadRefuse = <span class="hljs-number">0</span>  <span class="hljs-comment"># 拒绝劣质解的次数</span><br><br>            <span class="hljs-comment"># 内循环</span><br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(nMarkov):  <span class="hljs-comment"># 内循环，循环次数为Markov链长度</span><br>                totalMar += <span class="hljs-number">1</span>  <span class="hljs-comment"># 总 Markov链长度计数器</span><br><br>                <span class="hljs-comment"># ---产生新解</span><br>                <span class="hljs-comment"># 产生新解：通过在当前解附近随机扰动而产生新解，新解必须在 [min,max] 范围内</span><br>                <span class="hljs-comment"># 方案 1：只对 n元变量中的一个进行扰动，其它 n-1个变量保持不变</span><br>                xNew[:] = xNow[:]<br>                v = random.randint(<span class="hljs-number">0</span>, self.n - <span class="hljs-number">1</span>)  <span class="hljs-comment"># 产生 [0,n-1]之间的随机数</span><br>                <span class="hljs-keyword">if</span> v &lt; l1:<br>                    xNew[v] = xNow[v] + self.step * (self.x_max[<span class="hljs-number">0</span>][v] - self.x_min[<span class="hljs-number">0</span>][v]) * random.normalvariate(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>                    <span class="hljs-comment"># random.normalvariate(0, 1)：产生服从均值为0、标准差为 1 的正态分布随机实数</span><br>                    xNew[v] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">min</span>(xNew[v], self.x_max[<span class="hljs-number">0</span>][v]), self.x_min[<span class="hljs-number">0</span>][v])  <span class="hljs-comment"># 保证新解在 [min,max] 范围内</span><br>                <span class="hljs-keyword">elif</span> v &gt;= l1 <span class="hljs-keyword">and</span> v &lt; l2:<br>                    xNew[v] = xNow[v] + <span class="hljs-built_in">int</span>(self.step * (self.x_max[<span class="hljs-number">1</span>][v-l1] - self.x_min[<span class="hljs-number">1</span>][v-l1]) * random.normalvariate(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br>                    <span class="hljs-comment"># random.normalvariate(0, 1)：产生服从均值为0、标准差为 1 的正态分布随机实数</span><br>                    xNew[v] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">min</span>(xNew[v], self.x_max[<span class="hljs-number">1</span>][v-l1]), self.x_min[<span class="hljs-number">1</span>][v-l1])  <span class="hljs-comment"># 保证新解在 [min,max] 范围内</span><br>                <span class="hljs-keyword">else</span>:<br>                    xNew[v] = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>)    <span class="hljs-comment">#0-1变量</span><br>                    xNew[v] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">min</span>(xNew[v], self.x_max[<span class="hljs-number">2</span>][v-l2]), self.x_min[<span class="hljs-number">2</span>][v-l2])  <span class="hljs-comment"># 保证新解在 [min,max] 范围内</span><br><br>                <span class="hljs-comment"># 计算目标函数和能量差</span><br>                fxNew = Objective_function(xNew)<br>                deltaE = fxNew - fxNow<br><br>                <span class="hljs-comment"># 按 Metropolis 准则接受新解</span><br>                <span class="hljs-keyword">if</span> fxNew &lt; fxNow:  <span class="hljs-comment"># 更优解：如果新解的目标函数好于当前解，则接受新解</span><br>                    accept = <span class="hljs-literal">True</span><br>                    kBetter += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 容忍解：如果新解的目标函数比当前解差，则以一定概率接受新解</span><br>                    pAccept = np.exp(-np.float64(deltaE) / np.float64(tNow))        <span class="hljs-comment"># 计算容忍解的状态迁移概率</span><br>                    <span class="hljs-keyword">if</span> pAccept &gt; random.random():<br>                        accept = <span class="hljs-literal">True</span>  <span class="hljs-comment"># 接受劣质解</span><br>                        kBadAccept += <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">else</span>:<br>                        accept = <span class="hljs-literal">False</span>  <span class="hljs-comment"># 拒绝劣质解</span><br>                        kBadRefuse += <span class="hljs-number">1</span><br><br>                <span class="hljs-comment"># 保存新解</span><br>                <span class="hljs-keyword">if</span> accept == <span class="hljs-literal">True</span>:  <span class="hljs-comment"># 如果接受新解，则将新解保存为当前解</span><br>                    xNow[:] = xNew[:]<br>                    fxNow = fxNew<br>                    <span class="hljs-keyword">if</span> fxNew &lt; fxBest:  <span class="hljs-comment"># 如果新解的目标函数好于最优解，则将新解保存为最优解</span><br>                        fxBest = fxNew<br>                        xBest[:] = xNew[:]<br>                        totalImprove += <span class="hljs-number">1</span><br>                        self.step = self.step * <span class="hljs-number">0.99</span>  <span class="hljs-comment"># 可变搜索步长，逐步减小搜索范围，提高搜索精度</span><br><br>            <span class="hljs-comment"># 完成当前温度的搜索，保存数据和输出</span><br>            pBadAccept = kBadAccept / (kBadAccept + kBadRefuse)  <span class="hljs-comment"># 劣质解的接受概率</span><br>            recordIter.append(n_Iter)  <span class="hljs-comment"># 当前外循环次数</span><br>            recordFxNow.append(<span class="hljs-built_in">round</span>(fxNow, <span class="hljs-number">4</span>))  <span class="hljs-comment"># 当前解的目标函数值</span><br>            recordFxBest.append(<span class="hljs-built_in">round</span>(fxBest, <span class="hljs-number">4</span>))  <span class="hljs-comment"># 最佳解的目标函数值</span><br>            recordPBad.append(<span class="hljs-built_in">round</span>(pBadAccept, <span class="hljs-number">4</span>))  <span class="hljs-comment"># 最佳解的目标函数值</span><br><br>            <span class="hljs-comment">#if n_Iter % 10 == 0:  # 模运算，商的余数</span><br>                <span class="hljs-comment">#print(&#x27;迭代次数:&#123;&#125;,温度:&#123;:.3f&#125;,最优值:&#123;:.6f&#125;&#x27;.format(n_Iter,tNow,fxBest))</span><br><br>            <span class="hljs-comment"># 缓慢降温至新的温度，降温曲线：T(k)=k*T(k-1)</span><br>            tNow = tNow * self.k<br>            n_Iter = n_Iter + <span class="hljs-number">1</span><br>            fxBest = Objective_function(xBest)<br>            <span class="hljs-comment">###############################    结束模拟退火过程    #######################################</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;--------------模拟退火-------------&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;提升次数:&#123;:d&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(totalImprove))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;求解结果:&quot;</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\tx[&#123;&#125;] = &#123;:.9f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i, xBest[i]))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\tf(x):&#123;:.9f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(Objective_function(xBest)))<br>        <span class="hljs-keyword">return</span> recordFxBest<span class="hljs-comment">#,fxBest,n_Iter, xBest,  fxNow, recordIter, recordFxNow,  recordPBad</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main_work()<br></code></pre></td></tr></table></figure><h1 id="二，粒子群算法"><a href="#二，粒子群算法" class="headerlink" title="二，粒子群算法"></a>二，粒子群算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Objective_function</span>(<span class="hljs-params">X</span>):  <span class="hljs-comment"># 目标函数和约束条件    最小化</span><br>    X = X.flatten() <span class="hljs-comment">#将X变为一维数组</span><br>    x1 = X[<span class="hljs-number">0</span>]<br>    x2 = X[<span class="hljs-number">1</span>]<br>    x3 = X[<span class="hljs-number">2</span>]<br>    p1 = (<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-number">6</span> * x1 + <span class="hljs-number">5</span> * x2 - <span class="hljs-number">60</span>)) ** <span class="hljs-number">2</span>     <span class="hljs-comment">#表达的含义是函数表达式小于0</span><br>    p2 = (<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-number">10</span> * x1 + <span class="hljs-number">20</span> * x2 - <span class="hljs-number">150</span>)) ** <span class="hljs-number">2</span><br>    <span class="hljs-comment">#如果是等式约束，可以转化成表达式=0，然后目标函数-10000*表达式</span><br>    fx = <span class="hljs-number">100.0</span> * (x2 - x1) ** <span class="hljs-number">2.0</span> + (<span class="hljs-number">1</span> - x1) ** <span class="hljs-number">2.0</span> * x3<br>    <span class="hljs-keyword">return</span> fx + <span class="hljs-number">10000</span> * (p1 + p2)     <span class="hljs-comment">#施加惩罚项</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main_work</span>():<br>    <span class="hljs-comment"># ( 粒子个数, 最大迭代次数,x_min,x_max, max_vel, 阈值, C1=2, C2=2, W=1)   范围都是左闭右开</span><br>    pso = PSO(<span class="hljs-number">10</span>, <span class="hljs-number">10000</span>,[[-<span class="hljs-number">30</span>,-<span class="hljs-number">30</span>],[-<span class="hljs-number">1</span>],[]],[[<span class="hljs-number">30</span>,<span class="hljs-number">30</span>],[<span class="hljs-number">1</span>],[]], <span class="hljs-number">30</span>, -<span class="hljs-number">1000</span>, C1=<span class="hljs-number">1</span>, C2=<span class="hljs-number">2</span>, W=<span class="hljs-number">1</span>)<br>    fit_var_list, best_pos = pso.update_ndim()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最优位置:&quot;</span> + <span class="hljs-built_in">str</span>(best_pos))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;最优解为：<span class="hljs-subst">&#123;fit_var_list[-<span class="hljs-number">1</span>]:<span class="hljs-number">.9</span>f&#125;</span>&quot;</span>)<br>    plt.title(<span class="hljs-string">&#x27;粒子群&#x27;</span>)<br>    plt.plot([i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(fit_var_list)+<span class="hljs-number">1</span>)],fit_var_list, color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>    plt.show()<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">particle</span>:<br>    <span class="hljs-comment"># 初始化</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x_min, x_max, max_vel, dim</span>):<br>        pos = np.zeros((dim))<br>        self.l1 = <span class="hljs-built_in">len</span>(x_min[<span class="hljs-number">0</span>])<br>        self.l2 = <span class="hljs-built_in">len</span>(x_min[<span class="hljs-number">0</span>]+x_min[<span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(dim):           <span class="hljs-comment">#生成初始解</span><br>            <span class="hljs-keyword">if</span> v &lt; self.l1:<br>                pos[v] = np.random.uniform(x_min[<span class="hljs-number">0</span>][v], x_max[<span class="hljs-number">0</span>][v])     <span class="hljs-comment">#有理数</span><br>            <span class="hljs-keyword">elif</span> v &gt;= self.l1 <span class="hljs-keyword">and</span> v &lt; self.l2:<br>                pos[v] = np.random.randint(x_min[<span class="hljs-number">1</span>][v-self.l1], x_max[<span class="hljs-number">1</span>][v-self.l1]+<span class="hljs-number">1</span>)   <span class="hljs-comment">#整数</span><br>            <span class="hljs-keyword">else</span>:<br>                pos[v] = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>)    <span class="hljs-comment">#0-1变量</span><br>        self.__pos = np.array(pos)  <span class="hljs-comment"># 粒子的位置</span><br>        self.__vel = np.random.uniform(-max_vel, max_vel, (<span class="hljs-number">1</span>, dim))  <span class="hljs-comment"># 粒子的速度</span><br>        self.__bestPos = np.zeros((<span class="hljs-number">1</span>, dim))  <span class="hljs-comment"># 粒子最好的位置</span><br>        self.__fitnessValue = Objective_function(self.__pos)  <span class="hljs-comment"># 适应度函数值</span><br><span class="hljs-comment">#__开头的为私有属性，只在类内存在</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_pos</span>(<span class="hljs-params">self, value</span>):<br>        pos = np.array(value).ravel()<br>        self.__pos = pos<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_pos</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.__pos<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_best_pos</span>(<span class="hljs-params">self, value</span>):<br>        self.__bestPos = value<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_best_pos</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.__bestPos<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_vel</span>(<span class="hljs-params">self, value</span>):<br>        self.__vel = value<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_vel</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.__vel<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_fitness_value</span>(<span class="hljs-params">self, value</span>):<br>        self.__fitnessValue = value<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_fitness_value</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.__fitnessValue<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PSO</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,  size, iter_num, x_min,x_max, max_vel, tol, best_fitness_value=<span class="hljs-built_in">float</span>(<span class="hljs-params"><span class="hljs-string">&#x27;Inf&#x27;</span></span>), C1=<span class="hljs-number">2</span>, C2=<span class="hljs-number">2</span>, W=<span class="hljs-number">1</span></span>):<br>        self.C1 = C1      <span class="hljs-comment">#加速常数1，控制局部最优解</span><br>        self.C2 = C2      <span class="hljs-comment">#加速常数2，控制全局最优解</span><br>        self.W = W        <span class="hljs-comment">#惯性因子</span><br>        self.dim = <span class="hljs-built_in">len</span>(np.array(x_min).ravel())  <span class="hljs-comment"># 粒子的维度，变量个数</span><br>        self.size = size  <span class="hljs-comment"># 粒子个数</span><br>        self.iter_num = iter_num  <span class="hljs-comment"># 迭代次数</span><br>        self.x_min = x_min    <span class="hljs-comment">#x 的下限</span><br>        self.x_max = x_max     <span class="hljs-comment"># x 的上限</span><br>        self.max_vel = max_vel  <span class="hljs-comment"># 粒子最大速度</span><br>        self.tol = tol  <span class="hljs-comment"># 截止条件</span><br>        self.l1 = <span class="hljs-built_in">len</span>(x_min[<span class="hljs-number">0</span>])<br>        self.l2 = <span class="hljs-built_in">len</span>(x_min[<span class="hljs-number">0</span>]+x_min[<span class="hljs-number">1</span>])<br>        self.best_fitness_value = best_fitness_value<br>        self.best_position = np.zeros((<span class="hljs-number">1</span>, self.dim))  <span class="hljs-comment"># 种群最优位置</span><br>        self.fitness_val_list = []  <span class="hljs-comment"># 每次迭代最优适应值</span><br>        <span class="hljs-comment"># 对种群进行初始化</span><br>        self.Particle_list = [particle(self.x_min,self.x_max, self.max_vel, self.dim) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.size)]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_bestFitnessValue</span>(<span class="hljs-params">self, value</span>):<br>        self.best_fitness_value = value<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_bestFitnessValue</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.best_fitness_value<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_bestPosition</span>(<span class="hljs-params">self, value</span>):<br>        self.best_position = value<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_bestPosition</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.best_position<br>    <span class="hljs-comment"># 更新速度</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_vel</span>(<span class="hljs-params">self, part</span>):<br>        vel_value = self.W * part.get_vel() + self.C1 * np.random.rand() * (part.get_best_pos() - part.get_pos()) \<br>                    + self.C2 * np.random.rand() * (self.get_bestPosition() - part.get_pos())<br>        vel_value[vel_value &gt; self.max_vel] = self.max_vel<br>        vel_value[vel_value &lt; -self.max_vel] = -self.max_vel<br>        part.set_vel(vel_value)<br>    <span class="hljs-comment"># 更新位置</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_pos</span>(<span class="hljs-params">self, part</span>):<br>        pos_value = part.get_pos() + part.get_vel()<br>        pos_value = np.array(pos_value).ravel()<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(pos_value)):           <span class="hljs-comment">#生成初始解</span><br>            <span class="hljs-keyword">if</span> v &lt; self.l1:<br>                pos_value[v] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">min</span>(pos_value[v], self.x_max[<span class="hljs-number">0</span>][v]), self.x_min[<span class="hljs-number">0</span>][v])  <span class="hljs-comment"># 保证新解在 [min,max] 范围内</span><br>            <span class="hljs-keyword">elif</span> v &gt;= self.l1 <span class="hljs-keyword">and</span> v &lt; self.l2:<br>                pos_value[v] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">min</span>(pos_value[v], self.x_max[<span class="hljs-number">1</span>][v-self.l1]), self.x_min[<span class="hljs-number">1</span>][v-self.l1])  <span class="hljs-comment"># 保证新解在 [min,max] 范围内</span><br>            <span class="hljs-keyword">else</span>:<br>                pos_value[v] = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">min</span>(pos_value[v], self.x_max[<span class="hljs-number">1</span>][v-self.l2]), self.x_min[<span class="hljs-number">1</span>][v-self.l2])  <span class="hljs-comment"># 保证新解在 [min,max] 范围内</span><br>        part.set_pos(pos_value)<br>        value = Objective_function(part.get_pos())<br>        <span class="hljs-keyword">if</span> value &lt; part.get_fitness_value():<br>            part.set_fitness_value(value)<br>            part.set_best_pos(pos_value)<br>        <span class="hljs-keyword">if</span> value &lt; self.get_bestFitnessValue():<br>            self.set_bestFitnessValue(value)<br>            self.set_bestPosition(pos_value)<br>    <span class="hljs-comment">#更新粒子</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_ndim</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.iter_num):<br>            <span class="hljs-keyword">for</span> part <span class="hljs-keyword">in</span> self.Particle_list:<br>                self.update_vel(part)  <span class="hljs-comment"># 更新速度</span><br>                self.update_pos(part)  <span class="hljs-comment"># 更新位置</span><br>            self.fitness_val_list.append(self.get_bestFitnessValue())  <span class="hljs-comment"># 每次迭代完把当前的最优适应度存到列表</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;第&#123;&#125;次最佳适应值为&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i, self.get_bestFitnessValue()))<span class="hljs-comment">#################################################</span><br>            <span class="hljs-keyword">if</span> self.get_bestFitnessValue() &lt; self.tol:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;--------------粒子群--------------&#x27;</span>)<br>        <span class="hljs-keyword">return</span> self.fitness_val_list, self.get_bestPosition()<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main_work()<br></code></pre></td></tr></table></figure><h1 id="三，改进的鲸鱼算法"><a href="#三，改进的鲸鱼算法" class="headerlink" title="三，改进的鲸鱼算法"></a>三，改进的鲸鱼算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br>np.set_printoptions(threshold=np.inf) <span class="hljs-comment"># threshold 指定超过多少使用省略号，np.inf代表无限大</span><br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment">#不以科学计数法输出</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#显示负号</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = [<span class="hljs-string">&#x27;sans-serif&#x27;</span>]<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 散点图标签可以显示中文</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fun</span>(<span class="hljs-params">X</span>):  <span class="hljs-comment"># 目标函数和约束条件</span><br>    x = X.flatten() <span class="hljs-comment">#将X变为一维数组</span><br>    fx = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x)-<span class="hljs-number">1</span>):<br>        a = x[i]**<span class="hljs-number">2</span> - <span class="hljs-number">10</span>*np.cos(<span class="hljs-number">2</span>*np.pi*x[i]) + <span class="hljs-number">10</span><br>        fx += a<br>    fx += -<span class="hljs-number">7</span>*x[-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> fx      <span class="hljs-comment">#施加惩罚项</span><br><br>s = np.zeros((<span class="hljs-number">1</span>,<span class="hljs-number">30</span>))<br>sub = np.array(s-<span class="hljs-number">10</span>).ravel()  <span class="hljs-comment"># 自变量下限</span><br>up = np.array(s+<span class="hljs-number">10</span>).ravel()  <span class="hljs-comment"># 自变量上限</span><br><span class="hljs-built_in">type</span> = np.array(s).ravel()    <span class="hljs-comment">#-1是有理数，0是整数，1是0-1变量</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dd2</span>(<span class="hljs-params">best_x, x</span>):  <span class="hljs-comment">#欧氏距离</span><br>    best_x = np.array(best_x)   <span class="hljs-comment">#转化成numpy数组</span><br>    x = np.array(x)          <span class="hljs-comment">#转化成numpy数组</span><br>    c = np.<span class="hljs-built_in">sum</span>(<span class="hljs-built_in">pow</span>(x - best_x, <span class="hljs-number">2</span>), axis=<span class="hljs-number">1</span>)    <span class="hljs-comment">#求方差，在行上的标准差</span><br>    d = <span class="hljs-built_in">pow</span>(c, <span class="hljs-number">0.5</span>)   <span class="hljs-comment">#标准差</span><br>    <span class="hljs-keyword">return</span> d<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">new_min</span>(<span class="hljs-params">arr</span>):  <span class="hljs-comment">#求最小</span><br>    min_data = <span class="hljs-built_in">min</span>(arr)   <span class="hljs-comment">#找到最小值</span><br>    key = np.argmin(arr)  <span class="hljs-comment">#找到最小值的索引</span><br>    <span class="hljs-keyword">return</span> min_data, key<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">type_x</span>(<span class="hljs-params">xx,<span class="hljs-built_in">type</span>,n</span>):  <span class="hljs-comment">#变量范围约束</span><br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>[v] == -<span class="hljs-number">1</span>:<br>            xx[v] = np.maximum(sub[v], xx[v])<br>            xx[v] = np.minimum(up[v], xx[v])<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>[v] == <span class="hljs-number">0</span>:<br>            xx[v] = np.maximum(sub[v], <span class="hljs-built_in">int</span>(xx[v]))<br>            xx[v] = np.minimum(up[v], <span class="hljs-built_in">int</span>(xx[v]))<br>        <span class="hljs-keyword">else</span>:<br>            xx[v] = np.maximum(sub[v], random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>))<br>            xx[v] = np.minimum(up[v], random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> xx<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">woa</span>(<span class="hljs-params">sub,up,<span class="hljs-built_in">type</span>,nums,det</span>):<br>    n = <span class="hljs-built_in">len</span>(sub)  <span class="hljs-comment"># 自变量个数</span><br>    num = nums * n  <span class="hljs-comment"># 种群大小</span><br>    x = np.zeros([num, n])  <span class="hljs-comment">#生成保存解的矩阵</span><br>    f = np.zeros(num)   <span class="hljs-comment">#生成保存值的矩阵</span><br>    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):      <span class="hljs-comment">#随机生成初始解</span><br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            rand_data = np.random.uniform(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>            x[s, v] = sub[v] + (up[v] - sub[v]) * rand_data<br>        x[s, :] = type_x(x[s, :],<span class="hljs-built_in">type</span>,n)<br>        f[s] = fun(x[s, :])<br>    best_f, a = new_min(f)  <span class="hljs-comment"># 记录历史最优值</span><br>    best_x = x[a, :]  <span class="hljs-comment"># 记录历史最优解</span><br>    trace = np.array([deepcopy(best_f)]) <span class="hljs-comment">#记录初始最优值,以便后期添加最优值画图</span><br>    <span class="hljs-comment">############################ 改进的鲸鱼算法 ################################</span><br>    xx = np.zeros([num, n])<br>    ff = np.zeros(num)<br>    Mc = (up - sub) * <span class="hljs-number">0.1</span>  <span class="hljs-comment"># 猎物行动最大范围</span><br>    <span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(det)):      <span class="hljs-comment">#设置迭代次数，进入迭代过程</span><br>        <span class="hljs-comment"># 猎物躲避,蒙特卡洛模拟，并选择最佳的点作为下一逃跑点 #########！！！创新点</span><br>        d = dd2(best_x, x)  <span class="hljs-comment">#记录当前解与最优解的距离</span><br>        d.sort()  <span class="hljs-comment">#从小到大排序,d[0]恒为0</span><br>        z = np.exp(-d[<span class="hljs-number">1</span>] / np.mean(Mc))  <span class="hljs-comment"># 猎物急躁系数</span><br>        z = <span class="hljs-built_in">max</span>(z, <span class="hljs-number">0.1</span>)     <span class="hljs-comment">#决定最终系数</span><br>        yx = []  <span class="hljs-comment">#初始化存储函数值</span><br>        dx = []  <span class="hljs-comment">#初始化存储解</span><br>        random_rand = random.random(n) <span class="hljs-comment">#0-1的随机数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">50</span>):    <span class="hljs-comment">#蒙特卡洛模拟的次数</span><br>            m = [random.choice([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)] <span class="hljs-comment">#随机的-1和1</span><br>            asd = best_x + Mc * z * ((det-ii )/det) * random_rand * m   <span class="hljs-comment">#最优解更新公式</span><br>            xd = type_x(asd,<span class="hljs-built_in">type</span>,n)  <span class="hljs-comment">#对自变量进行限制</span><br>            <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">1</span>:<br>                dx = deepcopy(xd)<br>            <span class="hljs-keyword">else</span>:<br>                dx = np.vstack((dx,xd))   <span class="hljs-comment">#存储每一次的解</span><br>            yx=np.hstack((yx,fun(xd)))    <span class="hljs-comment">#存储每一次的值</span><br>        best_t, a = new_min(yx)  <span class="hljs-comment"># 选择最佳逃跑点</span><br>        best_c = dx[a, :]   <span class="hljs-comment">#最佳逃跑点</span><br>        <span class="hljs-keyword">if</span> best_t &lt; best_f:   <span class="hljs-comment">#与鲸鱼算法得到的最优值对比</span><br>            best_f = best_t   <span class="hljs-comment">#更新最优值</span><br>            best_x = best_c   <span class="hljs-comment">#更新最优解</span><br>        <span class="hljs-comment">############################# 鲸鱼追捕 #################################</span><br>        w = (ii / det)**<span class="hljs-number">3</span>   <span class="hljs-comment">#自适应惯性权重!!!创新点</span><br>        a = (<span class="hljs-number">2</span> - <span class="hljs-number">2</span>*ii/det)*(<span class="hljs-number">1</span>- w)  <span class="hljs-comment">#a随迭代次数从2非线性下降至0！！！创新点</span><br>        pp=<span class="hljs-number">0.7</span> <span class="hljs-keyword">if</span> ii &lt;= <span class="hljs-number">0.5</span>*det <span class="hljs-keyword">else</span> <span class="hljs-number">0.4</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):<br>            r1 = np.random.rand()  <span class="hljs-comment"># r1为[0,1]之间的随机数</span><br>            r2 = np.random.rand()  <span class="hljs-comment"># r2为[0,1]之间的随机数</span><br>            A = <span class="hljs-number">2</span> * a * r1 - a<br>            C = <span class="hljs-number">2</span> * r2<br>            b = <span class="hljs-number">1</span>     <span class="hljs-comment">#螺旋形状系数</span><br>            l = np.random.uniform(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)  <span class="hljs-comment">#参数l</span><br>            p = np.random.rand()<br>            <span class="hljs-keyword">if</span> p &lt; pp:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(A) &gt;= <span class="hljs-number">1</span>:<br>                    rand_leader = np.random.randint(<span class="hljs-number">0</span>, num)<br>                    X_rand = x[rand_leader, :]<br>                    D_X_rand = <span class="hljs-built_in">abs</span>(C * X_rand - x[i, :])<br>                    xx[i, :] = w*X_rand - A * D_X_rand<br>                    xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>                <span class="hljs-keyword">elif</span> <span class="hljs-built_in">abs</span>(A) &lt; <span class="hljs-number">1</span>:<br>                    D_Leader = <span class="hljs-built_in">abs</span>(C * best_x - x[i, :])<br>                    xx[i, :] = w*best_x - A * D_Leader<br>                    xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>            <span class="hljs-keyword">elif</span> p &gt;= pp:<br>                D = <span class="hljs-built_in">abs</span>(best_x - x[i, :])<br>                xx[i, :] = D*np.exp(b*l)*np.cos(<span class="hljs-number">2</span>*np.pi*l) + (<span class="hljs-number">1</span>-w)*best_x   <span class="hljs-comment">#完整的气泡网捕食公式</span><br>                xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>            ff[i] = fun(xx[i, :])<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(np.unique(ff[:i]))/(i+<span class="hljs-number">1</span>) &lt;= <span class="hljs-number">0.1</span>:     <span class="hljs-comment">#limit阈值 + 随机差分变异！！！创新点</span><br>                xx[i,:] = (r1*(best_x-xx[i,:]) +<br>                           r2*(x[np.random.randint(<span class="hljs-number">0</span>,num),:] - xx[i,:]))<br>                xx[i, :] = type_x(xx[i, :],<span class="hljs-built_in">type</span>,n) <span class="hljs-comment">#对自变量进行限制</span><br>                ff[i] = fun(xx[i, :])<br>        <span class="hljs-comment">#将上一代种群与这一代种群以及最优种群结合，选取排名靠前的个体组成新的种群</span><br>        F = np.hstack((np.array([best_f]), f, ff))<br>        F, b = np.sort(F,axis=-<span class="hljs-number">1</span>,kind=<span class="hljs-string">&#x27;stable&#x27;</span>), np.argsort(F)<span class="hljs-comment">#按小到大排序,获得靠前的位置</span><br>        X = np.vstack(([best_x], x, xx))[b, :]<br>        f = F[:num]  <span class="hljs-comment">#新种群的位置</span><br>        x = X[:num, :]  <span class="hljs-comment">#新种群的位置</span><br>        best_f, a = new_min(f)  <span class="hljs-comment"># 记录历史最优值</span><br>        best_x = x[a , :]  <span class="hljs-comment"># 记录历史最优解</span><br>        trace = np.hstack((trace, [best_f]))<br>    <span class="hljs-keyword">return</span> best_x,best_f,trace<br><br>best_x,best_f,trace = woa(sub,up,<span class="hljs-built_in">type</span>,<span class="hljs-number">20</span>,<span class="hljs-number">60</span>)     <span class="hljs-comment">#种群大小，迭代次数</span><br><span class="hljs-comment">#种群大小可以为自变量个数，迭代次数看情况</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;最优解为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(best_x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;最优值为：&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">float</span>(best_f))<br><br>plt.title(<span class="hljs-string">&#x27;鲸鱼算法&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(trace)+<span class="hljs-number">1</span>),trace, color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>生死狙击2净化行动挂机脚本</title>
    <link href="/2024/07/21/%E7%94%9F%E6%AD%BB%E7%8B%99%E5%87%BB2%E5%87%80%E5%8C%96%E8%A1%8C%E5%8A%A8%E6%8C%82%E6%9C%BA%E8%84%9A%E6%9C%AC/"/>
    <url>/2024/07/21/%E7%94%9F%E6%AD%BB%E7%8B%99%E5%87%BB2%E5%87%80%E5%8C%96%E8%A1%8C%E5%8A%A8%E6%8C%82%E6%9C%BA%E8%84%9A%E6%9C%AC/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyautogui<br><span class="hljs-keyword">import</span> pydirectinput<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> sys<br>pyautogui.PAUSE = <span class="hljs-number">0</span><br><span class="hljs-comment">#适用于净化行动，关闭自动匹配队友，开启单人匹配，在开始匹配页面运行程序。</span><br><span class="hljs-comment">#########   以管理员身份运行！！！！    ###########</span><br><span class="hljs-comment"># 获取图片的绝对路径</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_resource_path</span>(<span class="hljs-params">relative_path</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(sys, <span class="hljs-string">&#x27;_MEIPASS&#x27;</span>):<br>        <span class="hljs-keyword">return</span> os.path.join(sys._MEIPASS, relative_path)<br>    <span class="hljs-keyword">return</span> os.path.join(os.path.abspath(<span class="hljs-string">&quot;.&quot;</span>), relative_path)<br><span class="hljs-comment">#局内动作循环</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">repeat_keys</span>(<span class="hljs-params">keys</span>):<br>    <span class="hljs-keyword">try</span>:<br>        a = time.time()<br>        bb = time.time()<br>        <span class="hljs-keyword">while</span> a-bb+<span class="hljs-number">5000</span>&gt;<span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> keys:<br>                pyautogui.keyDown(key)<br>                time.sleep(<span class="hljs-number">1</span>)<br>                pyautogui.keyUp(key)<br>                time.sleep(<span class="hljs-number">9</span>)<br>                bb = time.time()<br>        pyautogui.press(<span class="hljs-string">&#x27;esc&#x27;</span>)<br>    <span class="hljs-keyword">except</span> KeyboardInterrupt:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Stopped by user&quot;</span>)<br><span class="hljs-comment">#检测图片</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identify_picture</span>(<span class="hljs-params">a</span>):<br>    left, top, width, height = pyautogui.locateOnScreen(get_resource_path(a),confidence=<span class="hljs-number">0.9</span>,grayscale=<span class="hljs-literal">True</span>)   <span class="hljs-comment"># 寻找图片</span><br>    center = pyautogui.center((left, top, width, height))    <span class="hljs-comment"># 寻找图片的中心</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;开始&#x27;</span>,center)<br>    pydirectinput.moveTo(center[<span class="hljs-number">0</span>],center[<span class="hljs-number">1</span>])<br>    pydirectinput.click()<br>    time.sleep(<span class="hljs-number">10</span>)<br><span class="hljs-comment"># 4：3比例 + 无边框窗口</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        identify_picture(<span class="hljs-string">&#x27;img\sta1.png&#x27;</span>) <span class="hljs-comment">#检测开始匹配</span><br>    <span class="hljs-keyword">except</span> TypeError:<br>        <span class="hljs-keyword">try</span>:<br>            identify_picture(<span class="hljs-string">&#x27;img\\bac.png&#x27;</span>) <span class="hljs-comment">#检测返回大厅</span><br>        <span class="hljs-keyword">except</span> TypeError:<br>            <span class="hljs-keyword">try</span>:<br>                identify_picture(<span class="hljs-string">&#x27;img\\img.png&#x27;</span>) <span class="hljs-comment">#检测准备完毕</span><br>                repeat_keys([<span class="hljs-string">&#x27;w&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;d&#x27;</span>]) <span class="hljs-comment">#局内动作，防止强退</span><br>            <span class="hljs-keyword">except</span> TypeError:<br>                <span class="hljs-keyword">try</span>:<br>                    identify_picture(<span class="hljs-string">&#x27;img\\img_1.png&#x27;</span>) <span class="hljs-comment">#检测返回大厅（出错情况）</span><br>                <span class="hljs-keyword">except</span> TypeError:<br>                    <span class="hljs-keyword">try</span>:<br>                        identify_picture(<span class="hljs-string">&#x27;img\\img_2.png&#x27;</span>) <span class="hljs-comment">#检测确定（出错情况）</span><br>                    <span class="hljs-keyword">except</span> TypeError:<br>                        <span class="hljs-keyword">try</span>:<br>                            identify_picture(<span class="hljs-string">&#x27;img\\img_3.png&#x27;</span>) <span class="hljs-comment">#检测点击空白处关闭（出错情况）</span><br>                        <span class="hljs-keyword">except</span> TypeError:<br>                            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;无&#x27;</span>)<br>                            time.sleep(<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>游戏</category>
      
      <category>自动化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>数据结构之栈与队列代码</title>
    <link href="/2024/02/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97%E4%BB%A3%E7%A0%81/"/>
    <url>/2024/02/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="一，顺序栈"><a href="#一，顺序栈" class="headerlink" title="一，顺序栈"></a>一，顺序栈</h1><h2 id="顺序栈的定义："><a href="#顺序栈的定义：" class="headerlink" title="顺序栈的定义："></a><strong>顺序栈的定义：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10           <span class="hljs-comment">//定义栈中元素的最大个数</span></span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    ElemType data[MaxSize];  <span class="hljs-comment">//静态数组存放栈中元素</span><br>    <span class="hljs-type">int</span> top;                 <span class="hljs-comment">//栈顶元素</span><br>&#125;SqStack;<br></code></pre></td></tr></table></figure><h2 id="顺序栈的初始化："><a href="#顺序栈的初始化：" class="headerlink" title="顺序栈的初始化："></a><strong>顺序栈的初始化：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    ElemType data[MaxSize];<br>    <span class="hljs-type">int</span> top;<br>&#125;SqStack;<br><br><span class="hljs-comment">// 初始化栈</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InitStack</span><span class="hljs-params">(SqStack &amp;S)</span></span>&#123;<br>    S.top = <span class="hljs-number">-1</span>;<span class="hljs-comment">//初始化栈顶指针</span><br>&#125;<br><br><span class="hljs-comment">// 判断栈是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">StackEmpty</span><span class="hljs-params">(SqStack S)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(S.top == <span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="入栈出栈："><a href="#入栈出栈：" class="headerlink" title="入栈出栈："></a><strong>入栈出栈：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 新元素进栈</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Push</span><span class="hljs-params">(SqStack &amp;S, ElemType x)</span></span>&#123;<br>    <span class="hljs-comment">// 判断栈是否已满</span><br>    <span class="hljs-keyword">if</span>(S.top == MaxSize - <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    S.data[++S.top] = x;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 出栈</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Pop</span><span class="hljs-params">(SqStack &amp;x, ElemType &amp;x)</span></span>&#123;<br>    <span class="hljs-comment">// 判断栈是否为空</span><br>    <span class="hljs-keyword">if</span>(S.top == <span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    x = S.data[S.top--];<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="读取栈顶元素："><a href="#读取栈顶元素：" class="headerlink" title="读取栈顶元素："></a><strong>读取栈顶元素：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 读栈顶元素</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">GetTop</span><span class="hljs-params">(SqStack S, ElemType &amp;x)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(S.top == <span class="hljs-number">-1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    x = S.data[S.top];<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="共享栈（两个栈共享同一片空间）："><a href="#共享栈（两个栈共享同一片空间）：" class="headerlink" title="共享栈（两个栈共享同一片空间）："></a><strong>共享栈（两个栈共享同一片空间）：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10      <span class="hljs-comment">//定义栈中元素的最大个数</span></span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    ElemType data[MaxSize];<span class="hljs-comment">//静态数组存放栈中元素</span><br>    <span class="hljs-type">int</span> top0;                        <span class="hljs-comment">//0号栈栈顶指针</span><br>    <span class="hljs-type">int</span> top1;                       <span class="hljs-comment">//1号栈栈顶指针</span><br>&#125;ShStack;<br><br><span class="hljs-comment">// 初始化栈</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InitSqStack</span><span class="hljs-params">(ShStack &amp;S)</span></span>&#123;<br>    S.top0 = <span class="hljs-number">-1</span>;<br>    S.top1 = MaxSize;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="二，链栈"><a href="#二，链栈" class="headerlink" title="二，链栈"></a>二，链栈</h1><h2 id="链栈的定义："><a href="#链栈的定义：" class="headerlink" title="链栈的定义："></a><strong>链栈的定义：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Linknode</span>&#123;<br>    ElemType data;<span class="hljs-comment">//数据域</span><br>    Linknode *next;<span class="hljs-comment">//指针域</span><br>&#125;Linknode,*LiStack;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">testStack</span><span class="hljs-params">()</span></span>&#123;<br>    LiStack L;<span class="hljs-comment">//声明一个链栈</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="链栈的初始化："><a href="#链栈的初始化：" class="headerlink" title="链栈的初始化："></a><strong>链栈的初始化：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Linknode</span>&#123;<br>    ElemType data;<br>    Linknode *next;<br>&#125;Linknode,*LiStack;<br><br><span class="hljs-comment">// 初始化栈</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InitStack</span><span class="hljs-params">(LiStack &amp;L)</span></span>&#123;<br>    L = (Linknode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(Linknode));<br>    <span class="hljs-keyword">if</span>(L == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    L-&gt;next = <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断栈是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isEmpty</span><span class="hljs-params">(LiStack &amp;L)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(L-&gt;next == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="入栈出栈：-1"><a href="#入栈出栈：-1" class="headerlink" title="入栈出栈："></a><strong>入栈出栈：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 新元素入栈</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">pushStack</span><span class="hljs-params">(LiStack &amp;L,ElemType x)</span></span>&#123;<br>    Linknode *s = (Linknode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(Linknode));<br>    <span class="hljs-keyword">if</span>(s == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    s-&gt;data = x;<br>    <span class="hljs-comment">// 头插法</span><br>    s-&gt;next = L-&gt;next;<br>    L-&gt;next = s;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 出栈</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">popStack</span><span class="hljs-params">(LiStack &amp;L, <span class="hljs-type">int</span> &amp;x)</span></span>&#123;<br>    <span class="hljs-comment">// 栈空不能出栈</span><br>    <span class="hljs-keyword">if</span>(L-&gt;next == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    Linknode *s = L-&gt;next;<br>    x = s-&gt;data;<br>    L-&gt;next = s-&gt;next;<br>    <span class="hljs-built_in">free</span>(s);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="三，顺序队列"><a href="#三，顺序队列" class="headerlink" title="三，顺序队列"></a>三，顺序队列</h1><h2 id="顺序队列的定义："><a href="#顺序队列的定义：" class="headerlink" title="顺序队列的定义："></a><strong>顺序队列的定义：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10;<span class="hljs-comment">//定义队列中元素的最大个数</span></span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    ElemType data[MaxSize];<span class="hljs-comment">//用静态数组存放队列元素</span><br>    <span class="hljs-type">int</span> front, rear;                <span class="hljs-comment">//队头指针和队尾指针</span><br>&#125;SqQueue;<br><br><span class="hljs-type">void</span> test&#123;<br>    SqQueue Q;<span class="hljs-comment">//声明一个队列</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="顺序队列的初始化："><a href="#顺序队列的初始化：" class="headerlink" title="顺序队列的初始化："></a><strong>顺序队列的初始化：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10;</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    ElemType data[MaxSize];<br>    <span class="hljs-type">int</span> front, rear;<br>&#125;SqQueue;<br><br><span class="hljs-comment">// 初始化队列</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InitQueue</span><span class="hljs-params">(SqQueue &amp;Q)</span></span>&#123;<br>    <span class="hljs-comment">// 初始化时，队头、队尾指针指向0</span><br>    <span class="hljs-comment">// 队尾指针指向的是即将插入数据的数组下标</span><br>    <span class="hljs-comment">// 队头指针指向的是队头元素的数组下标</span><br>    Q.rear = Q.front = <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断队列是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">QueueEmpty</span><span class="hljs-params">(SqQueue Q)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(Q.rear == Q.front)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="入队出队（循环队列）："><a href="#入队出队（循环队列）：" class="headerlink" title="入队出队（循环队列）："></a><strong>入队出队（循环队列）：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 新元素入队</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">EnQueue</span><span class="hljs-params">(SqQueue &amp;Q, ElemType x)</span></span>&#123;<br>    <span class="hljs-comment">// 如果队列已满直接返回</span><br>    <span class="hljs-keyword">if</span>((Q.rear+<span class="hljs-number">1</span>)%MaxSize == Q.front)<span class="hljs-comment">//牺牲一个单元区分队空和队满</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    Q.data[Q.rear] = x;<br>    Q.rear = (Q.rear+<span class="hljs-number">1</span>)%MaxSize;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 出队</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">DeQueue</span><span class="hljs-params">(SqQueue &amp;Q, ElemType &amp;x)</span></span>&#123;<br>    <span class="hljs-comment">// 如果队列为空直接返回</span><br>    <span class="hljs-keyword">if</span>(Q.rear == Q.front)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    x = Q.data[Q.front];<br>    Q.front = (Q.front+<span class="hljs-number">1</span>)%MaxSize;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="获得队头元素："><a href="#获得队头元素：" class="headerlink" title="获得队头元素："></a><strong>获得队头元素：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 获取队头元素并存入x</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">GetHead</span><span class="hljs-params">(SqQueue &amp;Q, ElemType &amp;x)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(Q.rear == Q.front)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    x = Q.data[Q.front];<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="四，链队列"><a href="#四，链队列" class="headerlink" title="四，链队列"></a>四，链队列</h1><h2 id="链队列的定义："><a href="#链队列的定义：" class="headerlink" title="链队列的定义："></a><strong>链队列的定义：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 链式队列结点</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LinkNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LinkNode</span> *next;<br>&#125;<br><br><span class="hljs-comment">// 链式队列</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    <span class="hljs-comment">// 头指针和尾指针</span><br>    LinkNode *front, *rear;<br>&#125;LinkQueue;<br></code></pre></td></tr></table></figure><h2 id="链队列的初始化（带头结点）："><a href="#链队列的初始化（带头结点）：" class="headerlink" title="链队列的初始化（带头结点）："></a><strong>链队列的初始化（带头结点）：</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LinkNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LinkNode</span> *next;<br>&#125;LinkNode;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span>&#123;<br>    LinkNode *front, *rear;<br>&#125;LinkQueue;<br><br><span class="hljs-comment">// 初始化队列</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InitQueue</span><span class="hljs-params">(LinkQueue &amp;Q)</span></span>&#123;<br>    <span class="hljs-comment">// 初始化时，front、rear都指向头结点</span><br>    Q.front = Q.rear = (LinkNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LinkNode));<br>    Q.front -&gt; next = <span class="hljs-literal">NULL</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断队列是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">IsEmpty</span><span class="hljs-params">(LinkQueue Q)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(Q.front == Q.rear)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="入队出队："><a href="#入队出队：" class="headerlink" title="入队出队："></a><strong>入队出队：</strong></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 新元素入队</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">EnQueue</span><span class="hljs-params">(LinkQueue &amp;Q, ElemType x)</span>&#123;<br>    LinkNode *s = (LinkNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(LinkNode));<br>    s-&gt;data = x;<br>    s-&gt;next = <span class="hljs-literal">NULL</span>;<br>    Q.rear-&gt;next = s;<br>    Q.rear = s;<br>&#125;<br><br><span class="hljs-comment">// 队头元素出队</span><br><span class="hljs-type">bool</span> <span class="hljs-title function_">DeQueue</span><span class="hljs-params">(LinkQueue &amp;Q, ElemType &amp;x)</span>&#123;<br>    <span class="hljs-keyword">if</span>(Q.front == Q.rear)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    LinkNode *p = Q.front-&gt;next;<br>    x = p-&gt;data;<br>    Q.front-&gt;next = p-&gt;next;<br>    <span class="hljs-comment">// 如果p是最后一个结点，则将队头指针也指向NULL</span><br>    <span class="hljs-keyword">if</span>(Q.rear == p)<br>        Q.rear = Q.front;<br>    <span class="hljs-built_in">free</span>(p);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="以上是带头结点的链队列，下面是不带头结点的操作："><a href="#以上是带头结点的链队列，下面是不带头结点的操作：" class="headerlink" title="以上是带头结点的链队列，下面是不带头结点的操作："></a><strong>以上是带头结点的链队列，下面是不带头结点的操作：</strong></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">LinkNode</span>&#123;</span><br>    ElemType data;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">LinkNode</span> *<span class="hljs-title">next</span>;</span><br>&#125;LinkNode;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span>&#123;</span><br>    LinkNode *front, *rear;<br>&#125;LinkQueue;<br><br><span class="hljs-comment">// 初始化队列</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">InitQueue</span><span class="hljs-params">(LinkQueue &amp;Q)</span>&#123;<br>    <span class="hljs-comment">// 不带头结点的链队列初始化，头指针和尾指针都指向NULL</span><br>    Q.front = <span class="hljs-literal">NULL</span>;<br>    Q.rear = <span class="hljs-literal">NULL</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断队列是否为空</span><br><span class="hljs-type">bool</span> <span class="hljs-title function_">IsEmpty</span><span class="hljs-params">(LinkQueue Q)</span>&#123;<br>    <span class="hljs-keyword">if</span>(Q.front == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-comment">// 新元素入队</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">EnQueue</span><span class="hljs-params">(LinkQueue &amp;Q, ElemType x)</span>&#123;<br>    LinkNode *s = (LinkNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(LinkNode));<br>    s-&gt;data = x;<br>    s-&gt;next = <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-comment">// 第一个元素入队时需要特别处理</span><br>    <span class="hljs-keyword">if</span>(Q.front == <span class="hljs-literal">NULL</span>)&#123;<br>        Q.front = s;<br>        Q.rear = s;<br>    &#125;<span class="hljs-keyword">else</span>&#123;<br>        Q.rear-&gt;next = s;<br>        Q.rear = s;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">//队头元素出队</span><br><span class="hljs-type">bool</span> <span class="hljs-title function_">DeQueue</span><span class="hljs-params">(LinkQueue &amp;Q, ElemType &amp;x)</span>&#123;<br>    <span class="hljs-keyword">if</span>(Q.front == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    LinkNode *s = Q.front;<br>    x = s-&gt;data;<br>    <span class="hljs-keyword">if</span>(Q.front == Q.rear)&#123;<br>        Q.front = Q.rear = <span class="hljs-literal">NULL</span>;<br>    &#125;<span class="hljs-keyword">else</span>&#123;<br>        Q.front = Q.front-&gt;next;<br>    &#125;<br>    <span class="hljs-built_in">free</span>(s);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>参考自：<a href="https://blog.csdn.net/qq_55593227/article/details/123598044">https://blog.csdn.net/qq_55593227/article/details/123598044</a></p>]]></content>
    
    
    <categories>
      
      <category>考研</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>数据结构之线性表代码</title>
    <link href="/2024/02/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%BB%A3%E7%A0%81/"/>
    <url>/2024/02/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="一，顺序表"><a href="#一，顺序表" class="headerlink" title="一，顺序表"></a>一，顺序表</h1><h2 id="1-1-顺序表的实现"><a href="#1-1-顺序表的实现" class="headerlink" title="1.1 顺序表的实现"></a>1.1 顺序表的实现</h2><h3 id="静态实现："><a href="#静态实现：" class="headerlink" title="静态实现："></a><strong>静态实现：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10 <span class="hljs-comment">// 定义最大长度 </span></span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-type">int</span> data[MaxSize]; <span class="hljs-comment">// 使用静态的数组存放数据元素 </span><br><span class="hljs-type">int</span> length; <span class="hljs-comment">// 顺序表的当前长度 </span><br>&#125;SqList;<br><br><span class="hljs-comment">// 初始化顺序表 </span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InitList</span><span class="hljs-params">(SqList &amp;L)</span> </span>&#123;<br>L.length = <span class="hljs-number">0</span>; <span class="hljs-comment">// 顺序表初始长度为0 </span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>SqList L; <span class="hljs-comment">// 声明一个顺序表 </span><br><span class="hljs-built_in">InitList</span>(L); <span class="hljs-comment">// 初始化顺序表 </span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="动态实现："><a href="#动态实现：" class="headerlink" title="动态实现："></a><strong>动态实现：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10 <span class="hljs-comment">// 定义最大长度 </span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> InitSize 10 <span class="hljs-comment">// 顺序表的初始长度</span></span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-type">int</span> *data; <span class="hljs-comment">// 声明动态分配数组的指针 </span><br><span class="hljs-type">int</span> MaxSize; <span class="hljs-comment">// 顺序表的最大容量</span><br><span class="hljs-type">int</span> length; <span class="hljs-comment">// 顺序表的当前长度 </span><br>&#125;SeqList;<br><br><span class="hljs-comment">// 初始化顺序表 </span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">InitList</span><span class="hljs-params">(SeqList &amp;L)</span> </span>&#123;<br><span class="hljs-comment">// 用malloc函数申请一片连续的存储空间 </span><br>L.data = (<span class="hljs-type">int</span> *)<span class="hljs-built_in">malloc</span>(InitSize * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>L.length = <span class="hljs-number">0</span>;<br>L.MaxSize = InitSize;<br>&#125;<br><br><span class="hljs-comment">// 增加动态数组的长度 ，非重点</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">IncreaseSize</span><span class="hljs-params">(SeqList &amp;L, <span class="hljs-type">int</span> len)</span> </span>&#123;<br><span class="hljs-type">int</span> *p = L.data;<br>L.data = (<span class="hljs-type">int</span> *)<span class="hljs-built_in">malloc</span>((L.MaxSize+len) * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; L.length; i++)<br>L.data[i] = p[i]; <span class="hljs-comment">// 将数据复制到新区域 </span><br>L.MaxSize = L.MaxSize + len; <span class="hljs-comment">// 顺序表最大长度增加len </span><br><span class="hljs-built_in">free</span>(p); <span class="hljs-comment">// 释放原来的内存空间 </span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>SeqList L; <span class="hljs-comment">// 声明一个顺序表 </span><br><span class="hljs-built_in">InitList</span>(L); <span class="hljs-comment">// 初始化顺序表 </span><br>    ...<br><span class="hljs-built_in">IncreaseSize</span>(L, <span class="hljs-number">5</span>);<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>malloc() 函数的作用：会申请一片存储空间，并返回存储空间第一个位置的地址，也就是该位置的指针。</p></blockquote><h2 id="1-2-顺序表的基本操作"><a href="#1-2-顺序表的基本操作" class="headerlink" title="1.2 顺序表的基本操作"></a>1.2 顺序表的基本操作</h2><h3 id="插入："><a href="#插入：" class="headerlink" title="插入："></a><strong>插入：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 在顺序表i位置插入e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListInsert</span><span class="hljs-params">(SqList &amp;L, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> e)</span> </span>&#123;<br><span class="hljs-keyword">if</span> (i &lt; <span class="hljs-number">1</span> || i &gt; L.length+<span class="hljs-number">1</span>) <span class="hljs-comment">// 判断i的范围是否有效 </span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-keyword">if</span> (L.length &gt;= MaxSize) <span class="hljs-comment">// 判断存储空间是否已满 </span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = L.length; j &gt;= i; j--) <span class="hljs-comment">// 将第i个元素之后的元素后移 </span><br>L.data[j] = L.data[j<span class="hljs-number">-1</span>];<br>L.data[i<span class="hljs-number">-1</span>] = e; <span class="hljs-comment">// 在位置i处放入e </span><br>L.length++; <span class="hljs-comment">// 长度+1 </span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125; <br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h3 id="删除："><a href="#删除：" class="headerlink" title="删除："></a><strong>删除：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 删除顺序表i位置的数据并存入e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListDelete</span><span class="hljs-params">(SqList &amp;L, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> &amp;e)</span> </span>&#123;<br><span class="hljs-keyword">if</span> (i &lt; <span class="hljs-number">1</span> || i &gt; L.length) <span class="hljs-comment">// 判断i的范围是否有效</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>e = L.data[i<span class="hljs-number">-1</span>]; <span class="hljs-comment">// 将被删除的元素赋值给e </span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = i; j &lt; L.length; j++) <span class="hljs-comment">//将第i个位置后的元素前移 </span><br>L.data[j<span class="hljs-number">-1</span>] = L.data[j];<br>L.length--;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>; <br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h3 id="按位查找："><a href="#按位查找：" class="headerlink" title="按位查找："></a><strong>按位查找：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 静态分配的按位查找</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> MaxSize 10</span><br><br><span class="hljs-function">ElemType <span class="hljs-title">GetElem</span><span class="hljs-params">(SqList L, <span class="hljs-type">int</span> i)</span> </span>&#123;<br><span class="hljs-keyword">return</span> L.data[i<span class="hljs-number">-1</span>];<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 动态分配的按位查找</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> InitSize 10</span><br><br><span class="hljs-function">ElemType <span class="hljs-title">GetElem</span><span class="hljs-params">(SeqList L, <span class="hljs-type">int</span> i)</span> </span>&#123;<br><span class="hljs-keyword">return</span> L.data[i<span class="hljs-number">-1</span>];<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度： O ( 1 )</p><h3 id="按值查找："><a href="#按值查找：" class="headerlink" title="按值查找："></a><strong>按值查找：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 查找第一个元素值为e的元素，并返回其位序 </span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">LocateElem</span><span class="hljs-params">(SqList L, ElemType e)</span> </span>&#123;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; L.length; i++)<br><span class="hljs-keyword">if</span> (L.data[i] == e)<br><span class="hljs-keyword">return</span> i+<span class="hljs-number">1</span>; <span class="hljs-comment">// 数组下标为i的元素值等于e，返回其位序i+1 </span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <span class="hljs-comment">// 没有查找到 </span><br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>在《数据结构》考研初试中，手写代码可以直接用“&#x3D;&#x3D;”，无论 ElemType 是基本数据类型还是结构类型</p></blockquote><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h1 id="二，单链表"><a href="#二，单链表" class="headerlink" title="二，单链表"></a>二，单链表</h1><h2 id="2-1-单链表的实现"><a href="#2-1-单链表的实现" class="headerlink" title="2.1 单链表的实现"></a>2.1 单链表的实现</h2><h3 id="不带头结点的单链表："><a href="#不带头结点的单链表：" class="headerlink" title="不带头结点的单链表："></a><strong>不带头结点的单链表：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">//初始化一个空的单链表</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InitList</span><span class="hljs-params">(LinkList &amp;L)</span></span>&#123;<br>    L = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//空表，暂时还没有任何结点</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">test</span><span class="hljs-params">()</span></span>&#123;<br>    LinkList L;<span class="hljs-comment">//声明一个指向单链表的头指针</span><br>    <span class="hljs-comment">//初始化一个空表</span><br>    <span class="hljs-built_in">InitList</span>(L);<br>    ...<br>&#125;<br><br><span class="hljs-comment">//判断单链表是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Empty</span><span class="hljs-params">(LinkList L)</span></span>&#123;<br>    <span class="hljs-keyword">return</span> (L==<span class="hljs-literal">NULL</span>)<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="带头结点的单链表："><a href="#带头结点的单链表：" class="headerlink" title="带头结点的单链表："></a><strong>带头结点的单链表：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">// 初始化一个单链表（带头结点）</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InitList</span><span class="hljs-params">(LinkList &amp;L)</span></span>&#123;<br>    L = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<span class="hljs-comment">//分配一个头结点</span><br>    <span class="hljs-keyword">if</span> (L == <span class="hljs-literal">NULL</span>)<span class="hljs-comment">//内存不足，分配失败</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    L-&gt;next = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//头结点之后暂时还没有结点</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">test</span><span class="hljs-params">()</span></span>&#123;<br>    LinkList L;<span class="hljs-comment">//声明一个指向单链表的头指针</span><br>    <span class="hljs-comment">//初始化一个空表</span><br>    <span class="hljs-built_in">InitList</span>(L);<br>    ...<br>&#125;<br><br><span class="hljs-comment">//判断单链表是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Empty</span><span class="hljs-params">(LinkList L)</span></span>&#123;<br>    <span class="hljs-keyword">if</span> (L-&gt;next == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-2-单链表的建立"><a href="#2-2-单链表的建立" class="headerlink" title="2.2 单链表的建立"></a>2.2 单链表的建立</h2><h3 id="尾插法建立单链表："><a href="#尾插法建立单链表：" class="headerlink" title="尾插法建立单链表："></a><strong>尾插法建立单链表：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 使用尾插法建立单链表L</span><br><span class="hljs-function">LinkList <span class="hljs-title">List_TailInsert</span><span class="hljs-params">(LinkList &amp;L)</span></span>&#123;<br>    <span class="hljs-type">int</span> x;<span class="hljs-comment">//设ElemType为整型int</span><br>    L = (LinkList)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<span class="hljs-comment">//建立头结点(初始化空表)</span><br>    LNode *s, *r = L;<span class="hljs-comment">//r为表尾指针</span><br>    <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;x);<span class="hljs-comment">//输入要插入的结点的值</span><br>    <span class="hljs-keyword">while</span>(x!=<span class="hljs-number">9999</span>)&#123;<span class="hljs-comment">//输入9999表示结束</span><br>        s = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<br>        s-&gt;data = x;<br>        r-&gt;next = s;<br>        r = s;<span class="hljs-comment">//r指针指向新的表尾结点</span><br>        <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;x);<br>    &#125;<br>    r-&gt;next = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//尾结点指针置空</span><br>    <span class="hljs-keyword">return</span> L;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：O ( n )</p><h3 id="头插法建立单链表："><a href="#头插法建立单链表：" class="headerlink" title="头插法建立单链表："></a><strong>头插法建立单链表：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">LinkList <span class="hljs-title">List_HeadInsert</span><span class="hljs-params">(LinkList &amp;L)</span></span>&#123;<span class="hljs-comment">//逆向建立单链表</span><br>    LNode *s;<br>    <span class="hljs-type">int</span> x;<br>    L = (LinkList)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<span class="hljs-comment">//建立头结点</span><br>    L-&gt;next = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//初始为空链表,这步很关键</span><br>    <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;x);<span class="hljs-comment">//输入要插入的结点的值</span><br>    <span class="hljs-keyword">while</span>(x!=<span class="hljs-number">9999</span>)&#123;<span class="hljs-comment">//输入9999表结束</span><br>        s = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<br>        s-&gt;data = x;<br>        s-&gt;next = L-&gt;next;<br>        L-&gt;next = s;<br><span class="hljs-comment">//将新结点插入表中，L为头指针</span><br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;x);<br>    &#125;<br>    <span class="hljs-keyword">return</span> L;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="头插法实现链表的逆置："><a href="#头插法实现链表的逆置：" class="headerlink" title="头插法实现链表的逆置："></a><strong>头插法实现链表的逆置：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 将链表L中的数据逆置并返回</span><br><span class="hljs-function">LNode *<span class="hljs-title">Inverse</span><span class="hljs-params">(LNode *L)</span></span>&#123;<br>    LNode *p, *q;<br>    p = L-&gt;next;<span class="hljs-comment">//p指针指向第一个结点</span><br>    L-&gt;next = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//头结点置空</span><br>    <span class="hljs-comment">// 依次判断p结点中的数据并采用头插法插到L链表中</span><br>    <span class="hljs-keyword">while</span> (p != <span class="hljs-literal">NULL</span>)&#123;<br>        q = p;<br>        p = p-&gt;next;<br>        q-&gt;next = L-&gt;next;<br>        L-&gt;next = q;<br>    &#125;<br>    <span class="hljs-keyword">return</span> L;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-3-单链表的基本操作"><a href="#2-3-单链表的基本操作" class="headerlink" title="2.3 单链表的基本操作"></a>2.3 单链表的基本操作</h2><h3 id="按位序插入（带头结点）："><a href="#按位序插入（带头结点）：" class="headerlink" title="按位序插入（带头结点）："></a><strong>按位序插入（带头结点）：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">//在第i个位置插入元素e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListInsert</span><span class="hljs-params">(LinkList &amp;L, <span class="hljs-type">int</span> i, ElemType e)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> False;<br>    LNode *p; <span class="hljs-comment">//指针p指向当前扫描到的结点</span><br>    <span class="hljs-type">int</span> j=<span class="hljs-number">0</span>;  <span class="hljs-comment">//当前p指向的是第几个结点</span><br>    p = L;    <span class="hljs-comment">//循环找到第i-1个结点</span><br>    <span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span> &amp;&amp; j&lt;i<span class="hljs-number">-1</span>)&#123; <span class="hljs-comment">//如果i&gt;lengh，p最后会等于NULL</span><br>        p = p-&gt;next;<br>        j++;<br>    &#125;<br><span class="hljs-comment">//p值为NULL说明i值不合法</span><br>    <span class="hljs-keyword">if</span> (p==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-comment">//在第i-1个结点后插入新结点</span><br>    LNode *s = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<br>    s-&gt;data = e;<br>    s-&gt;next = p-&gt;next;<br>    p-&gt;next = s;<br><span class="hljs-comment">//将结点s连到p后</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h3 id="按位序插入（不带头结点）："><a href="#按位序插入（不带头结点）：" class="headerlink" title="按位序插入（不带头结点）："></a><strong>按位序插入（不带头结点）：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">//在第i个位置插入元素e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListInsert</span><span class="hljs-params">(LinkList &amp;L, <span class="hljs-type">int</span> i, ElemType e)</span></span>&#123;<br><span class="hljs-comment">//判断i的合法性</span><br>    <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-comment">//需要判断插入的位置是否是第1个</span><br>    <span class="hljs-keyword">if</span>(i==<span class="hljs-number">1</span>)&#123;<br>        LNode *s = (LNode *)<span class="hljs-built_in">malloc</span>(size <span class="hljs-built_in">of</span>(LNode));<br>        s-&gt;data =e;<br>        s-&gt;next =L;<br>        L=s;<span class="hljs-comment">//头指针指向新结点</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br><span class="hljs-comment">//i&gt;1的情况与带头结点一样，唯一区别是j的初始值为1</span><br>    LNode *p;<span class="hljs-comment">//指针p指向当前扫描到的结点</span><br>    <span class="hljs-type">int</span> j=<span class="hljs-number">1</span>;<span class="hljs-comment">//当前p指向的是第几个结点</span><br>    p = L;<br><span class="hljs-comment">//循环找到第i-1个结点</span><br>    <span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span> &amp;&amp; j&lt;i<span class="hljs-number">-1</span>)&#123;<span class="hljs-comment">//如果i&gt;lengh，p最后会等于NULL</span><br>        p = p-&gt;next;<br>        j++;<br>    &#125;<br><span class="hljs-comment">//p值为NULL说明i值不合法</span><br>    <span class="hljs-keyword">if</span> (p==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-comment">//在第i-1个结点后插入新结点</span><br>    LNode *s = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<br>    s-&gt;data = e;<br>    s-&gt;next = p-&gt;next;<br>    p-&gt;next = s;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><blockquote><p>除非特别声明，否则之后的代码都默认为带头结点</p></blockquote><h3 id="指定结点的后插操作："><a href="#指定结点的后插操作：" class="headerlink" title="指定结点的后插操作："></a><strong>指定结点的后插操作：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">// 在结点p后插入元素e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InsertNextNode</span><span class="hljs-params">(LNode *p, ElemType e)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(p==<span class="hljs-literal">NULL</span>)&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>    LNode *s = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<br>    <span class="hljs-keyword">if</span>(s==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    s-&gt;data = e;<br>    s-&gt;next = p-&gt;next;<br>    p-&gt;next = s;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 按位序插入的函数中可以直接调用后插操作</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListInsert</span><span class="hljs-params">(LinkList &amp;L, <span class="hljs-type">int</span> i, ElemType e)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> False;<br>    LNode *p;<br><span class="hljs-comment">//指针p指向当前扫描到的结点</span><br><span class="hljs-type">int</span> j=<span class="hljs-number">0</span>;<br><span class="hljs-comment">//当前p指向的是第几个结点</span><br>    p = L;<br><span class="hljs-comment">//循环找到第i-1个结点</span><br>    <span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span> &amp;&amp; j&lt;i<span class="hljs-number">-1</span>)&#123;<br><span class="hljs-comment">//如果i&gt;lengh, p最后会等于NULL</span><br>        p = p-&gt;next;<br>        j++;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">InsertNextNode</span>(p, e)<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：O ( 1 )</p><h3 id="指定结点的前插操作："><a href="#指定结点的前插操作：" class="headerlink" title="指定结点的前插操作："></a><strong>指定结点的前插操作：</strong></h3><blockquote><p>如果传入头指针，就可以循环整个链表找到指定结点p的前驱结点q，再对q进行后插操作；<br>如果不传入头指针，可以在指定结点p后插入一个结点s，并交换两个结点所保存的数据，从而变相实现指定结点的前插操作。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">// 在结点p前插入元素e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InsertPriorNode</span><span class="hljs-params">(LNode *p, ElemType e)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(p==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    LNode *s = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));<br><span class="hljs-comment">// 内存不足分配失败</span><br><span class="hljs-keyword">if</span>(s==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-comment">// 将s插入结点p之后</span><br>    s-&gt;next = p-&gt;next;<br>    p-&gt;next = s;<br><span class="hljs-comment">// 交换两个结点中的数据</span><br>    s-&gt;data = p-&gt;data;<br>    p-&gt;data = e;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：O ( 1 )</p><h3 id="按位序删除："><a href="#按位序删除：" class="headerlink" title="按位序删除："></a><strong>按位序删除：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;&#125;LNode, *LinkList;<br><br><span class="hljs-comment">// 删除第i个结点并将其所保存的数据存入e</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListDelete</span><span class="hljs-params">(LinkList &amp;L, <span class="hljs-type">int</span> i, ElemType &amp;e)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    LNode *p;<span class="hljs-comment">//指针p指向当前扫描到的结点</span><br>    <span class="hljs-type">int</span> j=<span class="hljs-number">0</span>;<span class="hljs-comment">//当前p指向的是第几个结点</span><br>    p = L;<br><span class="hljs-comment">//循环找到第i-1个结点</span><br>    <span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span> &amp;&amp; j&lt;i<span class="hljs-number">-1</span>)&#123;<br><span class="hljs-comment">//如果i&gt;lengh，p和p的后继结点会等于NULL</span><br>        p = p-&gt;next;<br>        j++;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(p==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    <span class="hljs-keyword">if</span>(p-&gt;next == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br><span class="hljs-comment">//令q暂时保存被删除的结点</span><br>    LNode *q = p-&gt;next;<br>    e = q-&gt;data;<br>    p-&gt;next = q-&gt;next;<br>    <span class="hljs-built_in">free</span>(q)<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h3 id="删除指定结点："><a href="#删除指定结点：" class="headerlink" title="删除指定结点："></a><strong>删除指定结点：</strong></h3><blockquote><p>如果传入头指针，就可以循环整个链表找到指定结点p的前驱结点q，再对p进行删除操作；<br>如果不传入头指针，可以把指定结点p的后继结点q删除，并使结点p保存结点q存储的数据，从而变相实现删除指定结点的操作。但是<strong>如果指定结点p没有后继结点，这么做会报错</strong>。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 删除指定结点p</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">DeleteNode</span><span class="hljs-params">(LNode *p)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(p==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    LNode *q = p-&gt;next;<span class="hljs-comment">// 令q指向p的后继结点// 如果p是最后一个结点，则q指向NULL，继续执行就会报错</span><br>    p-&gt;data = q-&gt;data;<br>    p-&gt;next = q-&gt;next;<br>    <span class="hljs-built_in">free</span>(q);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：O ( 1 )</p><h3 id="按位查找：-1"><a href="#按位查找：-1" class="headerlink" title="按位查找："></a><strong>按位查找：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next;<br>&#125;LNode, *LinkList;<br><br><span class="hljs-comment">// 查找指定位序i的结点并返回</span><br><span class="hljs-function">LNode * <span class="hljs-title">GetElem</span><span class="hljs-params">(LinkList L, <span class="hljs-type">int</span> i)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>    LNode *p;<br>    <span class="hljs-type">int</span> j=<span class="hljs-number">0</span>;<br>    p = L;<br>    <span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span> &amp;&amp; j&lt;i)&#123;<br>        p = p-&gt;next;<br>        j++;<br>    &#125;<br>    <span class="hljs-keyword">return</span> p;<br>&#125;<br><br><span class="hljs-comment">// 封装后的插入操作，在第i个位置插入元素e，可以调用查询操作和后插操作</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">ListInsert</span><span class="hljs-params">(LinkList &amp;L, <span class="hljs-type">int</span> i, ElemType e)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> False;<br><span class="hljs-comment">// 找到第i-1个元素</span><br>    LNode *p = <span class="hljs-built_in">GetElem</span>(L, i<span class="hljs-number">-1</span>);<br><span class="hljs-comment">// 在p结点后插入元素e</span><br><span class="hljs-keyword">return</span> <span class="hljs-built_in">InsertNextNode</span>(p, e)<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h3 id="按值查找：-1"><a href="#按值查找：-1" class="headerlink" title="按值查找："></a><strong>按值查找：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 查找数据域为e的结点指针，否则返回NULL</span><br><span class="hljs-function">LNode * <span class="hljs-title">LocateElem</span><span class="hljs-params">(LinkList L, ElemType e)</span></span>&#123;<br>    LNode *P = L-&gt;next;<br>    <span class="hljs-comment">// 从第一个结点开始查找数据域为e的结点</span><br>    <span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span> &amp;&amp; p-&gt;data != e)&#123;<br>        p = p-&gt;next;<br>    &#125;<br>    <span class="hljs-keyword">return</span> p;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：</p><ul><li>最好时间复杂度：O ( 1 )</li><li>最坏时间复杂度：O ( n )</li><li>平均时间复杂度：O ( n )</li></ul><h3 id="计算单链表长度："><a href="#计算单链表长度：" class="headerlink" title="计算单链表长度："></a><strong>计算单链表长度：</strong></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 计算单链表的长度</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">Length</span><span class="hljs-params">(LinkList L)</span></span>&#123;<br>    <span class="hljs-type">int</span> len=<span class="hljs-number">0</span>;<span class="hljs-comment">//统计表长</span><br>    LNode *p = L;<br>    <span class="hljs-keyword">while</span>(p-&gt;next != <span class="hljs-literal">NULL</span>)&#123;<br>        p = p-&gt;next;<br>        len++;<br>    &#125;<br>    <span class="hljs-keyword">return</span> len;<br>&#125;<br></code></pre></td></tr></table></figure><p>时间复杂度：O ( n )</p><h1 id="三，双链表"><a href="#三，双链表" class="headerlink" title="三，双链表"></a>三，双链表</h1><p><img src="/2024/02/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%BB%A3%E7%A0%81/0.png"></p><h2 id="双链表的初始化-带头结点"><a href="#双链表的初始化-带头结点" class="headerlink" title="双链表的初始化 (带头结点)"></a><strong>双链表的初始化 (带头结点)</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">DNode</span>&#123;            <span class="hljs-comment">//定义双链表结点类型</span><br>    ElemType data;               <span class="hljs-comment">//数据域</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">DNode</span> *prior, *next;  <span class="hljs-comment">//前驱和后继指针</span><br>&#125;DNode, *DLinklist;<br><br><span class="hljs-comment">// 初始化双链表</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InitDLinkList</span><span class="hljs-params">(Dlinklist &amp;L)</span></span>&#123;<br>    L = (DNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(DNode));<br>    <span class="hljs-keyword">if</span>(L==<span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    L-&gt;prior = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//头结点的prior指针永远指向NULL</span><br>    L-&gt;next = <span class="hljs-literal">NULL</span>;<span class="hljs-comment">//头结点之后暂时还没有结点，置空</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">testDLinkList</span><span class="hljs-params">()</span></span>&#123;<br>    DLinklist L;<br>    <span class="hljs-built_in">InitDLinkList</span>(L);<br>    ...<br>&#125;<br><br><span class="hljs-comment">// 判断双链表是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Empty</span><span class="hljs-params">(DLinklist L)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(L-&gt;next == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="双链表的后插操作"><a href="#双链表的后插操作" class="headerlink" title="双链表的后插操作"></a><strong>双链表的后插操作</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">DNode</span>&#123;<br>    ElemType data;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">DNode</span> *prior, *next;<br>&#125;DNode, *DLinklist;<br><br><span class="hljs-comment">// 将结点s插入到结点p之后</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InsertNextDNode</span><span class="hljs-params">(DNode *p, DNode *s)</span></span>&#123; <br>    <span class="hljs-keyword">if</span>(p==<span class="hljs-literal">NULL</span> || s==<span class="hljs-literal">NULL</span>)  <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;         <br>    s-&gt;next = p-&gt;next;      <br>    <span class="hljs-comment">// 判断结点p之后是否有后继结点  </span><br>    <span class="hljs-keyword">if</span> (p-&gt;next != <span class="hljs-literal">NULL</span>)   <br>        p-&gt;next-&gt;prior = s; <br>    s-&gt;prior = p;   <br>    p-&gt;next = s;     <br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>双链表的前插操作、按位序插入操作都可以转换成后插操作</p></blockquote><h2 id="双链表的删除操作"><a href="#双链表的删除操作" class="headerlink" title="双链表的删除操作"></a><strong>双链表的删除操作</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 删除p结点的后继结点</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">DeletNextDNode</span><span class="hljs-params">(DNode *p)</span></span>&#123;   <br>    <span class="hljs-keyword">if</span>(p==<span class="hljs-literal">NULL</span>)           <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;   <br>    <span class="hljs-comment">// 找到p的后继结点q    </span><br>    DNode *q =p-&gt;next;   <br>    <span class="hljs-keyword">if</span>(q==<span class="hljs-literal">NULL</span>)          <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <br>    p-&gt;next = q-&gt;next;   <br>    <span class="hljs-keyword">if</span>(q-&gt;next != <span class="hljs-literal">NULL</span>) <br>        q-&gt;next-&gt;prior=p;  <br>    <span class="hljs-built_in">free</span>(q);     <br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 销毁一个双链表</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">DestoryList</span><span class="hljs-params">(DLinklist &amp;L)</span></span>&#123; <br>    <span class="hljs-comment">// 循环释放各个数据结点   </span><br>    <span class="hljs-keyword">while</span>(L-&gt;next != <span class="hljs-literal">NULL</span>)&#123;    <br>        <span class="hljs-built_in">DeletNextDNode</span>(L);      <br>        <span class="hljs-built_in">free</span>(L);        <br>        <span class="hljs-comment">// 头指针置空  </span><br>        L=<span class="hljs-literal">NULL</span>;     <br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="双链表的遍历"><a href="#双链表的遍历" class="headerlink" title="双链表的遍历"></a><strong>双链表的遍历</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 向后遍历</span><br><span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span>)&#123;    <br>    <span class="hljs-comment">// 对结点p做相应处理    </span><br>    p = p-&gt;next;<br>&#125;<br><br><span class="hljs-comment">// 向前遍历</span><br><span class="hljs-keyword">while</span>(p!=<span class="hljs-literal">NULL</span>)&#123;    <br>    <span class="hljs-comment">// 对结点p做相应处理 </span><br>    p = p-&gt;prior;<br>&#125;<br><br><span class="hljs-comment">// 跳过头结点的遍历</span><br><span class="hljs-keyword">while</span>(p-&gt;prior!=<span class="hljs-literal">NULL</span>)&#123; <br>    <span class="hljs-comment">//对结点p做相应处理    </span><br>    p = p-&gt;prior;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>双链表不可随机存取，按位查找、按值查找操作都只能用遍历的方式实现。</p></blockquote><h1 id="四，循环链表"><a href="#四，循环链表" class="headerlink" title="四，循环链表"></a>四，循环链表</h1><p><img src="/2024/02/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%BB%A3%E7%A0%81/1.png"></p><p><img src="/2024/02/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%A1%A8%E4%BB%A3%E7%A0%81/2.png"></p><h2 id="循环单链表的实现"><a href="#循环单链表的实现" class="headerlink" title="循环单链表的实现"></a><strong>循环单链表的实现</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span>&#123;           <br>    ElemType data;                  <br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">LNode</span> *next; <br>&#125;DNode, *Linklist;<br><br><span class="hljs-comment">// 初始化循环单链表</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InitList</span><span class="hljs-params">(LinkList &amp;L)</span></span>&#123;    <br>    L = (LNode *)<span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(LNode));  <br>    <span class="hljs-keyword">if</span>(L==<span class="hljs-literal">NULL</span>)             <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <br>    <span class="hljs-comment">// 最后一个结点的next指针指向头结点    </span><br>    L-&gt;next = L;       <br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断循环单链表是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Empty</span><span class="hljs-params">(LinkList L)</span></span>&#123;    <br>    <span class="hljs-keyword">if</span>(L-&gt;next == L)       <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    <br>    <span class="hljs-keyword">else</span>             <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断结点p是否为循环单链表的表尾结点</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isTail</span><span class="hljs-params">(LinkList L, LNode *p)</span></span>&#123; <br>    <span class="hljs-keyword">if</span>(p-&gt;next == L)          <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;      <br>    <span class="hljs-keyword">else</span>            <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="循环双链表的实现"><a href="#循环双链表的实现" class="headerlink" title="循环双链表的实现"></a><strong>循环双链表的实现</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">DNode</span>&#123;            <br>    ElemType data;           <br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">DNode</span> *prior, *next;  <br>&#125;DNode, *DLinklist;<br><br><span class="hljs-comment">// 初始循环双链表</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InitDLinkList</span><span class="hljs-params">(DLinklist &amp;L)</span></span>&#123;  <br>    L = (DNode *) <span class="hljs-built_in">malloc</span>(<span class="hljs-built_in">sizeof</span>(DNode));  <br>    <span class="hljs-keyword">if</span>(L==<span class="hljs-literal">NULL</span>)            <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <br>    <span class="hljs-comment">// 头结点的prior指针指向最后一个结点，最后一个结点的next指针指向头结点 </span><br>    L-&gt;prior = L;      <br>    L-&gt;next = L;<br>&#125;<br><br><span class="hljs-comment">// 判断循环双链表是否为空</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">Empty</span><span class="hljs-params">(DLinklist L)</span></span>&#123;   <br>    <span class="hljs-keyword">if</span>(L-&gt;next == L)       <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;      <br>    <span class="hljs-keyword">else</span>           <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-comment">// 判断结点p是否为循环双链表的表尾结点</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isTail</span><span class="hljs-params">(DLinklist L, DNode *p)</span></span>&#123;   <br>    <span class="hljs-keyword">if</span>(p-&gt;next == L)        <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;     <br>    <span class="hljs-keyword">else</span>            <br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="循环双链表的插入和删除操作"><a href="#循环双链表的插入和删除操作" class="headerlink" title="循环双链表的插入和删除操作"></a><strong>循环双链表的插入和删除操作</strong></h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 将结点s插入到结点p之后</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">InsertNextDNode</span><span class="hljs-params">(DNode *p, DNode *s)</span></span>&#123;  <br>    s-&gt;next = p-&gt;next;   <br>    <span class="hljs-comment">//循环双链表不用担心p结点的下一个结点为空   </span><br>    p-&gt;next-&gt;prior = s;  <br>    s-&gt;prior = p;     <br>    p-&gt;next = s;<br>&#125;<br><br><span class="hljs-comment">// 删除p结点的后继结点</span><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">DeletNextDNode</span><span class="hljs-params">(DNode *p)</span></span>&#123;  <br>    <span class="hljs-comment">// 找到p的后继结点q       </span><br>    DNode *q =p-&gt;next;        <br>    <span class="hljs-comment">//循环双链表不用担心q结点的下一个结点为空  </span><br>    p-&gt;next = q-&gt;next;    <br>    q-&gt;next-&gt;prior=p;    <br>    <span class="hljs-built_in">free</span>(q);      <br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>参考自：<a href="https://blog.csdn.net/qq_55593227/article/details/123598044">https://blog.csdn.net/qq_55593227/article/details/123598044</a></p>]]></content>
    
    
    <categories>
      
      <category>考研</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>python程序带图片等资源打包</title>
    <link href="/2024/01/12/python%E7%A8%8B%E5%BA%8F%E5%B8%A6%E5%9B%BE%E7%89%87%E7%AD%89%E8%B5%84%E6%BA%90%E6%89%93%E5%8C%85/"/>
    <url>/2024/01/12/python%E7%A8%8B%E5%BA%8F%E5%B8%A6%E5%9B%BE%E7%89%87%E7%AD%89%E8%B5%84%E6%BA%90%E6%89%93%E5%8C%85/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#在打包时，都需要将终端运行地址切换到要打包文件的父目录下</span><br><span class="hljs-comment">#在终端中运行以下代码</span><br>cd 父目录地址<br></code></pre></td></tr></table></figure><h1 id="1，常规打包"><a href="#1，常规打包" class="headerlink" title="1，常规打包"></a>1，常规打包</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Pyinstaller -F py_word.py     <span class="hljs-comment">#打包成单独exe，在文件夹dist中的单独文件</span><br><br>Pyinstaller -F -w py_word.py     <span class="hljs-comment">#不带控制台的打包，不建议，会导致静默运行，只能从运行管理器中找到并停止</span><br><br>Pyinstaller -F -w -i chengzi.ico py_word.py     <span class="hljs-comment">#打包指定exe图标打包</span><br><br>pyinstaller -F --uac-admin word.py    <span class="hljs-comment">#打包的程序以管理员身份运行</span><br></code></pre></td></tr></table></figure><p>如果打包过大，可以使用anaconda创建虚拟环境只下载需要的第三方库。</p><h1 id="2，带资源打包"><a href="#2，带资源打包" class="headerlink" title="2，带资源打包"></a>2，带资源打包</h1><h2 id="2-1-首先解决的问题：打包后代码里资源的地址会因在不同环境下运行而不同。"><a href="#2-1-首先解决的问题：打包后代码里资源的地址会因在不同环境下运行而不同。" class="headerlink" title="2.1 首先解决的问题：打包后代码里资源的地址会因在不同环境下运行而不同。"></a>2.1 首先解决的问题：打包后代码里资源的地址会因在不同环境下运行而不同。</h2><p>首先需要将图片放到代码同级文件夹内，同时更新代码内的图片地址，这样做是为了后期能够批量打包图片等资源。</p><p>这里通过文件运行的绝对路径结合图片的相对路径来生成图片的绝对路径。将以下函数代码复制到打包代码中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_resource_path</span>(<span class="hljs-params">relative_path</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(sys, <span class="hljs-string">&#x27;_MEIPASS&#x27;</span>):<br>        <span class="hljs-keyword">return</span> os.path.join(sys._MEIPASS, relative_path)<br>    <span class="hljs-keyword">return</span> os.path.join(os.path.abspath(<span class="hljs-string">&quot;.&quot;</span>), relative_path)<br></code></pre></td></tr></table></figure><p>定义了函数后，将代码里的图片地址统一换为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">get_resource_path(<span class="hljs-string">&#x27;原代码里的图片地址&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="2-2-开始进行打包"><a href="#2-2-开始进行打包" class="headerlink" title="2.2 开始进行打包"></a>2.2 开始进行打包</h2><ol><li><code>-add-data</code>后面可以加&#x3D;，也可以直接空格，效果一样。</li><li><code>-add-data</code>后面的参数值里，有两部分，用 <code>:</code> 或者 <code>;</code>隔开，前面是指打包前文件所在的位置，后面是指打包后你希望文件所在的位置。比如样例里的：<code>-add-data=&quot;image1.png:img&quot;</code> 的意思是把当前目录里一个叫 “image1.png” 的文件打包进去，但是放在打包后的 “img” 目录下，也就是变成 img&#x2F;image1.png，文件名不变。</li><li><code>-add-data</code>可以用好多次，也就是可以一个文件一个文件地加。</li><li>整个文件夹一起加：<code>-add-data &#39;images:images&#39;</code> 也就是把当前目录下 images 文件夹里的文件都打包进去，打包后的目录也是 images 一样的文件夹下。</li></ol><p>最终在终端运行的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pyinstaller --add-data <span class="hljs-string">&#x27;images:images&#x27;</span> -F --uac-admin py_name.py<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>基础工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>人工智能学习导航</title>
    <link href="/2024/01/10/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%88%AA/"/>
    <url>/2024/01/10/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%88%AA/</url>
    
    <content type="html"><![CDATA[<h1 id="1，机器学习算法python实现"><a href="#1，机器学习算法python实现" class="headerlink" title="1，机器学习算法python实现"></a>1，<a href="https://github.com/lawlite19/MachineLearning_Python?tab=readme-ov-file">机器学习算法python实现</a></h1><p>GitHub项目，讲解了机器学习算法的数学原理与python实现，做笔记必备。</p><h1 id="2，Hello算法"><a href="#2，Hello算法" class="headerlink" title="2，Hello算法"></a>2，<a href="https://www.hello-algo.com/">Hello算法</a></h1><p>数据结构类的算法的多方式实现，有c，python，c++等等，同时配备了可视化界面，形象讲解算法的原理与区别。</p><h1 id="3，可视化数据结构与算法"><a href="#3，可视化数据结构与算法" class="headerlink" title="3，可视化数据结构与算法"></a>3，<a href="https://visualgo.net/zh">可视化数据结构与算法</a></h1><p>一个单纯模拟数据结构算法的网站。</p><h1 id="4，菜鸟教程"><a href="#4，菜鸟教程" class="headerlink" title="4，菜鸟教程"></a>4，<a href="https://www.runoob.com/">菜鸟教程</a></h1><p>学计算机必备，各种语言与第三方库的讲解以及框架，数不胜数！</p><h1 id="5，神经网络与深度学习"><a href="#5，神经网络与深度学习" class="headerlink" title="5，神经网络与深度学习"></a>5，<a href="https://nndl.github.io/nndl-book.pdf">神经网络与深度学习</a></h1><p><strong>邱锡鹏</strong>教授出版，详细功能见网址上级GitHub仓库，具有以下特点：</p><p><strong>系统性</strong>：系统地整理了神经网络和深度学习的知识体系。鉴于深度学习涉及的知识点较多，本书从机器学习的基本概念、神经网络模型以及概率图模型三个层面来串联深度学习所涉及的知识点，使读者对深度学习技术的理解更具系统性、条理性和全面性。<br><strong>可读性</strong>：本书在编排上由浅入深，在语言表达上力求通俗易懂，并通过增加图例、示例以及必要的数学推导来理解抽象的概念。同时，附录简要介绍了本书所涉及的必要数学知识，便于读者查用。<br><strong>实践性</strong>：本书在网站上配套了针对每章知识点的编程练习，使得读者在学习过程中可以将理论和实践密切结合，加深对知识点的理解，并具备分析问题和解决问题的能力。</p><h1 id="6，小林coding"><a href="#6，小林coding" class="headerlink" title="6，小林coding"></a>6，<a href="https://xiaolincoding.com/">小林coding</a></h1><p>图解计算机网络、操作系统、计算机组成、数据库，让天下没有难懂的八股文！</p>]]></content>
    
    
    <categories>
      
      <category>人工智能</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GitHub desktop 基本用法</title>
    <link href="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"/>
    <url>/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="一，仓库"><a href="#一，仓库" class="headerlink" title="一，仓库"></a>一，仓库</h1><h2 id="1-1新建仓库"><a href="#1-1新建仓库" class="headerlink" title="1.1新建仓库"></a>1.1新建仓库</h2><p>   <strong>1</strong>，点击File,再点击new repository。</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled.png"></p><p>   <strong>2</strong>，通过新建仓库可以实时的在GitHub和GitHub desktop中创建一个空的仓库，你可以对新建的仓库进行各项设置。</p><p>包括仓库名字，仓库描述，仓库本地位置，自动创建readme文件，忽略文件的选择，以及开源许可证的选择。这里介绍后两个的详细内容：</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%201.png"></p><p> git ignore可以选择忽略文件，如果你有些文件并不想上传，那你就可以将其设置。</p><p> 以下是一个示例 .gitignore 文件：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><br><span class="hljs-section"># Ignore node<span class="hljs-emphasis">_modules folder   忽略文件夹</span></span><br><span class="hljs-emphasis"><span class="hljs-section">node_</span>modules/</span><br><br><span class="hljs-section"># Ignore build artifacts    忽略目录</span><br>build/<br>dist/<br><span class="hljs-emphasis">*.log</span><br><span class="hljs-emphasis"></span><br><span class="hljs-emphasis"># Ignore configuration files   忽略文件</span><br><span class="hljs-emphasis">.env</span><br><span class="hljs-emphasis">config.js</span><br><span class="hljs-emphasis"></span><br></code></pre></td></tr></table></figure><p>这将忽略 node_modules 文件夹、build 和 dist 目录、所有以 .log 结尾的文件以及 .env 和 config.js 文件。</p><p>license为许可证设置，设置许可证的目的是为了让别人可以合理合法地使用与修改我们的代码，有多种许可证可以选择，它们具有不同的权限设置。</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%202.png"></p><p>总结一下，MIT 最自由，简直就是没有任何限制，任何人都可以售卖我的软件，甚至可以用我的名字促销。BSD 和 Apache 协议也很自由，跟 MIT 的区别分别是不允许用作者本人名义促销和保护作者版权。GPL 可以说最霸道，对代码的修改部分也必须是 GPL 的，同时基于 GPL 代码而开发的代码也必须按照 GPL 发布，而 MPL ，也就是 Mozilla Public License 就温和一些，如果后续开发的代码中添加了新文件，同时新文件中也没有用到原来的代码，那么新文件可以不必继续沿用 MPL 。【<a href="https://zhuanlan.zhihu.com/p/51331026">如何为自己的 Github 项目选择开源许可证？ - 知乎 (zhihu.com)</a>】</p><p>  <strong>3</strong>，当你完成了前两步，你还需要点击Publish repository来上传仓库，并设置仓库<strong>是否公开</strong>（这很重要！）</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%203.png"></p><h2 id="1-2添加本地仓库"><a href="#1-2添加本地仓库" class="headerlink" title="1.2添加本地仓库"></a>1.2添加本地仓库</h2><p>   1，点击File，再点击Ddd local repository。</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%204.png"></p><p>   2，输入本地文件地址，但如果你的文件未初始化为git仓库，则需要点击create a repository来新建一个仓库（作用是将选定的文件初始化为git仓库）</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%205.png"></p><p>  3，点击后则与上面一样，进行各种参数填充。</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%206.png"></p><h2 id="1-3克隆仓库"><a href="#1-3克隆仓库" class="headerlink" title="1.3克隆仓库"></a>1.3克隆仓库</h2><p>1，点击File，再点击Clone repository。</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%207.png"></p><p>   2，选择需要克隆的仓库，如果你是要克隆别人的仓库，可以选择URL</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%208.png"></p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%209.png"></p><h2 id="1-4编辑仓库"><a href="#1-4编辑仓库" class="headerlink" title="1.4编辑仓库"></a>1.4编辑仓库</h2><ul><li>点击open in ········，如果这个编辑器不是你喜欢的，你可以点击绿色的Options进行编辑器的选择。</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2010.png"></p><h2 id="1-5删除仓库"><a href="#1-5删除仓库" class="headerlink" title="1.5删除仓库"></a>1.5删除仓库</h2><ul><li>删除仓库<strong>并不会删除GitHub上的仓库</strong>，更多的作用是删除本地与GitHub的连接！</li></ul><p>如果你想切断GitHub与本地库的连接，你可以执行以下操作：</p><ol><li><p>删除本地库中的.git文件夹（这是一个隐藏文件夹，你需要启用显示隐藏文件夹选项）</p></li><li><p>如果你想从GitHub上删除该库，你可以在GitHub上进入该库，点击“Settings”，然后在“Danger Zone”中点击“Delete this repository”。</p></li></ol><p>这里推荐使用GitHub desktop进行删除操作：</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/2023-05-07_232823.png"></p><p>右击需要删除的仓库</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2011.png"></p><p>在被删除仓库页面，点击Repository，再点击Remove</p><p>你会看到如下页面，勾选下方选项框的话，会将你的仓库从计算机硬盘中移除；如果不勾选，只会在GitHub desktop（GitHub）上移除。</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2012.png"></p><h1 id="二，版本控制"><a href="#二，版本控制" class="headerlink" title="二，版本控制"></a>二，版本控制</h1><h2 id="2-1更新版本"><a href="#2-1更新版本" class="headerlink" title="2.1更新版本"></a>2.1更新版本</h2><p>   <strong>1</strong>，GitHub desktop会自动识别仓库里代码的变动，并且你可选择应用哪些改变。如果你改变了仓库链接的本地仓库文件，你可以在GitHub desktop的主页面上看到如下场景：</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2013.png"></p><p>我在仓库中新建了‘版本更新.py’文件，并在其中写入了print(’dddd’)代码</p><p>   <strong>2</strong>，可以看到左侧栏中出现了changes，你需要在左下角的summary中填入摘记（必填），还可以填入相关描述，填入后，你还需要点击Push origin上传：</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2014.png"></p><p>   <strong>3</strong>，这时你就可以在GitHub上看到你的仓库发生了变化：</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2015.png"></p><h2 id="2-2项目回滚"><a href="#2-2项目回滚" class="headerlink" title="2.2项目回滚"></a>2.2项目回滚</h2><p><strong>1</strong>，你可以在History里看到每一次的版本变化：</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2016.png"></p><p><strong>2</strong>，具体操作：</p><ul><li>点击History</li><li>选择要回滚的版本</li><li>右键选择Revert Changes in Commit</li><li>确认回滚信息并提交</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2017.png"></p><p>可以看到版本回到了最开始的样子。</p><h1 id="三，分支管理"><a href="#三，分支管理" class="headerlink" title="三，分支管理"></a>三，分支管理</h1><h2 id="3-1新建分支"><a href="#3-1新建分支" class="headerlink" title="3.1新建分支"></a>3.1新建分支</h2><ul><li>点击Current brance</li><li>点击New brance</li><li>然后为你的分支命名即可</li><li>在GitHub中查看分支</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2018.png"></p><p>创建分支</p><h2 id="3-2切换分支"><a href="#3-2切换分支" class="headerlink" title="3.2切换分支"></a>3.2切换分支</h2><p>点击即可</p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2019.png" alt="在GitHub desktop选择分支"></p><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2020.png" alt="在GitHub查看与选择分支"></p><h2 id="3-3合并分支"><a href="#3-3合并分支" class="headerlink" title="3.3合并分支"></a>3.3合并分支</h2><ol><li><p>首先，在 GitHub Desktop 中打开你要合并的仓库。</p></li><li><p>点击左侧导航栏中的“分支”选项卡，找到你要合并的分支。</p></li><li><p>选择要合并的分支，右键点击该分支并选择“Merge into current branch”（合并到当前分支）选项。</p></li><li><p>确认合并操作，如果有冲突需要手动解决冲突。</p></li><li><p>点击“Commit merge”（提交合并）按钮。</p></li><li><p>最后点击“Push origin”（推送到远程仓库）按钮，将合并后的代码推送到远程仓库。</p></li></ol><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2021.png"></p><h2 id="3-4删除分支"><a href="#3-4删除分支" class="headerlink" title="3.4删除分支"></a>3.4删除分支</h2><ul><li>右键删除即可</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2022.png"></p><h2 id="3-5比较分支"><a href="#3-5比较分支" class="headerlink" title="3.5比较分支"></a>3.5比较分支</h2><ul><li>在 GitHub Desktop 中打开你要合并的仓库。</li><li>点击Compare to brance</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2023.png"></p><ul><li>在左侧搜索需要对比的即可</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2024.png"></p><h2 id="3-6查看提交历史"><a href="#3-6查看提交历史" class="headerlink" title="3.6查看提交历史"></a>3.6查看提交历史</h2><ul><li>在想要查看的分支下点击Hitory</li></ul><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2025.png"></p><h1 id="四，多人协作"><a href="#四，多人协作" class="headerlink" title="四，多人协作"></a>四，多人协作</h1><ol><li>创建GitHub仓库：首先，一个人（通常是项目的负责人）在GitHub上创建一个仓库，并将其与本地项目相关联。</li><li>邀请协作者：负责人可以通过在GitHub仓库的设置中添加协作者来邀请其他人加入项目。在协作者的GitHub帐户上，他们将收到邀请加入项目的通知。</li></ol><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2026.png"></p><p>在仓库设置里，点击Collabarators即可</p><ol><li>克隆仓库：协作者使用GitHub Desktop<strong>克隆项目</strong>的仓库到本地。他们可以选择克隆到自己的计算机上的任意位置。</li><li>进行更改：每个协作者在本地进行代码更改或其他操作。他们可以使用GitHub Desktop的界面进行提交更改。</li><li>提交更改：协作者完成更改后，使用GitHub Desktop提交他们的更改到GitHub仓库。他们可以添加有关更改的说明和描述。</li><li><strong>解决冲突</strong>：如果两个或多个协作者在相同的文件的相同行进行了更改，可能会出现冲突。在这种情况下，GitHub Desktop会提醒协作者，让他们解决冲突。协作者可以使用GitHub Desktop提供的冲突解决工具来处理冲突。</li><li>更新本地仓库：<strong>协作者</strong>可以通过点击GitHub Desktop中的”Pull”按钮来获取最新的更改。这将从GitHub仓库中拉取其他协作者提交的更改并合并到本地仓库。</li></ol><p><img src="/2024/01/09/GitHub%20desktop%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/Untitled%2027.png"></p><ol start="6"><li>推送更改：协作者在本地完成更改后，可以使用GitHub Desktop的”Push”按钮将更改推送到GitHub仓库。这将把他们的更改上传到仓库并使其他协作者可见。</li></ol><p>通过这些步骤，多人可以使用GitHub Desktop进行协作开发，并实时共享和同步他们的更改。在整个过程中，GitHub Desktop提供了一个简单直观的界面，帮助协作者进行版本控制和协作。</p>]]></content>
    
    
    <categories>
      
      <category>基础工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
